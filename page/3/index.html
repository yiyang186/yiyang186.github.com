<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="Try try try Never mind">
<meta property="og:type" content="website">
<meta property="og:title" content="Yiyang&#39;s Blog">
<meta property="og:url" content="http://yoursite.com/page/3/index.html">
<meta property="og:site_name" content="Yiyang&#39;s Blog">
<meta property="og:description" content="Try try try Never mind">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Yiyang&#39;s Blog">
<meta name="twitter:description" content="Try try try Never mind">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/3/"/>





  <title>Yiyang's Blog</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?3b9de7582df94dad7be13b2e75675386";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->










</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Yiyang's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404.html" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br />
            
            公益404
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/02/01/3 广义逆矩阵/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yiyang Peng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/7233064.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yiyang's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/02/01/3 广义逆矩阵/" itemprop="url">矩阵的广义逆</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-02-01T17:30:00+08:00">
                2016-02-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/数学/" itemprop="url" rel="index">
                    <span itemprop="name">数学</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h1><ul>
<li>广义逆<br>$A_{m \times n}, X_{m \times n}$，若X满足moore-penrose条件</li>
</ul>
<ol>
<li>AXA=A</li>
<li>XAX=X</li>
<li>$(AX)^H=AX$</li>
<li>$(XA)^H=XA$<br>中的一部分，称X是A的广义逆矩阵, 简称广义逆</li>
</ol>
<ul>
<li><p>伪逆$A^+$</p>
<ul>
<li>如果X满足上述所有moore-penrose条件，则称X是A的伪逆，或加号逆（M-P逆），记为$A^+$, 若A可逆，则$A^{-1} = A^+$。</li>
<li>$\forall A_{n \times n} \in C，A^+$ 存在且唯一。</li>
<li>性质</li>
</ul>
<ol>
<li>$AA^+A=A$</li>
<li>$A^+A A^+= A^+$</li>
<li>$(AA^+)^H = AA^+$</li>
<li>$(A^+A)^H = A^+A$</li>
</ol>
</li>
<li><p>伪逆的运算<br>设$A_{n \times n} \in C$，则</p>
</li>
</ul>
<ol>
<li>伪逆的伪逆是自己，$(A^+)^+ = A$</li>
<li>共轭转置的伪逆=伪逆的共轭转置，$(A^H)^+ = (A^+)^H$</li>
<li>转置的伪逆=伪逆的转置，$(A^T)^+ = (A^+)^T$</li>
<li>$(A^HA)^+ = A^+(A^H)^+，(AA^H)^+ = (A^H)^+A^+$</li>
<li>一般的伪逆不能去括号，$(AB)^+ ≠ B^+A^+$</li>
<li>一般地，A乘A的伪逆不等于单位阵，$A^+A ≠ AA^+ ≠ I$</li>
<li>伪逆的秩=本身的秩，$r(A^+) = r(A)$</li>
<li>$A^+ = (A^HA)^+A^H = A^H (AA^H)^+$ </li>
<li>伪逆的像空间=共轭转置的像空间$R(A^+) = R(A^H)$</li>
<li>伪逆的核空间=共轭转置的核空间$N(A^+) = N(A^H)$<br><img src="http://img.blog.csdn.net/20160201113818041" alt="这里写图片描述"></li>
</ol>
<ul>
<li>A的{n}逆<br>满足第n个moore-pensore条件的广义逆叫做A的{n}逆，记作A(n), n=1,2,3,4，如：</li>
</ul>
<ol>
<li>满足第1个mp条件为A的{1}逆，可写作A(1)，常记作$A^-$，也叫A的减号逆</li>
<li>满足第2,3个mp条件的为A的{2,3}逆，可写作A(2,3)<br>以上均是A的广义逆</li>
</ol>
<h1 id="伪逆-A-的求法"><a href="#伪逆-A-的求法" class="headerlink" title="伪逆$A^+$的求法"></a>伪逆$A^+$的求法</h1><ul>
<li>满秩分解求A+<br>对于$A_{m \times n}^r$, r &gt; 0, A有满秩分解 $A=F_{m \times r}G_{r \times n}$(列满秩×行满秩),则<br>$A^+ = G^H(GG^H)^{-1}(F^HF)^{-1}F^H = G^H(F^HAG^H)^{-1}F^H$<br>特别地，<br>当A列满秩，r=n时，$A^+ = (A^HA)^{-1}A^H$<br>当A行满秩，r=m时，$A^+ = A^H (AA^H)^{-1}$</li>
</ul>
<ul>
<li><p>奇异值分解求$A^+$<br>对于$A_{m \times n}^r, r &gt; 0$, A有奇异值分解<br>$$A=V\left(<br>\begin{matrix}<br>S_r &amp; 0 \\<br>0 &amp; 0<br>\end{matrix}<br>\right)U^H$$<br>则有<br>$$A^+=U\left(<br>\begin{matrix}<br>S_r^{-1} &amp; 0 \\<br>0 &amp; 0<br>\end{matrix}<br>\right)V^H$$<br>即UV位置对换，Sr取逆，对角元全变倒数：$Sr^{-1} = diag(σ_1^{-1}, … σ_r^{-1})$<br>或者，只需要U, $U=(U_1, U_2)$, 则$A^+ = U_1Λ_r^{-1}U_1^HA^H$, 这里$Λ_r=S_r^2=diag(λ_1, …, λ_n)$</p>
</li>
<li><p>奇异值分解求A+的简化步骤：</p>
</li>
</ul>
<ol>
<li>求出$A^HA$的r个非0特征值</li>
<li>求出相应的特征向量，并schmidt正交化，组成酉高矩阵$U_1$</li>
<li>$$A^+=U_1\left(<br>\begin{matrix}<br>λ_1^{-1} &amp;  &amp; \\<br>&amp;  \ddots  &amp;  \\<br>&amp; &amp; λ_r^{-1} \\<br>\end{matrix}<br>\right)U_1^HA^H$$</li>
</ol>
<ul>
<li>秩1公式求$A^+$：若r(A)=1, 则$$A^+={1 \over \sum |a_{ij}|^2}A^H$$</li>
</ul>
<ul>
<li>谱分解求$A^+$ (这个部分有些问题。。。有空再改)<br>$A^HA$有k个相异的特征值，$A^HA$的谱分解为$$A^HA= \sum_{i=1}^k λ_iG_i$$<br>这里$G_i = X_iY_i$，$X_i$是P的各列向量，$Y_i$是$P^{-1}$的各行向量，P是$A^HA$相似对角化时的可逆阵P, 则<br>$$A^+=\sum_{i=1}^k λ_i{ \phi_i(A^HA) \over \phi_i(\lambda_i)}A^H$$<br>其中$$\phi_i(\lambda)= \prod^k_{j=1, i≠j} (\lambda - \lambda_j)$$</li>
</ul>
<h1 id="广义逆与线性方程组"><a href="#广义逆与线性方程组" class="headerlink" title="广义逆与线性方程组"></a>广义逆与线性方程组</h1><ul>
<li><p>方程组相容：<br>即Ax=b有解（当且仅当A列满秩时解唯一, $A_{m \times n}$）<br>Ax=b相容的充要条件为$AA^-b=b$, 其通解为：$$x=A^-b+(I_n-A^-A)y$$<br>y为n阶任意列向量，因为$A^+$是$A^-$的子集，所以将$A^-$替换为$A^+$也成立(这里的$I_n$的阶数与A的列数相等)： $$x=A^+b+(I_n-A^+A)y$$<br>极小范数解为：$$x_0=A^+b$$</p>
</li>
<li><p>方程组不相容：<br>x的最小二乘解的通解为：<br>$$x=A^+b+(I_n-A^+A)y$$<br>当且仅当A列满秩时，不相容方程组Ax=b的最小二乘解唯一，是：<br>$$x_0=A^+b$$<br>当A非列满秩时,最小二乘解不唯一，但上式是极小范数最小二乘解, 且唯一。</p>
</li>
</ul>
<h1 id="A的-1-逆-A-的求法"><a href="#A的-1-逆-A-的求法" class="headerlink" title="A的{1}逆$A^-$的求法"></a>A的{1}逆$A^-$的求法</h1><p>对于$A_{m \times n}, \exists  P_m, Q_n$可逆，使得<br>$$PAQ=\left(<br>\begin{matrix}<br>I_r &amp; 0 \\<br>0 &amp; 0<br>\end{matrix}<br>\right)U^H$$<br>则<br>$$A^-=\left \{<br>\begin{array}{c|c}<br>Q\left(\begin{matrix}I_r &amp; X_{12} \\<br>X_{21} &amp; X_{22}<br>\end{matrix} \right)P &amp;X_{12},X_{21},X_{22}为任意适当阶子块<br>\end{array} \right \}$$<br>$X_{12}^{r \times (m-r)}， X_{12}^{(n-r) \times r}，X_{22}^{(n-r) \times (m-r)}$可取0, 则<br>$$A^-=Q\left( \begin{matrix} I_r &amp; 0 \\<br> 0 &amp; 0 \end{matrix} \right)P$$</p>
<p>特别地，当$A_{n \times n}$ 为方阵且可逆时，有$$PAQ=I_n$$此时$$A^- = QI_nP=QP=A^{-1}$$</p>
<ul>
<li>初等行变换求P, Q<br>$$<br>\left(\begin{matrix}A_{m \times n} &amp; I_m \\<br>I_n &amp; 0\end{matrix}\right) \longrightarrow \left(\begin{matrix} \left(\begin{matrix}I_n &amp; 0 \\<br>0 &amp; 0\end{matrix}\right) &amp; P \\<br>Q &amp; 0\end{matrix}\right)<br>$$</li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/01/31/2 矩阵的分解/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yiyang Peng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/7233064.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yiyang's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/01/31/2 矩阵的分解/" itemprop="url">几种常用矩阵分解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-01-31T12:40:00+08:00">
                2016-01-31
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/数学/" itemprop="url" rel="index">
                    <span itemprop="name">数学</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>矩阵分解 (decomposition, factorization)是将矩阵拆解为数个矩阵的乘积或加和的过程，可分为三角分解、满秩分解、QR分解、Jordan分解、SVD（奇异值）分解和谱分解等，其中三角分解(LU分解)是高斯消元法的另一种表现形式，在本科的线性代数里已经被我们用烂了，Jordan分解在上一章线性代数引论“求Jordan标准形”里已经介绍。这一章只介绍QR分解、满秩分解、SVD（奇异值）分解和谱分解。</p>
<h1 id="QR分解"><a href="#QR分解" class="headerlink" title="QR分解"></a>QR分解</h1><ul>
<li><p>描述<br>A=QR<br>A是满秩方阵，Q是正交矩阵，R是上三角阵，分解唯一<br>A=UR(把正交矩阵换成酉矩阵也一样)<br>如果A只是列满秩，($A_{m×n}, n≤m$, 秩为n)那么<br>$A_{m×n} = Q_{m×n}R_{n×n}$, Q只要满足n个列向量标准正交即可，R还是上三角阵</p>
</li>
<li><p>QR分解步骤</p>
</li>
</ul>
<ol>
<li>求r(A)判断A是否满秩</li>
<li>按列分块$A=(x_1,  x_2,  x_3)$，正交化为$y_1, y_2,y_3$, 单位化为$z_1, z_2, z_3$</li>
<li>令<br>$$Q=(z_1,z_2,z_3)$$<br>$$<br>R= \left(<br>\begin{matrix}<br>||y_1|| &amp; (x_2, z_1) &amp; (x_3, z_1) \\<br>0 &amp; ||y_2|| &amp; (x_3, z_2) \\<br>0 &amp; 0 &amp; ||y_3||<br>\end{matrix}<br>\right)<br>$$</li>
<li>最后，A=QR</li>
</ol>
<ul>
<li>scipy代码演示<br><img src="http://img.blog.csdn.net/20160929153348292" alt="这里写图片描述"></li>
</ul>
<h1 id="满秩分解"><a href="#满秩分解" class="headerlink" title="满秩分解"></a>满秩分解</h1><ul>
<li><p>描述<br>任一矩阵可分解为一个列满秩与行满秩矩阵的乘积，但分解不唯一<br>$A_{m×n} = F_{m×r} G_{r×n}$ (A的秩为r)</p>
</li>
<li><p>满秩分解方法</p>
</li>
</ul>
<ol>
<li>经初等行变换化为简化阶梯型<br><img src="http://img.blog.csdn.net/20160131104725445" alt="这里写图片描述"></li>
<li>取H中是单位向量的列的序号，找出A中对应序号的列组成F</li>
<li>取H中的非0行（前r行）作为G</li>
<li>最后，A=FG</li>
</ol>
<h1 id="奇异值分解"><a href="#奇异值分解" class="headerlink" title="奇异值分解"></a>奇异值分解</h1><ul>
<li><p>描述</p>
<ul>
<li><strong>奇异值</strong>：复矩阵$A_{m \times n}^r$(秩为r)，$A^HA$有n个特征值，按<strong>从大到小</strong>的顺序排列，保证$ \lambda_1 \geq  \lambda_2 \geq   … \geq \lambda_n$，有前r个为正，后n-r个为0，称 $σ_i=\sqrt{λ_i}$为A的奇异值，前r个$\sigma_1 \geq \sigma_2 \geq … \geq \sigma_r$为正奇异值。</li>
<li><strong>奇异值分解</strong>：$A=USV^H$<br>$A_{m×n}^r  = U_{m×m} S_{m×n} V^H_{n×n}$<br>其中，U和V为酉矩阵(见上一章)，S为A的奇异值组成的对角阵，前r个为正奇异值，后n-r个全为0<br>$$A=U\left(<br>\begin{matrix}<br>S_r &amp; 0 \\<br>0 &amp; 0<br>\end{matrix}<br>\right)V^H$$</li>
</ul>
</li>
<li><p>奇异值分解步骤：</p>
</li>
</ul>
<ol>
<li>计算$A^HA$的n个特征值并按从大到小排序得到$λ_i(i=1…n)$, 取平方根得到奇异值$σ_i$</li>
<li>计算这n个特征值$λ_i$对应的特征向量$α_i$，并schmidt正交化，得到标准正交特征向量$α_1, α_2, … α_r, α_{r+1}, … , α_n$。令$V_1=(α_1, … α_r), V_2=(α_{r+1}, … , α_n), V=(V_1, V_2)$;令$S_r=diag(σ_1, … σ_r)，(\sigma_1 \geq \sigma_2 \geq … \geq \sigma_r)$</li>
<li>计算$U_1=(β_1, … β_r) =AV_1S_r^{-1}$</li>
<li>求出$N(A^H)$的一组标准正交基$β_{r+1}, … β_m$(即求$A^H$齐次方程组的一组基础解系，也需要schmidt正交化)。令$U_2=(β_{r+1}, … β_m), U=(U_1, U_2)$, 则<br>$$A=U\left(<br>\begin{matrix}<br>S_r &amp; 0 \\<br>0 &amp; 0<br>\end{matrix}<br>\right)V^H$$</li>
</ol>
<ul>
<li>scipy演示代码<br><img src="http://img.blog.csdn.net/20160929152827925" alt="这里写图片描述"></li>
</ul>
<h1 id="谱分解"><a href="#谱分解" class="headerlink" title="谱分解"></a>谱分解</h1><ul>
<li><p>描述<br>N阶方阵$A_{n \times n}$的n个特征值称为A的谱（谱分解是对于单纯矩阵而言的）</p>
</li>
<li><p>谱分解步骤：</p>
</li>
</ul>
<ol>
<li>以A的线性无关的特征向量为列组成矩阵P，将P按列分块$P=(X_1, X_2, …, X_n)$</li>
<li>求$P^{-1}$, 将$P^{-1}$按行分块   $P^{-1}=(Y_1, Y_2, …, Y_n)^T$</li>
<li>则A的谱分解为<br>$A = λ_1X_1Y_1 +λ_2X_2Y_2 + … + λ_kX_kY_k$<br>或<br>$A = λ_1G_1 +λ_2G_2 + … + λ_kG_k$<br>其中，$G_i = X_iY_i$, 这里的$G_i$是幂等矩阵, 且有如下性质: $G_i$两两正交，所有$G_i$的和为$I_n$</li>
</ol>
<ul>
<li>特殊情况<br>若A是正规矩阵($A^HA=AA^H$)，则上述的$G_i$为幂等厄米特阵，A酉相似于对角阵，那么，将U按列分块<br>$U=( X_1, X_2, …, X_n)$,  取$G_i = X_iX_i^H$即可！</li>
</ul>
<h1 id="补充：幂等阵"><a href="#补充：幂等阵" class="headerlink" title="补充：幂等阵"></a>补充：幂等阵</h1><ul>
<li><p>描述<br>幂等阵：$A∈C_{n×n}$, 若满足$A^2=A$, 则称A为幂等阵。</p>
</li>
<li><p>A为幂等阵的等价命题</p>
</li>
</ul>
<ol>
<li>与A相似的任意矩阵也是幂等阵；</li>
<li>$A^H,A^T,A^*，I-A^H，I-A^T$都是幂等阵</li>
<li>$A^k$是幂等阵, $k \in N$</li>
</ol>
<ul>
<li>幂等阵的主要性质：</li>
</ul>
<ol>
<li>幂等阵的特征值只可能是0，1；</li>
<li>幂等阵可对角化；</li>
<li>幂等阵的迹等于幂等阵的秩，即tr(A)=rank(A)；</li>
<li>可逆的幂等阵为I；</li>
<li>零方阵和单位矩阵都是幂等阵；</li>
<li>幂等阵A满足：A(I-A)=(I-A)A=0；</li>
<li>幂等阵A有Ax=x的充要条件是x∈R(A)；</li>
<li>A的核空间N(A)等于I-A的像空间R(I-A), 且N(I-A)=R(A)。　</li>
</ol>
<ul>
<li>幂等阵的运算：<br>设 $A_1,A_2$都是幂等阵</li>
</ul>
<ol>
<li>$A_1+A_2$ 为幂等阵的充分必要条件为：$A_1A_2 =A_2A_1 = 0$且有：<br>$R(A_1+A_2) =R (A_1) ⊕R (A_2)$；(⊕表示直积)<br>$N(A_1+A_2) =N (A_1)∩N(A_2)$；</li>
<li>$A_1-A_2$ 为幂等阵的充分必要条件为：$A_1A_2 =A_2A_1=A_2$且有：$R(A_1-A_2) =R(A_1)∩N (A_2 )$；<br>$N (A_1 - A_2 ) =N (A_1 )⊕R (A_2)$；</li>
<li>若$A_1A_2 =A_2A_1$，则$A_1A_2$ 为幂等阵，且有：<br>$R (A_1A_2 ) =R (A_1 ) ∩R (A_2 )$；<br>$N (A_1A_2 ) =N (A_1 ) +N (A_2 )$。</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/01/31/1-线性代数引论/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yiyang Peng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/7233064.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yiyang's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/01/31/1-线性代数引论/" itemprop="url">矩阵论的线性代数基础</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-01-31T11:35:00+08:00">
                2016-01-31
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/数学/" itemprop="url" rel="index">
                    <span itemprop="name">数学</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Jordan标准形"><a href="#Jordan标准形" class="headerlink" title="Jordan标准形"></a>Jordan标准形</h1><ul>
<li><p>Jordan块<br>主对角元素为<strong>某一特征值</strong>，副对角元素为1，如：<br>1阶J块：($\lambda$)<br>2阶J块：$\left(\begin{matrix}\lambda &amp; 1 \\<br>&amp; \lambda \end{matrix}\right)$<br>3阶J块：$\left(\begin{matrix}\lambda &amp; 1 &amp;  \\<br>&amp; \lambda &amp; 1 \\<br>  &amp;  &amp; \lambda \end{matrix}\right)$<br>4阶J块：$\left(\begin{matrix}\lambda &amp; 1 &amp;  &amp;  \\<br>&amp; \lambda &amp; 1 &amp;  \\<br>&amp;  &amp; \lambda &amp; 1 \\<br>&amp;  &amp;  &amp; \lambda\end{matrix}\right)$<br>……<br>n阶J块：$\left(\begin{matrix}\lambda &amp; 1 &amp;  &amp;  &amp;\\<br>&amp; \lambda &amp; 1 &amp; &amp; \\<br>&amp;  &amp; \ddots &amp; \ddots \\<br>&amp;  &amp;  &amp; \ddots &amp; 1\\<br>&amp;  &amp;  &amp; &amp; \lambda \end{matrix}\right)$</p>
</li>
<li><p>Jordan标准形<br>由Jordan块组成的对角阵，如<br>$$\left(\begin{matrix}<br>J_1 &amp;  &amp;  &amp;  \\<br>&amp; J_2 &amp;  &amp;  \\<br>&amp;  &amp; \ddots &amp;  \\<br>&amp;  &amp;  &amp; J_n \end{matrix}\right)$$</p>
</li>
<li><p>求矩阵A的Jordan标准形</p>
</li>
</ul>
<ol>
<li>先求A的特征多项式，解出特征值</li>
<li>特征值单重根为1阶J块，2重根为1个2阶J块或2个1阶J块，即副对角线元素为1或0，先设为*（3重以上的差不多，可能是3个1阶J块，或1个3阶J块，或1个1阶J块+1个2阶J块）</li>
<li>对多重根算n-r(A- Iλ)=k，（r(A- Iλ)= r(Iλ-A)，实际上跟证相似对角化是一样的套路）k是多少那么那个特征值就对应几个J块，如k=1，则这个2重特征值对应1个2阶J块，*=1,。如k=2，则对应2个1阶J块，*=0。</li>
</ol>
<ul>
<li><p>注意</p>
<ul>
<li>矩阵A有多少个正交的特征向量，就有多少个Jordan块</li>
<li>A有n个相异的特征值，就有n个1阶J块</li>
<li>不考虑J块次序，复矩阵A的Jordan形由A唯一确定</li>
</ul>
</li>
<li><p>定理<br>任意n阶矩阵A都可相似于Jordan标准形</p>
</li>
</ul>
<h1 id="λ矩阵理论"><a href="#λ矩阵理论" class="headerlink" title="λ矩阵理论"></a>λ矩阵理论</h1><p>λ矩阵——A(λ)表示矩阵元素含λ</p>
<ul>
<li><p>最小多项式<br>首1的，次数最低的，A的零化式，为A的最小多项式$m_A(λ)$ 。能让f(A)=0的就是A的零化式</p>
</li>
<li><p>求最小式<br>先求特征多项式 $f(λ)=| λI-A |$，设$g(λ)=( λ-a)^i(λ-b)^j…$从次数最低的开始尝试如$g_1(λ)=( λ-a)(λ-b)…$，算一算是否有$g_1(A)= 0$，不断提高次数直到遇到$g_X(A)=0$，它就是最小式</p>
</li>
<li><p>A的最小式无重根 等价于</p>
</li>
</ul>
<ol>
<li>A可对角化</li>
<li>λI-A的不变因子无重根</li>
<li>λI-A的初等因子均一次</li>
</ol>
<ul>
<li><p>求初等因子<br><img src="http://img.blog.csdn.net/20160131000927987" alt="img{300x500}"><br>方法2中第2步所谓的分解因式是把不同类型的因式拆开，$(λ-1)^2(λ+1)^3$，同类型带次数的不要把次数拆开<br>方法3 常用，一般不考r&gt;3的清醒<br>初等因子可能有重复的，如北航矩阵论教材27页例5</p>
</li>
<li><p>求不变因子<br>A为几阶方阵就有几个不变因子，从第n个往前求。从初等因子组中取出同类型因子次数最高的项（如：λ-1, (λ-1)2, λ+2 ,( λ+2)3，带λ-1的是一个类型的，取出最高次(λ-1)2 ，带λ+1的是一个类型的，取出最高次(λ+1)3，组成(λ-1)2(λ+1)3）作为第n个不变因子dn(λ)，重复上述步奏直到初等因子全部用完，不变因子不足n个，用1补齐，如…=d2(λ)= d1(λ) = 1</p>
</li>
<li><p>求Smith标准形<br>不变因子顺序排下来，写在主对角线上，就是smith标准形<br>也可以直接由A(λ)经初等行变换化得，要保证第i项能被第i+1项整除，非常麻烦</p>
</li>
</ul>
<h1 id="Hermite转置"><a href="#Hermite转置" class="headerlink" title="Hermite转置"></a>Hermite转置</h1><ul>
<li>共轭转置:  $A^H$,对A取转置后再取共轭</li>
<li>厄米特阵: $A^H=A$，若$x^HAx &gt; $0 则称A厄米特正定</li>
<li>酉矩阵: $U^HU=I$ 类似正交阵($Q^TQ=I$)，但U是复数阵</li>
<li>共轭转置Hermite转置的计算</li>
</ul>
<ol>
<li>$(AB)^H = B^HA^H$，其中A为m行n列的矩阵，B为n行p列矩阵。</li>
<li>$(A^H)^H = A$</li>
<li>$(A +B)^H = A^H + B^H$。</li>
<li>$(rA)^H = \overline rA^H$，其中r为复数，$\overline r$为r的共轭</li>
<li>若A为方阵，则 $|A^H| = |A|^H$，且$tr(A^H) = (tr A)^H$</li>
<li>A是可逆矩阵， 当且仅当 $A^H$可逆，且有$(A^H)^{-1} = (A^{-1})^H$</li>
<li>$A^H$的特征值是A的特征值的复共轭。</li>
<li>$(Ax,y) = (x, A^Hy)$，其中A为m行n列的矩阵，复向量x为n维列向量，复向量y为m维列向量，( , )为复数的内积。</li>
<li>分块矩阵的运算与转置相同，先交换行列，在求每个分块的共轭转置</li>
</ol>
<h1 id="酉空间"><a href="#酉空间" class="headerlink" title="酉空间"></a>酉空间</h1><p>其实就是把欧式空间里的实数变成复数, 欧式空间是有限维的实内积空间，酉空间是有限维的复内积空间</p>
<ul>
<li>实对称阵，正交阵，厄米特阵与酉矩阵</li>
</ul>
<table>
<thead>
<tr>
<th>.</th>
<th>实数域</th>
<th>复数域</th>
</tr>
</thead>
<tbody>
<tr>
<td>对称</td>
<td>实对称阵($A^T=A$)</td>
<td>厄米特阵($A^H=A$)</td>
</tr>
<tr>
<td>正交</td>
<td>正交阵($A^TA=I$)</td>
<td>酉矩阵($A^HA=I$)</td>
</tr>
</tbody>
</table>
<ol>
<li>A是实对称阵（$A^T=A$）等价于 存在正交阵Q使得 A相似于 对角阵，即$Q^TAQ = diag(λ_i…)$，且$λ_i$为实数</li>
<li>A是正交矩阵（$A^T=A^{-1}$） 等价于 存在酉矩阵U使得 A酉相似于 对角阵，即$U^HAU = diag(λ_i…)$, 且$|λ_i|=1$</li>
<li>A是厄米特阵（$A^H=A$） 等价于 A酉相似于 对角阵，且特征值为实数</li>
<li>A是酉矩阵（$A^H=A^{-1}$） 等价于 A酉相似于 对角阵，且特征值模为1</li>
</ol>
<ul>
<li>相似, 正交相似与酉相似：</li>
</ul>
<ol>
<li>$\exists$可逆阵P, 使得$P^{-1}AP = B$, 即A 相似于B</li>
<li>$\exists$正交阵Q, 使得$Q^TAQ = B$, 即A 正交相似于B</li>
<li>$\exists$酉矩阵U, 使得$U^HAU = B$, 即A 酉相似于B</li>
</ol>
<ul>
<li><p>许尔引理（Schur）：$\forall A_{n \times n} \in C$, A都可 酉相似于 一个上三角阵，其主对角元为A的特征值    </p>
</li>
<li><p>正规矩阵（规范阵）：$\forall A_{n \times n} \in C$，有 $A^HA=AA^H$ </p>
<ul>
<li>实对称阵（$A^T=A$）    反实对称阵（$A^T= -A$）    正交阵（$A^T=A^{-1}$）</li>
<li>厄米特阵（$A^H=A$）    反厄米特阵（$A^H= -A$）    酉矩阵（$A^H=A^{-1}$）<br>均是正规矩阵</li>
</ul>
</li>
</ul>
<h1 id="补充：正定矩阵"><a href="#补充：正定矩阵" class="headerlink" title="补充：正定矩阵"></a>补充：正定矩阵</h1><ul>
<li><p>描述<br>设方阵$M_{n \times n}$，若对任何非零向量z，都有$z^TMz&gt; 0$，则称M为正定矩阵。</p>
</li>
<li><p>判定<br>正定矩阵在合同变换下可化为标准型， 即对角矩阵。<br>所有特征值大于零的对称矩阵（或厄米矩阵）也是正定矩阵。<br>判定定理1：对称阵A为正定的充分必要条件是 A的特征值全为正。<br>判定定理2：对称阵A为正定的充分必要条件是 A的各阶顺序主子式都为正。<br>判定定理3：任意阵A为正定的充分必要条件是 A合同于单位阵。</p>
</li>
<li><p>性质：</p>
</li>
</ul>
<ol>
<li>正定矩阵一定是非奇异的。（奇异矩阵的定义：若n阶矩阵A为奇异阵，则其的行列式为零，即 |A|=0）</li>
<li>正定矩阵的任一主子矩阵也是正定矩阵。</li>
<li>若A为n阶正定矩阵，则A为n阶可逆矩阵。</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/01/19/spark构建回归模型/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yiyang Peng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/7233064.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yiyang's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/01/19/spark构建回归模型/" itemprop="url">在spark上做简单的回归</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-01-19T15:24:00+08:00">
                2016-01-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>###加载数据集<br>数据集为<a href="http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset" target="_blank" rel="external">Bike-Sharing-Dataset</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">path = <span class="string">"hdfs:///user/yy/Bike-Sharing-Dataset/hour_noheader.csv"</span></div><div class="line">raw_data = sc.textFile(path)</div><div class="line">num_data = raw_data.count()</div><div class="line">records = raw_data.map(<span class="keyword">lambda</span> x: x.split(<span class="string">","</span>))</div><div class="line">records.cache()</div><div class="line">first = records.first()</div><div class="line"><span class="keyword">print</span> first</div><div class="line"><span class="keyword">print</span> num_data</div></pre></td></tr></table></figure></p>
<pre><code>[u&apos;1&apos;, u&apos;2011-01-01&apos;, u&apos;1&apos;, u&apos;0&apos;, u&apos;1&apos;, u&apos;0&apos;, u&apos;0&apos;, u&apos;6&apos;, u&apos;0&apos;, u&apos;1&apos;, u&apos;0.24&apos;, u&apos;0.2879&apos;, u&apos;0.81&apos;, u&apos;0&apos;, u&apos;3&apos;, u&apos;13&apos;, u&apos;16&apos;]
17379
</code></pre><hr>
<p>###为线性回归模型准备数据集<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 将特征映射到二元编码向量的映射函数</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_mapping</span><span class="params">(rdd, idx)</span>:</span></div><div class="line">    <span class="keyword">return</span> rdd.map(<span class="keyword">lambda</span> fields: fields[idx])\</div><div class="line">              .distinct()\</div><div class="line">              .zipWithIndex()\</div><div class="line">              .collectAsMap()</div></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 查看映射字典结构</span></div><div class="line"><span class="keyword">print</span> <span class="string">"Mapping of first categorical feature column: %s"</span> % get_mapping(records, <span class="number">2</span>)</div></pre></td></tr></table></figure>
<pre><code>Mapping of first categorical feature column: {u&apos;1&apos;: 0, u&apos;3&apos;: 1, u&apos;2&apos;: 2, u&apos;4&apos;: 3}
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 建立将特征映射到二元编码向量的映射字典</span></div><div class="line">mappings = [get_mapping(records, i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>, <span class="number">10</span>)]</div><div class="line">cat_len = sum(map(len, mappings))</div><div class="line">num_len = len(records.first()[<span class="number">11</span>:<span class="number">15</span>])</div><div class="line">total_len = num_len + cat_len</div><div class="line"><span class="keyword">print</span> <span class="string">"Feature vector length for categorical features: %d"</span> % cat_len</div><div class="line"><span class="keyword">print</span> <span class="string">"Feature vector length for numerical features: %d"</span> % num_len</div><div class="line"><span class="keyword">print</span> <span class="string">"Total feature vector length: %d"</span> % total_len</div></pre></td></tr></table></figure>
<pre><code>Feature vector length for categorical features: 57
Feature vector length for numerical features: 4
Total feature vector length: 61
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pyspark.mllib.regression <span class="keyword">import</span> LabeledPoint</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"><span class="comment"># 用于建立二元编码的特征向量</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_features</span><span class="params">(record)</span>:</span></div><div class="line">    cat_vec = np.zeros(cat_len)</div><div class="line">    i = <span class="number">0</span></div><div class="line">    step = <span class="number">0</span></div><div class="line">    <span class="keyword">for</span> field <span class="keyword">in</span> record[<span class="number">2</span>:<span class="number">9</span>]:</div><div class="line">        m = mappings[i]</div><div class="line">        idx = m[field]</div><div class="line">        cat_vec[idx+step] = <span class="number">1</span></div><div class="line">        i += <span class="number">1</span></div><div class="line">        step += len(m)</div><div class="line">    num_vec = np.array([float(field) <span class="keyword">for</span> field <span class="keyword">in</span> record[<span class="number">10</span>:<span class="number">14</span>]])</div><div class="line">    <span class="keyword">return</span> np.concatenate((cat_vec, num_vec))</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_label</span><span class="params">(record)</span>:</span></div><div class="line">    <span class="keyword">return</span> float(record[<span class="number">-1</span>])</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 对每条记录提取特征向量（使用二元编码）和标签</span></div><div class="line">data = records.map(<span class="keyword">lambda</span> r: LabeledPoint(extract_label(r), extract_features(r)))</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 查看使用了二元编码的训练样本结构</span></div><div class="line">first_point = data.first()</div><div class="line"><span class="keyword">print</span> <span class="string">"Raw data: "</span> + str(first[<span class="number">2</span>:])</div><div class="line"><span class="keyword">print</span> <span class="string">"Label: "</span> + str(first_point.label)</div><div class="line"><span class="keyword">print</span> <span class="string">"Linear Model feature vector:\n"</span> + str(first_point.features)</div><div class="line"><span class="keyword">print</span> <span class="string">"Linear Model feature vector length: "</span> + str(len(first_point.features))</div></pre></td></tr></table></figure>
<pre><code>Raw data: [u&apos;1&apos;, u&apos;0&apos;, u&apos;1&apos;, u&apos;0&apos;, u&apos;0&apos;, u&apos;6&apos;, u&apos;0&apos;, u&apos;1&apos;, u&apos;0.24&apos;, u&apos;0.2879&apos;, u&apos;0.81&apos;, u&apos;0&apos;, u&apos;3&apos;, u&apos;13&apos;, u&apos;16&apos;]
Label: 16.0
Linear Model feature vector:
[1.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.24,0.2879,0.81,0.0]
Linear Model feature vector length: 61
</code></pre><hr>
<p>###为决策回归树准备数据集<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 决策回归树不需要将类型数据用二元编码表示</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_features_dt</span><span class="params">(record)</span>:</span></div><div class="line">    <span class="keyword">return</span> np.array(map(float, record[<span class="number">2</span>:<span class="number">14</span>]))</div></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 对每条记录提取特征向量（未使用二元编码）和标签</span></div><div class="line">data_dt = records.map(<span class="keyword">lambda</span> r: LabeledPoint(extract_label(r), extract_features_dt(r)))</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 查看未使用二元编码的训练样本结构</span></div><div class="line">first_point_dt = data_dt.first()</div><div class="line"><span class="keyword">print</span> <span class="string">"Label: "</span> + str(first_point_dt.label)</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree feature vector: "</span> + str(first_point_dt.features)</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree feature vector length: "</span> + str(len(first_point_dt.features))</div></pre></td></tr></table></figure>
<pre><code>Label: 16.0
Decision Tree feature vector: [1.0,0.0,1.0,0.0,0.0,6.0,0.0,1.0,0.24,0.2879,0.81,0.0]
Decision Tree feature vector length: 12
</code></pre><hr>
<p>###线性回归和决策回归树的帮助文档<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pyspark.mllib.regression <span class="keyword">import</span> LinearRegressionWithSGD</div><div class="line"><span class="keyword">from</span> pyspark.mllib.tree <span class="keyword">import</span> DecisionTree</div></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">help(LinearRegressionWithSGD.train)</div></pre></td></tr></table></figure>
<pre><code>Help on method train in module pyspark.mllib.regression:

train(cls, data, iterations=100, step=1.0, miniBatchFraction=1.0, initialWeights=None, regParam=0.0, regType=None, intercept=False, validateData=True) method of __builtin__.type instance
    Train a linear regression model using Stochastic Gradient
    Descent (SGD).
    This solves the least squares regression formulation
            f(weights) = 1/n ||A weights-y||^2^
    (which is the mean squared error).
    Here the data matrix has n rows, and the input RDD holds the
    set of rows of A, each with its corresponding right hand side
    label y. See also the documentation for the precise formulation.

    :param data:              The training data, an RDD of
                              LabeledPoint.
    :param iterations:        The number of iterations
                              (default: 100).
    :param step:              The step parameter used in SGD
                              (default: 1.0).
    :param miniBatchFraction: Fraction of data to be used for each
                              SGD iteration (default: 1.0).
    :param initialWeights:    The initial weights (default: None).
    :param regParam:          The regularizer parameter
                              (default: 0.0).
    :param regType:           The type of regularizer used for
                              training our model.

                              :Allowed values:
                                 - &quot;l1&quot; for using L1 regularization (lasso),
                                 - &quot;l2&quot; for using L2 regularization (ridge),
                                 - None for no regularization

                                 (default: None)

    :param intercept:         Boolean parameter which indicates the
                              use or not of the augmented representation
                              for training data (i.e. whether bias
                              features are activated or not,
                              default: False).
    :param validateData:      Boolean parameter which indicates if
                              the algorithm should validate data
                              before training. (default: True)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">help(DecisionTree.trainRegressor)</div></pre></td></tr></table></figure>
<pre><code>Help on method trainRegressor in module pyspark.mllib.tree:

trainRegressor(cls, data, categoricalFeaturesInfo, impurity=&apos;variance&apos;, maxDepth=5, maxBins=32, minInstancesPerNode=1, minInfoGain=0.0) method of __builtin__.type instance
    Train a DecisionTreeModel for regression.

    :param data: Training data: RDD of LabeledPoint.
                 Labels are real numbers.
    :param categoricalFeaturesInfo: Map from categorical feature
             index to number of categories.
             Any feature not in this map is treated as continuous.
    :param impurity: Supported values: &quot;variance&quot;
    :param maxDepth: Max depth of tree.
             E.g., depth 0 means 1 leaf node.
             Depth 1 means 1 internal node + 2 leaf nodes.
    :param maxBins: Number of bins used for finding splits at each
             node.
    :param minInstancesPerNode: Min number of instances required at
             child nodes to create the parent split
    :param minInfoGain: Min info gain required to create a split
    :return: DecisionTreeModel

    Example usage:

    &gt;&gt;&gt; from pyspark.mllib.regression import LabeledPoint
    &gt;&gt;&gt; from pyspark.mllib.tree import DecisionTree
    &gt;&gt;&gt; from pyspark.mllib.linalg import SparseVector
    &gt;&gt;&gt;
    &gt;&gt;&gt; sparse_data = [
    ...     LabeledPoint(0.0, SparseVector(2, {0: 0.0})),
    ...     LabeledPoint(1.0, SparseVector(2, {1: 1.0})),
    ...     LabeledPoint(0.0, SparseVector(2, {0: 0.0})),
    ...     LabeledPoint(1.0, SparseVector(2, {1: 2.0}))
    ... ]
    &gt;&gt;&gt;
    &gt;&gt;&gt; model = DecisionTree.trainRegressor(sc.parallelize(sparse_data), {})
    &gt;&gt;&gt; model.predict(SparseVector(2, {1: 1.0}))
    1.0
    &gt;&gt;&gt; model.predict(SparseVector(2, {1: 0.0}))
    0.0
    &gt;&gt;&gt; rdd = sc.parallelize([[0.0, 1.0], [0.0, 0.0]])
    &gt;&gt;&gt; model.predict(rdd).collect()
    [1.0, 0.0]
</code></pre><hr>
<p>###训练回归模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 训练线性回归模型,后面会慢慢改进</span></div><div class="line">linear_model = LinearRegressionWithSGD.train(data, iterations=<span class="number">50</span>, step=<span class="number">0.1</span>, intercept=<span class="keyword">False</span>)</div><div class="line">true_vs_predicted = data.map(<span class="keyword">lambda</span> p: (p.label, linear_model.predict(p.features)))</div><div class="line"><span class="keyword">print</span>  <span class="string">"Linear Model predictions: "</span> + str(true_vs_predicted.take(<span class="number">5</span>))</div></pre></td></tr></table></figure>
<pre><code>Linear Model predictions: [(16.0, 110.54561916607503), (40.0, 107.92836240337226), (32.0, 107.45239452594706), (13.0, 107.46860142170017), (1.0, 107.19840815670955)]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 训练决策回归模型,后面会慢慢改进</span></div><div class="line">dt_model = DecisionTree.trainRegressor(data_dt, &#123;&#125;)</div><div class="line">preds = dt_model.predict(data_dt.map(<span class="keyword">lambda</span> p: p.features))</div><div class="line">actual = data.map(<span class="keyword">lambda</span> p: p.label)</div><div class="line">true_vs_predicted_dt = actual.zip(preds)</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree predictions: "</span> + str(true_vs_predicted_dt.take(<span class="number">5</span>))</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree depth: "</span> + str(dt_model.depth())</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree number of nodes: "</span> + str(dt_model.numNodes())</div></pre></td></tr></table></figure>
<pre><code>Decision Tree predictions: [(16.0, 54.913223140495866), (40.0, 54.913223140495866), (32.0, 53.171052631578945), (13.0, 14.284023668639053), (1.0, 14.284023668639053)]
Decision Tree depth: 5
Decision Tree number of nodes: 63
</code></pre><hr>
<p>###评估回归模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 几个计算误差的函数</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">squared_error</span><span class="params">(actual, pred)</span>:</span></div><div class="line">    <span class="keyword">return</span> (pred - actual) ** <span class="number">2</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">abs_error</span><span class="params">(actual, pred)</span>:</span></div><div class="line">    <span class="keyword">return</span> np.abs(pred - actual)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">squared_log_error</span><span class="params">(pred, actual)</span>:</span></div><div class="line">    <span class="keyword">return</span> (np.log(pred+<span class="number">1</span>) - np.log(actual+<span class="number">1</span>)) ** <span class="number">2</span></div><div class="line"></div><div class="line"><span class="comment"># 评估函数</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">myEvaluation</span><span class="params">(true_vs_predicted)</span>:</span></div><div class="line">    mse = true_vs_predicted.map(<span class="keyword">lambda</span> (t,p): squared_error(t,p)).mean()</div><div class="line">    mae = true_vs_predicted.map(<span class="keyword">lambda</span> (t,p): abs_error(t,p)).mean()</div><div class="line">    rmsle = np.sqrt(true_vs_predicted.map(<span class="keyword">lambda</span> (t,p): squared_log_error(t,p)).mean())</div><div class="line">    <span class="keyword">return</span> (mse, mae, rmsle)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估线性回归模型</span></div><div class="line">mse ,mae ,rmsle = myEvaluation(true_vs_predicted)</div><div class="line"><span class="keyword">print</span> <span class="string">"Linear Model - Mean Squared Error: %2.4f"</span> % mse</div><div class="line"><span class="keyword">print</span> <span class="string">"Linear Model - Mean Absolute Error: %2.4f"</span> % mae</div><div class="line"><span class="keyword">print</span> <span class="string">"Linear Model - Root Mean Squared Log Error: %2.4f"</span> % rmsle</div><div class="line"><span class="comment"># 1.46只达到了kaggle上的平均成绩</span></div></pre></td></tr></table></figure>
<pre><code>Linear Model - Mean Squared Error: 27408.1527
Linear Model - Mean Absolute Error: 127.4103
Linear Model - Root Mean Squared Log Error: 1.4847
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估决策回归模型</span></div><div class="line">mse_dt ,mae_dt ,rmsle_dt = myEvaluation(true_vs_predicted_dt)</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree - Mean Squared Error: %2.4f"</span> % mse_dt</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree - Mean Absolute Error: %2.4f"</span> % mae_dt</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree - Root Mean Squared Log Error: %2.4f"</span> % rmsle_dt</div><div class="line"><span class="comment"># 最好成绩是0.2左右，0.6只能算马马虎虎</span></div></pre></td></tr></table></figure>
<pre><code>Decision Tree - Mean Squared Error: 11560.7978
Decision Tree - Mean Absolute Error: 71.0969
Decision Tree - Root Mean Squared Log Error: 0.6259
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">%matplotlib inline</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line"><span class="comment"># 通过画直方图来检查目标值的分布情况</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">checkTargets</span><span class="params">(targets)</span>:</span></div><div class="line">    plt.hist(targets, bins=<span class="number">40</span>, color=<span class="string">'lightblue'</span>, normed=<span class="keyword">True</span>)</div><div class="line">    fig = plt.gcf()</div><div class="line">    fig.set_size_inches(<span class="number">16</span>,<span class="number">10</span>)</div></pre></td></tr></table></figure>
<hr>
<p>###目标变量分布</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 对于线性回归模型,当目标变量服从正态分布,误差项满足高斯--马尔科夫条件（零均值、等方差、不相关）时,回归参数的最小二乘估计是一致最小方差无偏估计. 显然这里的响应变量并不服从正态分布</span></div><div class="line">targets = records.map(<span class="keyword">lambda</span> r: float(r[<span class="number">-1</span>])).collect()</div><div class="line">checkTargets(targets)</div></pre></td></tr></table></figure>
<p><img src="http://img.blog.csdn.net/20160119151242014" alt="这里写图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 对目标值，即响应变量（因变量）进行对数变换，并查看变换后的分布</span></div><div class="line">log_targets = records.map(<span class="keyword">lambda</span> r: np.log(float(r[<span class="number">-1</span>]))).collect()</div><div class="line">checkTargets(log_targets)</div></pre></td></tr></table></figure>
<p><img src="http://img.blog.csdn.net/20160119151303592" alt="这里写图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 对目标值，即响应变量（因变量）进行平方根变换，并查看变换后的分布</span></div><div class="line">log_targets = records.map(<span class="keyword">lambda</span> r: np.sqrt(float(r[<span class="number">-1</span>]))).collect()</div><div class="line">checkTargets(log_targets)</div></pre></td></tr></table></figure>
<p><img src="http://img.blog.csdn.net/20160119151334608" alt="这里写图片描述"></p>
<hr>
<p>###对目标变量作对数变换后重新训练并评估<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 用对数变换后的目标值重新训练线性回归模型</span></div><div class="line">data_log = data.map(<span class="keyword">lambda</span> lp: LabeledPoint(np.log(lp.label), lp.features))</div><div class="line">model_log = LinearRegressionWithSGD.train(data_log, iterations=<span class="number">50</span>, step=<span class="number">0.1</span>)</div><div class="line">true_vs_predicted_log = data_log.map(<span class="keyword">lambda</span> p: (np.exp(p.label), np.exp(model_log.predict(p.features))))</div></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估</span></div><div class="line">mse_log, mae_log, rmsle_log = myEvaluation(true_vs_predicted_log)</div><div class="line"><span class="keyword">print</span> <span class="string">"Linear Model - Mean Squared Error: %2.4f"</span> % mse_log</div><div class="line"><span class="keyword">print</span> <span class="string">"Linear Model - Mean Absolute Error: %2.4f"</span> % mae_log</div><div class="line"><span class="keyword">print</span> <span class="string">"Linear Model - Root Mean Squared Log Error: %2.4f"</span> % rmsle_log</div><div class="line"><span class="keyword">print</span> <span class="string">"Non log-transformed predictions:\n"</span> + str(true_vs_predicted.take(<span class="number">3</span>))</div><div class="line"><span class="keyword">print</span> <span class="string">"Log-transformed predictions:\n"</span> + str(true_vs_predicted_log.take(<span class="number">3</span>))</div></pre></td></tr></table></figure>
<pre><code>Linear Model - Mean Squared Error: 37837.3776
Linear Model - Mean Absolute Error: 133.6572
Linear Model - Root Mean Squared Log Error: 1.3315
Non log-transformed predictions:
[(16.0, 110.54561916607503), (40.0, 107.92836240337226), (32.0, 107.45239452594706)]
Log-transformed predictions:
[(15.999999999999998, 45.336304060846494), (40.0, 42.455963122588777), (32.0, 41.297013243855893)]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 用对数变换后的目标值重新训练决策回归树模型</span></div><div class="line">data_dt_log = data_dt.map(<span class="keyword">lambda</span> lp: LabeledPoint(np.log(lp.label), lp.features))</div><div class="line">dt_model_log = DecisionTree.trainRegressor(data_dt_log, &#123;&#125;)</div><div class="line">preds_log = dt_model_log.predict(data_dt_log.map(<span class="keyword">lambda</span> p: p.features))</div><div class="line">actual_log = data_dt_log.map(<span class="keyword">lambda</span> p: p.label)</div><div class="line">true_vs_predicted_dt_log = actual_log.zip(preds_log).map(<span class="keyword">lambda</span> (t,p): (np.exp(t), np.exp(p)))</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估</span></div><div class="line">mse_log_dt, mae_log_dt, rmsle_log_dt = myEvaluation(true_vs_predicted_dt_log)</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree - Mean Squared Error: %2.4f"</span> % mse_log_dt</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree - Mean Absolute Error: %2.4f"</span> % mae_log_dt</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree - Root Mean Squared Log Error: %2.4f"</span> % rmsle_log_dt</div><div class="line"><span class="keyword">print</span> <span class="string">"Non log-transformed predictions:\n"</span> + str(true_vs_predicted_dt.take(<span class="number">3</span>))</div><div class="line"><span class="keyword">print</span> <span class="string">"Log-transformed predictions:\n"</span> + str(true_vs_predicted_dt_log.take(<span class="number">3</span>))</div></pre></td></tr></table></figure>
<pre><code>Decision Tree - Mean Squared Error: 14781.5760
Decision Tree - Mean Absolute Error: 76.4131
Decision Tree - Root Mean Squared Log Error: 0.6406
Non log-transformed predictions:
[(16.0, 54.913223140495866), (40.0, 54.913223140495866), (32.0, 53.171052631578945)]
Log-transformed predictions:
[(15.999999999999998, 37.530779787154522), (40.0, 37.530779787154522), (32.0, 7.2797070993907287)]
</code></pre><hr>
<p>###为数据集划分训练集与测试集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 对用于线性回归的数据集，按2：8划分测试集与训练集</span></div><div class="line">data_with_idx = data.zipWithIndex().map(<span class="keyword">lambda</span> (k,v): (v,k)) <span class="comment"># 给每个样本加上序号，再反转键值对</span></div><div class="line">test = data_with_idx.sample(<span class="keyword">False</span>, <span class="number">0.2</span>, <span class="number">42</span>) <span class="comment"># 参数：不重复抽样，抽样20%，随机数种子42</span></div><div class="line">train = data_with_idx.subtractByKey(test) <span class="comment"># 从data_with_idx中抽掉（去掉）与test的key（样本序号）相等的样本</span></div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 形成可用于训练和测试的</span></div><div class="line">train_data = train.map(<span class="keyword">lambda</span> (idx,p): p)</div><div class="line">test_data = test.map(<span class="keyword">lambda</span> (idx,p): p)</div><div class="line">train_size = train_data.count()</div><div class="line">test_size = test_data.count()</div><div class="line"><span class="keyword">print</span> <span class="string">"Train data size: %d"</span> % train_size</div><div class="line"><span class="keyword">print</span> <span class="string">"Test data size: %d"</span> % test_size</div><div class="line"><span class="keyword">print</span> <span class="string">"Total data size: %d"</span> % num_data</div><div class="line"><span class="keyword">print</span> <span class="string">"Train + Test size: %d"</span> % (train_size+test_size)</div></pre></td></tr></table></figure>
<pre><code>Train data size: 13934
Test data size: 3445
Total data size: 17379
Train + Test size: 17379
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 对用于决策回归的数据集，按2：8划分测试集与训练集</span></div><div class="line">data_with_idx_dt = data_dt.zipWithIndex().map(<span class="keyword">lambda</span> (k,v): (v,k))</div><div class="line">test_dt = data_with_idx_dt.sample(<span class="keyword">False</span>, <span class="number">0.2</span>, <span class="number">42</span>)</div><div class="line">train_dt = data_with_idx_dt.subtractByKey(test_dt)</div><div class="line">train_data_dt = train_dt.map(<span class="keyword">lambda</span> (idx,p): p)</div><div class="line">test_data_dt = test_dt.map(<span class="keyword">lambda</span> (idx,p): p)</div></pre></td></tr></table></figure>
<hr>
<p>###对线性回归模型的参数调优</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 用于在不同参数配置下评估线性回归模型的性能</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(train, test, iterations, step, regParam, regType, intercept)</span>:</span></div><div class="line">    model = LinearRegressionWithSGD.train(train, iterations, step, regParam=regParam, \</div><div class="line">                                          regType=regType, intercept=intercept)</div><div class="line">    tp = test.map(<span class="keyword">lambda</span> p: (p.label, model.predict(p.features)))</div><div class="line">    rmsle = np.sqrt(tp.map(<span class="keyword">lambda</span> (t,p): squared_log_error(t,p)).mean())</div><div class="line">    <span class="keyword">return</span> rmsle</div><div class="line"></div><div class="line"><span class="comment"># 画折线图展示不同参数与RMSLE的关系</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotting</span><span class="params">(params, metrics)</span>:</span></div><div class="line">    plt.plot(params, metrics)</div><div class="line">    plt.xscale(<span class="string">'log'</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估不同迭代次数对线性回归性能的影响</span></div><div class="line">params = [<span class="number">1</span>,<span class="number">5</span>,<span class="number">10</span>,<span class="number">20</span>,<span class="number">50</span>,<span class="number">100</span>,<span class="number">200</span>]</div><div class="line">metrics = [evaluate(train_data, test_data, param, <span class="number">0.01</span>, <span class="number">0.0</span>, <span class="string">'l2'</span>, <span class="keyword">False</span>) <span class="keyword">for</span> param <span class="keyword">in</span> params]</div><div class="line"><span class="keyword">print</span> params</div><div class="line"><span class="keyword">print</span> metrics</div><div class="line"></div><div class="line"><span class="comment"># 迭代次数与RMSLE的关系</span></div><div class="line">plotting(params, metrics)</div></pre></td></tr></table></figure>
<pre><code>[1, 5, 10, 20, 50, 100, 200]
[2.8779465130028195, 2.0390187660391499, 1.7761565324837874, 1.5828778102209107, 1.4382263191764473, 1.4050638054019449, 1.4191482045051593]
</code></pre><p><img src="http://img.blog.csdn.net/20160119151735437" alt="这里写图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估不同步长对线性回归性能的影响</span></div><div class="line">params = [<span class="number">0.01</span>,<span class="number">0.025</span>,<span class="number">0.05</span>,<span class="number">0.1</span>,<span class="number">1.0</span>]</div><div class="line">metrics = [evaluate(train_data, test_data, <span class="number">10</span>, param, <span class="number">0.0</span>, <span class="string">'l2'</span>, <span class="keyword">False</span>) <span class="keyword">for</span> param <span class="keyword">in</span> params]</div><div class="line"><span class="keyword">print</span> params</div><div class="line"><span class="keyword">print</span> metrics</div><div class="line"></div><div class="line"><span class="comment"># 步长与RMSLE的关系</span></div><div class="line">plotting(params, metrics)</div></pre></td></tr></table></figure>
<pre><code>[0.01, 0.025, 0.05, 0.1, 1.0]
[1.7761565324837874, 1.4379348243997032, 1.4189071944747718, 1.5027293911925559, nan]
</code></pre><p><img src="http://img.blog.csdn.net/20160119151750953" alt="这里写图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估不同L2正则化参数对线性回归性能的影响，L2正则化既是对过大的模型权重向量2范数进行惩罚</span></div><div class="line">params = [<span class="number">0.0</span>,<span class="number">0.01</span>,<span class="number">0.1</span>,<span class="number">1.0</span>,<span class="number">5.0</span>,<span class="number">10.0</span>,<span class="number">20.0</span>]</div><div class="line">metrics = [evaluate(train_data, test_data, <span class="number">10</span>, <span class="number">0.1</span>, param, <span class="string">'l2'</span>, <span class="keyword">False</span>) <span class="keyword">for</span> param <span class="keyword">in</span> params]</div><div class="line"><span class="keyword">print</span> params</div><div class="line"><span class="keyword">print</span> metrics</div><div class="line"></div><div class="line"><span class="comment"># L2正则化参数与RMSLE的关系</span></div><div class="line">plotting(params, metrics)</div></pre></td></tr></table></figure>
<pre><code>[0.0, 0.01, 0.1, 1.0, 5.0, 10.0, 20.0]
[1.5027293911925559, 1.5020646031965639, 1.4961903335175231, 1.4479313176192781, 1.4113329999970989, 1.5381692234875386, 1.8279640526059082]
</code></pre><p><img src="http://img.blog.csdn.net/20160119151809922" alt="这里写图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估不同L1正则化参数对线性回归性能的影响</span></div><div class="line">params = [<span class="number">0.0</span>,<span class="number">0.01</span>,<span class="number">0.1</span>,<span class="number">1.0</span>,<span class="number">10.0</span>,<span class="number">100.0</span>,<span class="number">1000.0</span>]</div><div class="line">metrics = [evaluate(train_data, test_data, <span class="number">10</span>, <span class="number">0.1</span>, param, <span class="string">'l1'</span>, <span class="keyword">False</span>) <span class="keyword">for</span> param <span class="keyword">in</span> params]</div><div class="line"><span class="keyword">print</span> params</div><div class="line"><span class="keyword">print</span> metrics</div><div class="line"></div><div class="line"><span class="comment"># L1正则化参数与RMSLE的关系</span></div><div class="line">plotting(params, metrics)</div></pre></td></tr></table></figure>
<pre><code>[0.0, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]
[1.5027293911925559, 1.5026938950690176, 1.5023761634555699, 1.499412856617814, 1.4713669769550108, 1.7596682962964314, 4.7551250073268614]
</code></pre><p><img src="http://img.blog.csdn.net/20160119151831845" alt="这里写图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 查看线性回归模型在不同的L1正则化参数下权重向量中0的个数</span></div><div class="line"><span class="keyword">for</span> regParam <span class="keyword">in</span> [<span class="number">1.0</span>, <span class="number">10.0</span>, <span class="number">100.0</span>]:</div><div class="line">    model = LinearRegressionWithSGD.train(train_data, <span class="number">10</span>, <span class="number">0.1</span>, regParam=regParam,\</div><div class="line">                                         regType=<span class="string">'l1'</span>, intercept=<span class="keyword">False</span>)</div><div class="line">    <span class="keyword">print</span> <span class="string">"L1 (%s) number of zero weights: "</span>%regParam + str(sum(model.weights.array == <span class="number">0</span>))</div><div class="line"><span class="comment"># L1正则化参数越大，即对模型的L1范数惩罚越大，    那么      权重</span></div></pre></td></tr></table></figure>
<pre><code>L1 (1.0) number of zero weights: 4
L1 (10.0) number of zero weights: 33
L1 (100.0) number of zero weights: 58
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估是否使用截距（intercept）对线性回归性能的影响</span></div><div class="line">params = [<span class="keyword">False</span>,<span class="keyword">True</span>]</div><div class="line">metrics = [evaluate(train_data, test_data, <span class="number">10</span>, <span class="number">0.1</span>, <span class="number">1.0</span>, <span class="string">'l2'</span>, param) <span class="keyword">for</span> param <span class="keyword">in</span> params]</div><div class="line"><span class="keyword">print</span> params</div><div class="line"><span class="keyword">print</span> metrics</div><div class="line"></div><div class="line"><span class="comment"># 是否使用截距与RMSLE的关系</span></div><div class="line">plt.bar(params, metrics, color=<span class="string">'lightblue'</span>)</div><div class="line">fig = plt.gcf()</div><div class="line"><span class="comment"># 使用截距使RMSLE有略微的增加</span></div></pre></td></tr></table></figure>
<pre><code>[False, True]
[1.4479313176192781, 1.4798261513419801]
</code></pre><p><img src="http://img.blog.csdn.net/20160119151850689" alt="这里写图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 用于在不同参数配置下评估决策回归数模型的性能</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_dt</span><span class="params">(train, test, maxDepth, maxBins)</span>:</span></div><div class="line">    model = DecisionTree.trainRegressor(train, &#123;&#125;, impurity=<span class="string">'variance'</span>, maxDepth=maxDepth, \</div><div class="line">                                          maxBins=maxBins)</div><div class="line">    preds = model.predict(test.map(<span class="keyword">lambda</span> p: p.features))</div><div class="line">    actual = test.map(<span class="keyword">lambda</span> p: p.label)</div><div class="line">    tp = actual.zip(preds)</div><div class="line">    rmsle = np.sqrt(tp.map(<span class="keyword">lambda</span> (t,p): squared_log_error(t,p)).mean())</div><div class="line">    <span class="keyword">return</span> rmsle</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估不同最大树深度对决策回归树性能的影响</span></div><div class="line">params = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">10</span>,<span class="number">20</span>]</div><div class="line">metrics = [evaluate_dt(train_data_dt, test_data_dt, param, <span class="number">32</span>) <span class="keyword">for</span> param <span class="keyword">in</span> params]</div><div class="line"><span class="keyword">print</span> params</div><div class="line"><span class="keyword">print</span> metrics</div><div class="line"></div><div class="line"><span class="comment"># 最大树深度与RMSLE的关系</span></div><div class="line">plt.plot(params, metrics)</div><div class="line">fig = plt.gcf()</div></pre></td></tr></table></figure>
<pre><code>[1, 2, 3, 4, 5, 10, 20]
[1.0280339660196287, 0.92686672078778276, 0.81807794023407532, 0.74060228537329209, 0.63583503599563096, 0.42659354467941862, 0.45291736653588244]
</code></pre><p><img src="http://img.blog.csdn.net/20160119151911393" alt="这里写图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估不同最大划分数对决策回归树性能的影响</span></div><div class="line">params = [<span class="number">2</span>,<span class="number">4</span>,<span class="number">8</span>,<span class="number">16</span>,<span class="number">32</span>,<span class="number">64</span>, <span class="number">100</span>]</div><div class="line">metrics = [evaluate_dt(train_data_dt, test_data_dt, <span class="number">5</span>, param) <span class="keyword">for</span> param <span class="keyword">in</span> params]</div><div class="line"><span class="keyword">print</span> params</div><div class="line"><span class="keyword">print</span> metrics</div><div class="line"></div><div class="line"><span class="comment"># 最大树深度与RMSLE的关系</span></div><div class="line">plt.plot(params, metrics)</div><div class="line">fig = plt.gcf()</div></pre></td></tr></table></figure>
<pre><code>[2, 4, 8, 16, 32, 64, 100]
[1.3069788763726049, 0.81923394899750324, 0.75745322513058744, 0.62430742982038667, 0.63583503599563096, 0.63583503599563096, 0.63583503599563096]
</code></pre><p><img src="http://img.blog.csdn.net/20160119151926877" alt="这里写图片描述"></p>
<p>###使用IPython的交互插件进行参数调优<br>需要IPython notebook<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> IPython.html.widgets <span class="keyword">import</span> interact, interactive, fixed</div><div class="line"><span class="keyword">from</span> IPython.html <span class="keyword">import</span> widgets</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(param)</span>:</span></div><div class="line">    metrics = evaluate_dt(train_data_dt, test_data_dt, <span class="number">5</span>, param)</div><div class="line">    <span class="keyword">print</span> param</div><div class="line">    <span class="keyword">print</span> metrics</div><div class="line"></div><div class="line">interact(f, param=(<span class="number">10</span>,<span class="number">20</span>));</div></pre></td></tr></table></figure></p>
<p><img src="http://img.blog.csdn.net/20160119152107317" alt="这里写图片描述"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/01/17/在spark上做简单的文本分类(python)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yiyang Peng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/7233064.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yiyang's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/01/17/在spark上做简单的文本分类(python)/" itemprop="url">在spark上做简单的文本分类</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-01-17T23:58:00+08:00">
                2016-01-17
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>数据集选的是20_newsgroups，我按7：3分的训练集和测试集。</p>
<p>总的流程如下：</p>
<p><img src="http://img.blog.csdn.net/20160117232525303" alt="文本分类基本步骤"><br>这里把数据集中的每一条文本都表示成TFTDF向量，用训练集的TFTDF向量来训练模型，用测试集的TFTDF向量进行分类测试，最后统计测试准确率。</p>
<hr>
<p>###初始化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 设置训练集，测试集路径。</span></div><div class="line">trainPath = <span class="string">"hdfs:///user/yy/20_newsgroups/train/*"</span></div><div class="line">testPath = <span class="string">"hdfs:///user/yy/20_newsgroups/test/*"</span></div><div class="line"></div><div class="line"><span class="comment"># 分类时，新闻主题需要转换成数字，labelsDict将主题转换成数字</span></div><div class="line">labelsDict = &#123;<span class="string">'alt.atheism'</span>:<span class="number">0</span>, <span class="string">'comp.graphics'</span>:<span class="number">1</span>, <span class="string">'comp.os.ms-windows.misc'</span>:<span class="number">2</span>,\</div><div class="line">              <span class="string">'comp.sys.ibm.pc.hardware'</span>:<span class="number">3</span>, <span class="string">'comp.sys.mac.hardware'</span>:<span class="number">4</span>, <span class="string">'comp.windows.x'</span>:<span class="number">5</span>,\</div><div class="line">              <span class="string">'misc.forsale'</span>:<span class="number">6</span>, <span class="string">'rec.autos'</span>:<span class="number">7</span>, <span class="string">'rec.motorcycles'</span>:<span class="number">8</span>, <span class="string">'rec.sport.baseball'</span>:<span class="number">9</span>,\</div><div class="line">              <span class="string">'rec.sport.hockey'</span>:<span class="number">10</span>, <span class="string">'sci.crypt'</span>:<span class="number">11</span>, <span class="string">'sci.electronics'</span>:<span class="number">12</span>, <span class="string">'sci.med'</span>:<span class="number">13</span>,\</div><div class="line">              <span class="string">'sci.space'</span>:<span class="number">14</span>, <span class="string">'soc.religion.christian'</span>:<span class="number">15</span>, <span class="string">'talk.politics.guns'</span>:<span class="number">16</span>,\</div><div class="line">              <span class="string">'talk.politics.mideast'</span>:<span class="number">17</span>, <span class="string">'talk.politics.misc'</span>:<span class="number">18</span>, <span class="string">'talk.religion.misc'</span>:<span class="number">19</span>&#125;</div><div class="line"></div><div class="line"><span class="comment"># keyTolabels则将数字再转换回主题，主要是方便自己看的</span></div><div class="line">keyTolabels = &#123;<span class="number">0</span>:<span class="string">'alt.atheism'</span>, <span class="number">1</span>:<span class="string">'comp.graphics'</span>, <span class="number">2</span>:<span class="string">'comp.os.ms-windows.misc'</span>,\</div><div class="line">              <span class="number">3</span>:<span class="string">'comp.sys.ibm.pc.hardware'</span>, <span class="number">4</span>:<span class="string">'comp.sys.mac.hardware'</span>, <span class="number">5</span>:<span class="string">'comp.windows.x'</span>,\</div><div class="line">              <span class="number">6</span>:<span class="string">'misc.forsale'</span>, <span class="number">7</span>:<span class="string">'rec.autos'</span>, <span class="number">8</span>:<span class="string">'rec.motorcycles'</span>, <span class="number">9</span>:<span class="string">'rec.sport.baseball'</span>,\</div><div class="line">              <span class="number">10</span>:<span class="string">'rec.sport.hockey'</span>, <span class="number">11</span>:<span class="string">'sci.crypt'</span>, <span class="number">12</span>:<span class="string">'sci.electronics'</span>, <span class="number">13</span>:<span class="string">'sci.med'</span>,\</div><div class="line">              <span class="number">14</span>:<span class="string">'sci.space'</span>, <span class="number">15</span>:<span class="string">'soc.religion.christian'</span>, <span class="number">16</span>:<span class="string">'talk.politics.guns'</span>,\</div><div class="line">              <span class="number">17</span>:<span class="string">'talk.politics.mideast'</span>, <span class="number">18</span>:<span class="string">'talk.politics.misc'</span>, <span class="number">19</span>:<span class="string">'talk.religion.misc'</span>&#125;</div></pre></td></tr></table></figure>
<hr>
<p>###预处理函数<br>完成对文档的分词，去停用词，词干提取，同义词替换的工作，需要安装一个自然语言处理的第三方库nltk。当然，每个节点都需要安装。预处理的基本步骤如下：<br><img src="http://img.blog.csdn.net/20160117233401568" alt="预处理步骤"><br>这里的同义词替换做的非常简单，只是从单词的第一个同义词集里取出第一个同义词。这么做有时会产生歧义，因为单词在不同的语义下有不同的同义词集，只取第一个同义词集即限定了仅仅使用单词的第一个语义。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenlize</span><span class="params">(doc)</span>:</span></div><div class="line">    <span class="keyword">import</span> nltk, re</div><div class="line">    <span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords</div><div class="line">    <span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> wordnet</div><div class="line">    </div><div class="line">    r = re.compile(<span class="string">r'[\w]+'</span>) <span class="comment"># 以非字母数字字符来进行分词</span></div><div class="line">    my_stopwords = nltk.corpus.stopwords.words(<span class="string">'english'</span>)</div><div class="line">    porter = nltk.PorterStemmer()</div><div class="line">    </div><div class="line">    newdoc = []</div><div class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> nltk.regexp_tokenize(doc, r): <span class="comment"># 分词</span></div><div class="line">        newWord = porter.stem(word.lower()) <span class="comment"># 词干提取</span></div><div class="line">        <span class="keyword">if</span> newWord <span class="keyword">in</span> my_stopwords: <span class="comment"># 去停用词</span></div><div class="line">            <span class="keyword">continue</span></div><div class="line">        tokenSynsets = wordnet.synsets(newWord)</div><div class="line">        newdoc.append(newWord <span class="keyword">if</span> tokenSynsets == [] <span class="keyword">else</span> tokenSynsets[<span class="number">0</span>].lemma_names()[<span class="number">0</span>]) <span class="comment"># 同义词替换</span></div><div class="line">    <span class="keyword">return</span> newdoc</div></pre></td></tr></table></figure></p>
<hr>
<p>###导入训练集<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">trainTokens = sc.wholeTextFiles(trainPath)\</div><div class="line">                .map(<span class="keyword">lambda</span> (fileName, doc): doc)\</div><div class="line">                .map(<span class="keyword">lambda</span> doc: tokenlize(doc))</div></pre></td></tr></table></figure></p>
<hr>
<p>###构建单词映射哈希表，tfidf模型<br>训练集和测试集都需要使用这个哈希表，它的大小根据不同单词的数量来设置，一般取2的n方，在前期数据探索的时候需要计算一下不同单词的数量。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pyspark.mllib.feature <span class="keyword">import</span> HashingTF</div><div class="line">hasingTF = HashingTF(<span class="number">2</span> ** <span class="number">16</span>)</div><div class="line"></div><div class="line"><span class="comment"># 将训练集每个文档都映射为tf向量</span></div><div class="line">trainTf = hasingTF.transform(trainTokens)</div><div class="line">trainTf.cache()</div><div class="line"></div><div class="line"><span class="comment"># 构建IDF模型，训练集和测试集都用它</span></div><div class="line"><span class="keyword">from</span> pyspark.mllib.feature <span class="keyword">import</span> IDF</div><div class="line">idf = IDF().fit(trainTf)</div><div class="line"></div><div class="line"><span class="comment"># 将训练集每个tf向量转换为tfidf向量</span></div><div class="line">trainTfidf = idf.transform(trainTf)</div><div class="line">trainTfidf.cache()</div></pre></td></tr></table></figure></p>
<hr>
<p>###标注训练集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 为训练集标注，成为最终可用的训练集，每个样本都需要放在LabeledPoint里</span></div><div class="line"><span class="keyword">from</span> pyspark.mllib.regression <span class="keyword">import</span> LabeledPoint</div><div class="line">trainLabels = sc.wholeTextFiles(trainPath)\</div><div class="line">                .map(<span class="keyword">lambda</span> (path, doc): path.split(<span class="string">'/'</span>)[<span class="number">-2</span>])</div><div class="line">train = trainLabels.zip(trainTfidf)\</div><div class="line">                   .map(<span class="keyword">lambda</span> (topic, vector): LabeledPoint(labelsDict[topic], vector))</div><div class="line">train.cache()</div></pre></td></tr></table></figure>
<hr>
<p>###导入测试集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 导入测试集并完成预处理</span></div><div class="line">testTokens = sc.wholeTextFiles(testPath)\</div><div class="line">               .map(<span class="keyword">lambda</span> (fileName, doc): doc)\</div><div class="line">               .map(<span class="keyword">lambda</span> doc: tokenlize(doc))</div></pre></td></tr></table></figure>
<hr>
<p>###将测试集转换成tfidf向量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 将测试集每个文档都映射为tf向量，和训练集用的是同一个哈希映射hasingTF</span></div><div class="line"><span class="keyword">from</span> pyspark.mllib.feature <span class="keyword">import</span> HashingTF</div><div class="line">testTf = hasingTF.transform(testTokens)</div><div class="line"></div><div class="line"><span class="comment"># 将测试集每个tf向量转换为tfidf向量，和训练集用的是同一个IDF模型idf</span></div><div class="line"><span class="keyword">from</span> pyspark.mllib.feature <span class="keyword">import</span> IDF</div><div class="line">testTfidf = idf.transform(testTf)</div></pre></td></tr></table></figure>
<hr>
<p>###标注测试集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 为测试集标注，成为最终可用与测试的测试集</span></div><div class="line"><span class="keyword">from</span> pyspark.mllib.regression <span class="keyword">import</span> LabeledPoint</div><div class="line">testLabels = sc.wholeTextFiles(testPath)\</div><div class="line">               .map(<span class="keyword">lambda</span> (path, doc): path.split(<span class="string">'/'</span>)[<span class="number">-2</span>])</div><div class="line"></div><div class="line">test = testLabels.zip(testTfidf)\</div><div class="line">                 .map(<span class="keyword">lambda</span> (topic, vector): LabeledPoint(labelsDict[topic], vector))</div><div class="line">testCount = test.count()</div></pre></td></tr></table></figure>
<hr>
<h3 id="训练朴素贝叶斯模型并计算准确率"><a href="#训练朴素贝叶斯模型并计算准确率" class="headerlink" title="训练朴素贝叶斯模型并计算准确率"></a>训练朴素贝叶斯模型并计算准确率</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pyspark.mllib.classification <span class="keyword">import</span> NaiveBayes</div><div class="line">model = NaiveBayes.train(train, <span class="number">0.1</span>)</div><div class="line"></div><div class="line"><span class="comment"># 计算测试的准确率</span></div><div class="line">predictionAndLabel = test.map(<span class="keyword">lambda</span> p: (model.predict(p.features), p.label))</div><div class="line">accuracy = <span class="number">1.0</span> * predictionAndLabel.filter(<span class="keyword">lambda</span> x: x[<span class="number">0</span>] == x[<span class="number">1</span>]).count() / testCount</div><div class="line"><span class="keyword">print</span> accuracy</div></pre></td></tr></table></figure>
<pre><code>0.803298634582
</code></pre><hr>
<p>###训练多元逻辑回归模型并计算准确率</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span>  pyspark.mllib.classification <span class="keyword">import</span> LogisticRegressionWithLBFGS</div><div class="line">lrModel = LogisticRegressionWithLBFGS.train(train, iterations=<span class="number">10</span>, numClasses=<span class="number">20</span>)</div><div class="line"></div><div class="line"><span class="comment"># 计算测试的准确率</span></div><div class="line">predictionAndLabel = test.map(<span class="keyword">lambda</span> p: (lrModel.predict(p.features), p.label))</div><div class="line">accuracy = <span class="number">1.0</span> * predictionAndLabel.filter(<span class="keyword">lambda</span> x: x[<span class="number">0</span>] == x[<span class="number">1</span>]).count() / testCount</div><div class="line"><span class="keyword">print</span> accuracy</div></pre></td></tr></table></figure>
<pre><code>0.812897120454
</code></pre><hr>
<p>如果有兴趣，可以随便拿一份新闻组文本来测试一下，给自己一个更为直观的感受。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line">aTestText = <span class="string">"""</span></div><div class="line">Path: cantaloupe.srv.cs.cmu.edu!rochester!udel!bogus.sura.net!howland.reston.ans.net!ira.uka.de!math.fu-berlin.de!cs.tu-berlin.de!ossip</div><div class="line">From: ossip@cs.tu-berlin.de (Ossip Kaehr)</div><div class="line">Newsgroups: comp.sys.mac.hardware</div><div class="line">Subject: SE/30 8bit card does not work with 20mb..</div><div class="line">Date: 21 Apr 1993 23:22:22 GMT</div><div class="line">Organization: Technical University of Berlin, Germany</div><div class="line">Lines: 27</div><div class="line">Message-ID: &lt;1r4kve$6cl@news.cs.tu-berlin.de&gt;</div><div class="line">NNTP-Posting-Host: trillian.cs.tu-berlin.de</div><div class="line">Mime-Version: 1.0</div><div class="line">Content-Type: text/plain; charset=iso-8859-1</div><div class="line">Content-Transfer-Encoding: 8bit</div><div class="line">Summary: HELP!</div><div class="line">Keywords: SE/30 MODE32 System7 PDS</div><div class="line"></div><div class="line">Hello!</div><div class="line"></div><div class="line">I have a SE/30 and a Generation Systems 8bit PDS card for a 17"</div><div class="line">screen.</div><div class="line">It worked great until I upgraded from 5 to 20 mb ram.</div><div class="line">Now with Sys7.1 and MODE32 or 32enabler it does not boot..</div><div class="line"></div><div class="line">a tech support person said the card does not support these 32bit</div><div class="line">fixes.</div><div class="line"></div><div class="line">BUT: when pressing the shift key while booting (when the ext. monitor</div><div class="line">goes black after having been grey) the system  SOMETIMES boots properly!!</div><div class="line">and then works ok with the 20mb and full graphics.</div><div class="line"></div><div class="line">WHAT's HAPPENING???</div><div class="line"></div><div class="line">Thanks a lot for any advice!!!</div><div class="line">please answer by mail.</div><div class="line"></div><div class="line">Ossip Kaehr</div><div class="line">ossip@cs.tu-berlin.de</div><div class="line">voice: +49.30.6226317</div><div class="line">-- </div><div class="line"> __   --------------------------------------------------------------   __</div><div class="line">/_/\  Ossip Kaehr	Hermannstrasse 32  D-1000 Berlin 44  Germany  /\_\</div><div class="line">\_\/  Tel. +49.30.6223910 or 6218814     EMail ossip@cs.tu-berlin.de  \/_/</div><div class="line">      --------------------------------------------------------------</div><div class="line"></div><div class="line">"""</div></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">testTf = hasingTF.transform(tokenlize(aTestText)) <span class="comment"># 预处理后转换为tf向量</span></div><div class="line">testTfidf = idf.transform(testTf) <span class="comment"># 再转换成tfidf向量</span></div><div class="line"><span class="keyword">print</span> keyTolabels[lrModel.predict(testTfidf)] <span class="comment"># 预测并输出结果</span></div></pre></td></tr></table></figure>
<pre><code>&apos;comp.sys.mac.hardware&apos;
</code></pre><hr>
<p>###总结spark上如何将文档转换成tfidf向量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 构建哈希表用于映射所有单词</span></div><div class="line"><span class="keyword">from</span> pyspark.mllib.feature <span class="keyword">import</span> HashingTF</div><div class="line">hasingTF = HashingTF(<span class="number">2</span> ** <span class="number">16</span>) <span class="comment"># 维数需要大于不同单词的总数</span></div><div class="line"></div><div class="line"><span class="comment"># 将文档映射为tf向量，这里的trainTokens为rdd类型</span></div><div class="line">trainTf = hasingTF.transform(trainTokens)</div><div class="line">testTf = hasingTF.transform(testTokens)</div><div class="line"></div><div class="line"><span class="comment"># 构建IDF模型，训练集和测试集都用它</span></div><div class="line"><span class="keyword">from</span> pyspark.mllib.feature <span class="keyword">import</span> IDF</div><div class="line">idf = IDF().fit(trainTf)</div><div class="line"></div><div class="line"><span class="comment"># 将tf向量转换为tfidf向量</span></div><div class="line">trainTfidf = idf.transform(trainTf)</div><div class="line">testTfidf = idf.transform(testTf)</div></pre></td></tr></table></figure>
<hr>
<p>###相关阅读<br><a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" target="_blank" rel="external">https://en.wikipedia.org/wiki/Tf%E2%80%93idf</a><br><a href="https://en.wikipedia.org/wiki/Natural_Language_Toolkit" target="_blank" rel="external">https://en.wikipedia.org/wiki/Natural_Language_Toolkit</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/01/02/MLlib里几个简单的分类模型(python)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yiyang Peng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/7233064.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yiyang's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/01/02/MLlib里几个简单的分类模型(python)/" itemprop="url">MLlib里几个简单的分类模型</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-01-02T17:41:00+08:00">
                2016-01-02
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"># 这个数据集来自www.kaggle.com/c/stumbleupon/data, 用于预测网页是短暂存在还是长时间流行,这里我把它存放在hdfs文件系统内的/user/yy/stumbleupon/目录里</div><div class="line">rawData = sc.textFile(&quot;hdfs:///user/yy/stumbleupon/train_noheader.tsv&quot;)</div><div class="line">records = rawData.map(lambda line: line.split(&apos;\t&apos;))</div><div class="line">records.first()</div><div class="line"># 每一条样本是一个网页的信息</div></pre></td></tr></table></figure>
<p>[u’”<a href="http://www.bloomberg.com/news/2010-12-23/ibm-predicts-holographic-calls-air-breathing-batteries-by-2015.html" target="_blank" rel="external">http://www.bloomberg.com/news/2010-12-23/ibm-predicts-holographic-calls-air-breathing-batteries-by-2015.html</a>“‘,<br>     u’”4042”‘,<br>     u’”{“”title””:””IBM Sees Holographic Calls Air Breathing Batteries ibm sees holographic calls, air-breathing batteries””,””body””:””A sign stands outside the International Business Machines Corp IBM Almaden Research Center campus in San Jose California Photographer Tony Avelar Bloomberg Buildings stand at the International Business Machines Corp IBM Almaden Research Center campus in the Santa Teresa Hills of San Jose California Photographer Tony Avelar Bloomberg By 2015 your mobile phone will project a 3 D image of anyone who calls and your laptop will be powered by kinetic energy At least that s what International Business Machines Corp sees in its crystal ball The predictions are part of an annual tradition for the Armonk New York based company which surveys its 3 000 researchers to find five ideas expected to take root in the next five years IBM the world s largest provider of computer services looks to Silicon Valley for input gleaning many ideas from its Almaden research center in San Jose California Holographic conversations projected from mobile phones lead this year s list The predictions also include air breathing batteries computer programs that can tell when and where traffic jams will take place environmental information generated by sensors in cars and phones and cities powered by the heat thrown off by computer servers These are all stretch goals and that s good said Paul Saffo managing director of foresight at the investment advisory firm Discern in San Francisco In an era when pessimism is the new black a little dose of technological optimism is not a bad thing For IBM it s not just idle speculation The company is one of the few big corporations investing in long range research projects and it counts on innovation to fuel growth Saffo said Not all of its predictions pan out though IBM was overly optimistic about the spread of speech technology for instance When the ideas do lead to products they can have broad implications for society as well as IBM s bottom line he said Research Spending They have continued to do research when all the other grand research organizations are gone said Saffo who is also a consulting associate professor at Stanford University IBM invested 5 8 billion in research and development last year 6 1 percent of revenue While that s down from about 10 percent in the early 1990s the company spends a bigger share on research than its computing rivals Hewlett Packard Co the top maker of personal computers spent 2 4 percent last year At Almaden scientists work on projects that don t always fit in with IBM s computer business The lab s research includes efforts to develop an electric car battery that runs 500 miles on one charge a filtration system for desalination and a program that shows changes in geographic data IBM rose 9 cents to 146 04 at 11 02 a m in New York Stock Exchange composite trading The stock had gained 11 percent this year before today Citizen Science The list is meant to give a window into the company s innovation engine said Josephine Cheng a vice president at IBM s Almaden lab All this demonstrates a real culture of innovation at IBM and willingness to devote itself to solving some of the world s biggest problems she said Many of the predictions are based on projects that IBM has in the works One of this year s ideas that sensors in cars wallets and personal devices will give scientists better data about the environment is an expansion of the company s citizen science initiative Earlier this year IBM teamed up with the California State Water Resources Control Board and the City of San Jose Environmental Services to help gather information about waterways Researchers from Almaden created an application that lets smartphone users snap photos of streams and creeks and report back on conditions The hope is that these casual observations will help local and state officials who don t have the resources to do the work themselves Traffic Predictors IBM also sees data helping shorten commutes in the next five years Computer programs will use algorithms and real time traffic information to predict which roads will have backups and how to avoid getting stuck Batteries may last 10 times longer in 2015 than today IBM says Rather than using the current lithium ion technology new models could rely on energy dense metals that only need to interact with the air to recharge Some electronic devices might ditch batteries altogether and use something similar to kinetic wristwatches which only need to be shaken to generate a charge The final prediction involves recycling the heat generated by computers and data centers Almost half of the power used by data centers is currently spent keeping the computers cool IBM scientists say it would be better to harness that heat to warm houses and offices In IBM s first list of predictions compiled at the end of 2006 researchers said instantaneous speech translation would become the norm That hasn t happened yet While some programs can quickly translate electronic documents and instant messages and other apps can perform limited speech translation there s nothing widely available that acts like the universal translator in Star Trek Second Life The company also predicted that online immersive environments such as Second Life would become more widespread While immersive video games are as popular as ever Second Life s growth has slowed Internet users are flocking instead to the more 2 D environments of Facebook Inc and Twitter Inc Meanwhile a 2007 prediction that mobile phones will act as a wallet ticket broker concierge bank and shopping assistant is coming true thanks to the explosion of smartphone applications Consumers can pay bills through their banking apps buy movie tickets and get instant feedback on potential purchases all with a few taps on their phones The nice thing about the list is that it provokes thought Saffo said If everything came true they wouldn t be doing their job To contact the reporter on this story Ryan Flinn in San Francisco at rflinn bloomberg net To contact the editor responsible for this story Tom Giles at tgiles5 bloomberg net by 2015, your mobile phone will project a 3-d image of anyone who calls and your laptop will be powered by kinetic energy. at least that\\u2019s what international business machines corp. sees in its crystal ball.””,””url””:””bloomberg news 2010 12 23 ibm predicts holographic calls air breathing batteries by 2015 html””}”‘,<br>     u’”business”‘,<br>     u’”0.789131”‘,<br>     u’”2.055555556”‘,<br>     u’”0.676470588”‘,<br>     u’”0.205882353”‘,<br>     u’”0.047058824”‘,<br>     u’”0.023529412”‘,<br>     u’”0.443783175”‘,<br>     u’”0”‘,<br>     u’”0”‘,<br>     u’”0.09077381”‘,<br>     u’”0”‘,<br>     u’”0.245831182”‘,<br>     u’”0.003883495”‘,<br>     u’”1”‘,<br>     u’”1”‘,<br>     u’”24”‘,<br>     u’”0”‘,<br>     u’”5424”‘,<br>     u’”170”‘,<br>     u’”8”‘,<br>     u’”0.152941176”‘,<br>     u’”0.079129575”‘,<br>     u’”0”‘]</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">from pyspark.mllib.regression import LabeledPoint # 标注点类型，（label, feature）通常feature是Vectors.dense类型</div><div class="line">from pyspark.mllib.linalg import Vectors</div><div class="line"></div><div class="line"># DenseVector类型的好处,这2行只是一个演示而已</div><div class="line">a = sc.parallelize([Vectors.dense(1,2),Vectors.dense(3,4)])</div><div class="line">a.sum() # 装着DenseVector类型向量的rdd,可以按列求值</div><div class="line"></div><div class="line"># def records_processing(record):</div><div class="line">#     trimmed = record.map(lambda e: e.replaceAll(&apos;\&quot;&apos;, &apos;&apos;))</div><div class="line">#     label = int(trimmed[record.size - 1])</div><div class="line">#     features = trimmed[4 : record.size - 1].map(lambda d: 0.0 if d == &apos;?&apos; else float(d))</div><div class="line">#     return LabeledPoint(label, Vectors.dense(features))</div><div class="line"></div><div class="line">sizeAndData = records.map(lambda record : (len(record), map(lambda e: e.replace(&apos;\&quot;&apos;, &apos;&apos;), record)))</div><div class="line">labelAndFeature = sizeAndData.map(lambda (size, data): (int(data[size-1]), map(lambda d: 0.0 if d == &apos;?&apos; else float(d), data[4: size-1])))</div><div class="line">data = labelAndFeature.map(lambda (label, feature): LabeledPoint(label, Vectors.dense(map(lambda d: 0.0 if d &lt; 0 else d, feature))))</div><div class="line">data.first()</div></pre></td></tr></table></figure>
<p>LabeledPoint(0.0, [0.789131,2.055555556,0.676470588,0.205882353,0.047058824,0.023529412,0.443783175,0.0,0.0,0.09077381,0.0,0.245831182,0.003883495,1.0,1.0,24.0,0.0,5424.0,170.0,8.0,0.152941176,0.079129575])</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">data.cache()</div><div class="line">data.count()</div></pre></td></tr></table></figure>
<p>7395</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">from pyspark.mllib.classification import LogisticRegressionWithSGD</div><div class="line">from pyspark.mllib.classification import SVMWithSGD</div><div class="line">from pyspark.mllib.classification import NaiveBayes</div><div class="line">from pyspark.mllib.tree import DecisionTree</div><div class="line"># from pyspark.mllib.tree.configuration import Algo </div><div class="line"># from pyspark.mllib.tree.impurity import Entropy</div><div class="line"></div><div class="line">numIterations = 10</div><div class="line">maxTreeDepth = 5</div><div class="line">dataPoint = data.first()</div><div class="line">dataPoint</div></pre></td></tr></table></figure>
<p>LabeledPoint(0.0, [0.789131,2.055555556,0.676470588,0.205882353,0.047058824,0.023529412,0.443783175,0.0,0.0,0.09077381,0.0,0.245831182,0.003883495,1.0,1.0,24.0,0.0,5424.0,170.0,8.0,0.152941176,0.079129575])</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"># 训练逻辑回归模型</div><div class="line">lrModel = LogisticRegressionWithSGD.train(data, numIterations)</div><div class="line"></div><div class="line"># 使用逻辑归回模型</div><div class="line">prediction = lrModel.predict(dataPoint.features)</div><div class="line">print &quot;预测值：%d, 真实值：%d&quot; % (prediction, dataPoint.label)</div><div class="line"></div><div class="line"># 看看逻辑回归整体的预测结果</div><div class="line">predictionsAndRealities = data.map(lambda point: lrModel.predict(point.features) == point.label)</div><div class="line"></div><div class="line"># 计算逻辑回归的准确率</div><div class="line">lrTotalCorrect = data.map(lambda point :</div><div class="line">                         1 if lrModel.predict(point.features) == point.label else 0</div><div class="line">                         ).sum()</div><div class="line">lrAccuracy = float(lrTotalCorrect) / data.count()</div><div class="line">print &quot;逻辑回归准确率：&quot;, lrAccuracy</div><div class="line"></div><div class="line"># 计算PR(准确率-召回率)曲线下面积， 以及ROC(受试者工作特征曲线， 真阳性率-假阳性率)曲线下面积即AUC</div><div class="line">from pyspark.mllib.evaluation import BinaryClassificationMetrics</div><div class="line">scoreAndLabels = data.map(lambda point: (float(lrModel.predict(point.features)), point.label))</div><div class="line"></div><div class="line">metrics = BinaryClassificationMetrics(scoreAndLabels)</div><div class="line">print &apos;Area under PR: %2.4f%%, Area under ROC: %2.4f%%&apos; % \</div><div class="line">    (metrics.areaUnderPR * 100, metrics.areaUnderROC * 100)</div></pre></td></tr></table></figure>
<p>预测值：1, 真实值：0</p>
<p>   逻辑回归准确率： 0.514672075727</p>
<p>   Area under PR: 75.6759%, Area under ROC: 50.1418%</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"># 训练SVM模型</div><div class="line">svmModel = SVMWithSGD.train(data, numIterations)</div><div class="line"></div><div class="line"># 使用SVM模型</div><div class="line">prediction = svmModel.predict(dataPoint.features)</div><div class="line">print &quot;预测值：%d, 真实值：%d&quot; % (prediction, dataPoint.label)</div><div class="line"></div><div class="line"># 看看SVM整体的预测结果</div><div class="line">predictionsAndRealities = data.map(lambda point: svmModel.predict(point.features) == point.label)</div><div class="line"></div><div class="line"># 计算SVM的准确率</div><div class="line">svmTotalCorrect = data.map(lambda point :</div><div class="line">                         1 if svmModel.predict(point.features) == point.label else 0</div><div class="line">                         ).sum()</div><div class="line">svmAccuracy = float(svmTotalCorrect) / data.count()</div><div class="line">print &quot;SVM准确率：&quot;, svmAccuracy</div><div class="line"></div><div class="line"># 计算PR(准确率-召回率)曲线下面积， 以及ROC(受试者工作特征曲线， 真阳性率-假阳性率)曲线下面积即AUC</div><div class="line">scoreAndLabels = data.map(lambda point: (float(svmModel.predict(point.features)), point.label))</div><div class="line"></div><div class="line">metrics = BinaryClassificationMetrics(scoreAndLabels)</div><div class="line">print &apos;Area under PR: %2.4f%%, Area under ROC: %2.4f%%&apos; % \</div><div class="line">    (metrics.areaUnderPR * 100, metrics.areaUnderROC * 100)</div></pre></td></tr></table></figure>
<p>   预测值：1, 真实值：0</p>
<p>   SVM准确率： 0.514672075727</p>
<p>   Area under PR: 75.6759%, Area under ROC: 50.1418%</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"># 训练朴素贝叶斯模型</div><div class="line">nbModel = NaiveBayes.train(data)</div><div class="line"></div><div class="line"># 使用朴素贝叶斯模型</div><div class="line">prediction = nbModel.predict(dataPoint.features)</div><div class="line">print &quot;预测值：%d, 真实值：%d&quot; % (prediction, dataPoint.label)</div><div class="line"></div><div class="line"># 看看朴素贝叶斯整体的预测结果</div><div class="line">predictionsAndRealities = data.map(lambda point: nbModel.predict(point.features) == point.label)</div><div class="line"></div><div class="line"># 计算朴素贝叶斯的准确率</div><div class="line">nbTotalCorrect = data.map(lambda point :</div><div class="line">                         1 if nbModel.predict(point.features) == point.label else 0</div><div class="line">                         ).sum()</div><div class="line">nbAccuracy = float(nbTotalCorrect) / data.count()</div><div class="line">print &quot;朴素贝叶斯准确率：&quot;, nbAccuracy</div><div class="line"></div><div class="line"># 计算PR(准确率-召回率)曲线下面积， 以及ROC(受试者工作特征曲线， 真阳性率-假阳性率)曲线下面积即AUC</div><div class="line">from pyspark.mllib.evaluation import BinaryClassificationMetrics</div><div class="line">scoreAndLabels = data.map(lambda point: (float(nbModel.predict(point.features)), point.label))</div><div class="line"></div><div class="line">metrics = BinaryClassificationMetrics(scoreAndLabels)</div><div class="line">print &apos;Area under PR: %2.4f%%, Area under ROC: %2.4f%%&apos; % \</div><div class="line">    (metrics.areaUnderPR * 100, metrics.areaUnderROC * 100)</div></pre></td></tr></table></figure>
<p>   预测值：1, 真实值：0</p>
<p>   朴素贝叶斯准确率： 0.580392156863</p>
<p>   Area under PR: 68.0851%, Area under ROC: 58.3559%</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"># 训练决策树模型</div><div class="line">dtModel = DecisionTree.trainClassifier(data, 2, &#123;&#125;)</div><div class="line"></div><div class="line"># 使用决策树模型</div><div class="line">prediction = dtModel.predict(dataPoint.features)</div><div class="line">print &quot;预测值：%d, 真实值：%d&quot; % (prediction, dataPoint.label)</div><div class="line"></div><div class="line"># 看看决策树整体的预测结果, 决策树模型只能在主节点上使用</div><div class="line">predictions = dtModel.predict(data.map(lambda point: point.features))</div><div class="line">results = predictions.zip(data.map(lambda point: point.label))</div><div class="line"></div><div class="line"># 计算决策树的准确率</div><div class="line">dtTotalCorrect = results.filter(lambda (real, pred): pred == real).count()</div><div class="line">dtAccuracy = float(dtTotalCorrect) / data.count()</div><div class="line">print &quot;决策树准确率：&quot;, dtAccuracy</div><div class="line"></div><div class="line"># 计算PR(准确率-召回率)曲线下面积， 以及ROC(受试者工作特征曲线， 真阳性率-假阳性率)曲线下面积即AUC</div><div class="line">metrics = BinaryClassificationMetrics(results)</div><div class="line">print &apos;Area under PR: %2.4f%%, Area under ROC: %2.4f%%&apos; % \</div><div class="line">    (metrics.areaUnderPR * 100, metrics.areaUnderROC * 100)</div></pre></td></tr></table></figure>
<p>   预测值：0, 真实值：0</p>
<p>   决策树准确率： 0.648275862069</p>
<p>   Area under PR: 74.2894%, Area under ROC: 64.8916%</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"># 上面的结果跟随机差不多，原因是我们仅仅只是把数据送入模型</div><div class="line"># 改进模型性能以及参数调优</div><div class="line"></div><div class="line"># from pyspark.mllib.linalg.distributed import RowMatrix</div><div class="line"></div><div class="line">matrix = data.map(lambda point: point.features)</div><div class="line">print &quot;矩阵的第一行：\n&quot;, matrix.first()</div><div class="line"></div><div class="line">result = matrix.stats()</div><div class="line">print &quot;矩阵各列的平均值：\n&quot;, result.mean()</div><div class="line">print &quot;矩阵各列的最小值：\n&quot;, result.min()</div><div class="line">print &quot;矩阵各列的最大值：\n&quot;, result.max()</div><div class="line">print &quot;矩阵各列的标准差：\n&quot;, result.stdev()</div><div class="line">print &quot;矩阵各列的方差：\n&quot;, result.variance()</div></pre></td></tr></table></figure>
<p>   矩阵的第一行：<br>    [0.789131,2.055555556,0.676470588,0.205882353,0.047058824,0.023529412,0.443783175,0.0,0.0,0.09077381,0.0,0.245831182,0.003883495,1.0,1.0,24.0,0.0,5424.0,170.0,8.0,0.152941176,0.079129575]</p>
<p>   矩阵各列的平均值：<br>    [0.412258052995,2.76182319199,0.468230473286,0.214079926384,0.092062360719,0.0492621604391,2.25510345221,0.000914886880189,0.0,0.0564227449842,0.02123056119,0.233778176655,0.369015325398,0.615551048005,0.66031102096,30.0770791075,0.0397565922921,5716.59824206,178.754563895,4.96064908722,0.17286405047,0.101220791893]</p>
<p>   矩阵各列的最小值：</p>
<p>   [ 0.          0.          0.          0.          0.          0.          0.</p>
<pre><code>0.          0.          0.          0.          0.04556422  0.          0.
0.          0.          0.          0.          1.          0.          0.
0.        ]
</code></pre><p>   矩阵各列的最大值：</p>
<p>   [  9.99426000e-01   3.63000000e+02   1.00000000e+00   1.00000000e+00<br>       9.80392157e-01   9.80392157e-01   2.10000000e+01   2.50000000e-01<br>       0.00000000e+00   4.44444444e-01   1.00000000e+00   7.16883117e-01<br>       1.13333333e+02   1.00000000e+00   1.00000000e+00   1.00000000e+02<br>       1.00000000e+00   2.07952000e+05   4.99700000e+03   2.20000000e+01<br>       1.00000000e+00   1.00000000e+00]</p>
<p>   矩阵各列的标准差：</p>
<p>   [  3.31251568e-01   8.61920979e+00   2.03119645e-01   1.46732834e-01<br>       9.59717238e-02   7.26238264e-02   5.70392733e+00   7.42829375e-03<br>       0.00000000e+00   4.14428371e-02   1.44152088e-01   5.24830153e-02<br>       1.87878356e+00   4.86464752e-01   4.73603607e-01   2.03917219e+01<br>       1.95386810e-01   8.87483231e+03   1.79454063e+02   3.23289275e+00<br>       1.83273269e-01   7.92255262e-02]</p>
<p>   矩阵各列的方差：<br>    [0.109727601589,74.2907773273,0.041257590017,0.0215305244407,0.00921057176901,0.00527422015895,32.5347869854,5.51795480353e-05,0.0,0.00171750875055,0.0207798244616,0.00275446689512,3.52982764865,0.236647955305,0.224300376559,415.822321151,0.0381760056614,78762648.5733,32203.7608565,10.4515955219,0.0335890912886,0.00627668399539]</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">from pyspark.mllib.feature import StandardScaler</div><div class="line"></div><div class="line"># 第一个True表示均值正则化（每个值减去均值），第二个True表示正则化标准差（每个值除以标准差进行缩放）</div><div class="line">scaler = StandardScaler(withMean=True, withStd=True).fit(matrix)</div><div class="line">scaledData = scaler.transform(matrix)</div><div class="line">scaledData = data.map(lambda lp: lp.label).zip(scaledData).map(lambda (label, feature): LabeledPoint(label, feature))</div><div class="line"></div><div class="line">print &quot;标准化前：\n&quot;, data.first().features</div><div class="line">print &quot;标准化后：\n&quot;, scaledData.first().features</div><div class="line"></div><div class="line">import numpy as np</div><div class="line">vector = np.array(matrix.first())</div><div class="line">mean = np.array(result.mean())</div><div class="line">stdev = np.array(result.stdev())</div><div class="line">print &quot;手动标准化：\n&quot;, (vector - mean) / stdev</div></pre></td></tr></table></figure>
<p>   标准化前：<br>    [0.789131,2.055555556,0.676470588,0.205882353,0.047058824,0.023529412,0.443783175,0.0,0.0,0.09077381,0.0,0.245831182,0.003883495,1.0,1.0,24.0,0.0,5424.0,170.0,8.0,0.152941176,0.079129575]</p>
<p>   标准化后：<br>    [1.1376473365,-0.0819355716929,1.02513981289,-0.0558635644254,-0.468893253129,-0.354305326308,-0.317535217236,-0.123154125351,0.0,0.828822173315,-0.147268943346,0.229639823578,-0.194331667814,0.790238049918,0.717194729453,-0.297996816496,-0.20346257793,-0.0329672096969,-0.0487811297558,0.940069975117,-0.108698488525,-0.278820782314]</p>
<p>   手动标准化：</p>
<p>   [ 1.13772426 -0.08194111  1.02520913 -0.05586734 -0.46892496 -0.35432928<br>     -0.31755669 -0.12316245         nan  0.82887822 -0.1472789   0.22965535<br>     -0.19434481  0.79029149  0.71724323 -0.29801697 -0.20347634 -0.03296944<br>     -0.04878443  0.94013354 -0.10870584 -0.27883964]</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"># 用标准化后的数据重新训练模型，不训练决策树和朴素贝叶斯，因为他俩不受特征标准化的影响</div><div class="line"></div><div class="line"># 训练逻辑回归模型</div><div class="line">lrModelScaled = LogisticRegressionWithSGD.train(scaledData, numIterations)</div><div class="line"></div><div class="line"># 看看逻辑回归整体的预测结果</div><div class="line">lrTotalCorrectScaled = scaledData.filter(lambda point: lrModelScaled.predict(point.features) == point.label).count()</div><div class="line">print &quot;预测正确的样本个数&quot;, lrTotalCorrectScaled</div><div class="line"></div><div class="line"># 计算逻辑回归的准确率</div><div class="line">lrAccuracyScaled = float(lrTotalCorrectScaled) / data.count()</div><div class="line">print &quot;逻辑回归准确率：&quot;, lrAccuracyScaled</div><div class="line"></div><div class="line"># 计算PR(准确率-召回率)曲线下面积， 以及ROC(受试者工作特征曲线， 真阳性率-假阳性率)曲线下面积即AUC</div><div class="line">lrPredictionsVsTrue = scaledData.map(lambda point: (float(lrModelScaled.predict(point.features)), point.label))</div><div class="line">lrMetricsScaled = BinaryClassificationMetrics(lrPredictionsVsTrue)</div><div class="line">print &apos;Area under PR: %2.4f%%, Area under ROC: %2.4f%%&apos; % \</div><div class="line">    (lrMetricsScaled.areaUnderPR * 100, lrMetricsScaled.areaUnderROC * 100)</div></pre></td></tr></table></figure>
<p>   预测正确的样本个数 4609</p>
<p>   逻辑回归准确率： 0.623258958756</p>
<p>   Area under PR: 73.0204%, Area under ROC: 62.2292%</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"># 考虑网页的类别特征，比如这个网页是属于sports类还是business类</div><div class="line">categories = dict(records.map(lambda record: record[3].replace(&apos;\&quot;&apos;, &apos;&apos;)).distinct().zipWithIndex().collect())</div><div class="line">print categories</div><div class="line">numCategories = len(categories)</div><div class="line">print numCategories</div><div class="line"></div><div class="line">categories = sc.broadcast(categories)</div><div class="line">numCategories = sc.broadcast(numCategories)</div></pre></td></tr></table></figure>
<p>   {u’gaming’: 7, u’recreation’: 0, u’business’: 1, u’computer_internet’: 2, u’unknown’: 8, u’culture_politics’: 3, u’science_technology’: 9, u’law_crime’: 4, u’sports’: 10, u’religion’: 11, u’weather’: 12, u’health’: 5, u’?’: 6, u’arts_entertainment’: 13}<br>    14</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">def buildCategoriesVector(data):</div><div class="line">    vector = [0] * numCategories.value</div><div class="line">    vector[categories.value[data[3]]] = 1</div><div class="line">    return vector + data[4:-1]</div><div class="line">    </div><div class="line">sizeAndData = records.map(lambda record : (len(record), map(lambda e: e.replace(&apos;\&quot;&apos;, &apos;&apos;), record)))</div><div class="line">labelAndFeature = sizeAndData.map(lambda (size, data): (int(data[-1]), map(lambda d: 0.0 if d == &apos;?&apos; else float(d), buildCategoriesVector(data))))</div><div class="line">dataCategories = labelAndFeature.map(lambda (label, feature): LabeledPoint(label, Vectors.dense(map(lambda d: 0.0 if d &lt; 0 else d, feature))))</div><div class="line">dataPointCats = dataCategories.first()</div><div class="line">print labelAndFeature.first()</div><div class="line">print dataPointCats</div></pre></td></tr></table></figure>
<p>   (0, [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.789131, 2.055555556, 0.676470588, 0.205882353, 0.047058824, 0.023529412, 0.443783175, 0.0, 0.0, 0.09077381, 0.0, 0.245831182, 0.003883495, 1.0, 1.0, 24.0, 0.0, 5424.0, 170.0, 8.0, 0.152941176, 0.079129575])</p>
<p>(0.0,[0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.789131,2.055555556,0.676470588,0.205882353,0.047058824,0.023529412,0.443783175,0.0,0.0,0.09077381,0.0,0.245831182,0.003883495,1.0,1.0,24.0,0.0,5424.0,170.0,8.0,0.152941176,0.079129575])</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># 标准化转换</div><div class="line">labels = dataCategories.map(lambda lp: lp.label)</div><div class="line">featuresMatrix = dataCategories.map(lambda lp: lp.features)</div><div class="line">scalerCats = StandardScaler(withMean=True, withStd=True).fit(featuresMatrix)</div><div class="line">scaledDataCats = scalerCats.transform(featuresMatrix).zip(labels).map(lambda (features, label): LabeledPoint(label, features))</div><div class="line">scaledDataCats.first()</div></pre></td></tr></table></figure>
<p>   LabeledPoint(0.0, [-0.446421204794,2.72073665645,-0.204182210579,-0.220526884579,-0.0648775723926,-0.270999069693,-0.680752790425,-0.101894690972,-0.028494000387,-0.201654052319,-0.232727977095,-0.0991499193088,-0.0232621058984,-0.381813223243,1.1376473365,-0.0819355716929,1.02513981289,-0.0558635644254,-0.468893253129,-0.354305326308,-0.317535217236,-0.123154125351,0.0,0.828822173315,-0.147268943346,0.229639823578,-0.194331667814,0.790238049918,0.717194729453,-0.297996816496,-0.20346257793,-0.0329672096969,-0.0487811297558,0.940069975117,-0.108698488525,-0.278820782314])</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">lrModelScaledCats = LogisticRegressionWithSGD.train(scaledDataCats, numIterations)</div><div class="line"></div><div class="line"># 看看逻辑回归整体的预测结果</div><div class="line">lrTotalCorrectScaledCats = scaledDataCats.filter(lambda point: lrModelScaledCats.predict(point.features) == point.label).count()</div><div class="line">print &quot;预测正确的样本个数&quot;, lrTotalCorrectScaledCats</div><div class="line"></div><div class="line"># 计算逻辑回归的准确率</div><div class="line">lrAccuracyScaledCats = float(lrTotalCorrectScaledCats) / scaledDataCats.count()</div><div class="line">print &quot;逻辑回归准确率：&quot;, lrAccuracyScaledCats</div><div class="line"></div><div class="line"># 计算PR(准确率-召回率)曲线下面积， 以及ROC(受试者工作特征曲线， 真阳性率-假阳性率)曲线下面积即AUC</div><div class="line">lrPredictionsVsTrue = scaledDataCats.map(lambda point: (float(lrModelScaledCats.predict(point.features)), point.label))</div><div class="line">lrMetricsScaledCats = BinaryClassificationMetrics(lrPredictionsVsTrue)</div><div class="line">print &apos;Area under PR: %2.4f%%, Area under ROC: %2.4f%%&apos; % \</div><div class="line">    (lrMetricsScaledCats.areaUnderPR * 100, lrMetricsScaledCats.areaUnderROC * 100)</div></pre></td></tr></table></figure>
<p>   预测正确的样本个数 4928</p>
<p>   逻辑回归准确率： 0.666396213658</p>
<p>   Area under PR: 75.8535%, Area under ROC: 66.6127%</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"># 只使用1-of-k编码的类别特征</div><div class="line">def onlyCategoriesVector(data):</div><div class="line">    vector = [0] * numCategories.value</div><div class="line">    vector[categories.value[data[3]]] = 1</div><div class="line">    return vector</div><div class="line">    </div><div class="line">sizeAndData = records.map(lambda record : (len(record), map(lambda e: e.replace(&apos;\&quot;&apos;, &apos;&apos;), record)))</div><div class="line">labelAndFeature = sizeAndData.map(lambda (size, data): \</div><div class="line">                                  (int(data[-1]), map(lambda d: 0.0 if d == &apos;?&apos; else float(d), onlyCategoriesVector(data))))</div><div class="line">dataNB = labelAndFeature.map(lambda (label, feature): \</div><div class="line">                             LabeledPoint(label, Vectors.dense(map(lambda d: 0.0 if d &lt; 0 else d, feature))))</div><div class="line"></div><div class="line"># 训练朴素贝叶斯模型</div><div class="line">nbModelCats = NaiveBayes.train(dataNB)</div><div class="line"></div><div class="line"># 计算朴素贝叶斯的准确率</div><div class="line">nbTotalCorrectCats = dataNB.map(lambda point :</div><div class="line">                         1 if nbModelCats.predict(point.features) == point.label else 0</div><div class="line">                         ).sum()</div><div class="line">nbAccuracyCats = float(nbTotalCorrectCats) / dataNB.count()</div><div class="line">print &quot;朴素贝叶斯准确率：&quot;, nbAccuracyCats</div><div class="line"></div><div class="line">nbPredictionsVsTrueCats = dataNB.map(lambda point: (float(nbModelCats.predict(point.features)), point.label))</div><div class="line">nbMetricsCats = BinaryClassificationMetrics(nbPredictionsVsTrueCats)</div><div class="line">print &apos;Area under PR: %2.4f%%, Area under ROC: %2.4f%%&apos; % \</div><div class="line">    (nbMetricsCats.areaUnderPR * 100, nbMetricsCats.areaUnderROC * 100)</div></pre></td></tr></table></figure>
<p>   朴素贝叶斯准确率： 0.609601081812</p>
<p>   Area under PR: 74.0522%, Area under ROC: 60.5138%</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2015/10/18/构建基于Spark的推荐引擎(python实现)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yiyang Peng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/7233064.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yiyang's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2015/10/18/构建基于Spark的推荐引擎(python实现)/" itemprop="url">构建基于Spark的小推荐系统demo</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2015-10-18T21:28:00+08:00">
                2015-10-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>这几天在看由人民邮电出版社出版的《Spark机器学习》（Machine Learning with Spark，Nick Pentreath），看的很是郁闷。这本书一会儿用python, 一会儿用scala。由于我很喜欢用python, 所以用Python把这本书的scala代码又实现了一遍。收获很大，比直接对着书敲scala要理解的更多，对整个推荐过程的理解更加深刻。当然，与实际应用中的推荐系统相比，这只是个玩具而已。</p>
<p>以下为我的python代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">rawData = sc.textFile(<span class="string">"hdfs:///user/yy/ml-100k/u.data"</span>)</div><div class="line">rawData.first()</div></pre></td></tr></table></figure>
<p>u’196\t242\t3\t881250949’<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 取出数据，仅需要用户、电影、评分</span></div><div class="line">rawRatings = rawData.map(<span class="keyword">lambda</span> line: line.split(<span class="string">'\t'</span>)[<span class="number">0</span>:<span class="number">3</span>])</div><div class="line">rawRatings.first()</div></pre></td></tr></table></figure></p>
<p>[u’196’, u’242’, u’3’]<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pyspark.mllib.recommendation <span class="keyword">as</span> rd</div><div class="line"></div><div class="line"><span class="comment"># 由于ALS模型需要由Rating记录构成的RDD作为参数，因此这里用rd.Rating方法封装数据</span></div><div class="line">ratings = rawRatings.map(<span class="keyword">lambda</span> (user, movie, rating): rd.Rating(int(user), int(movie), float(rating)))</div><div class="line">ratings.first()</div></pre></td></tr></table></figure></p>
<p>Rating(user=196, product=242, rating=3.0)<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 训练ALS模型</span></div><div class="line">model = rd.ALS.train(ratings, <span class="number">50</span>, <span class="number">10</span>, <span class="number">0.01</span>)</div><div class="line">model.userFeatures</div></pre></td></tr></table></figure></p>
<p><bound method="" matrixfactorizationmodel.userfeatures="" of="" <pyspark.mllib.recommendation.matrixfactorizationmodel="" object="" at="" 0x7f68d9b3fbd0="">&gt;<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 利用该模型预测789用户对123电影的评分</span></div><div class="line">predictedRating = model.predict(<span class="number">789</span>, <span class="number">123</span>)</div><div class="line"><span class="keyword">print</span> predictedRating</div></pre></td></tr></table></figure></bound></p>
<p>3.00704909501</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 给789用户推荐的前10个商品</span></div><div class="line">topKRecs = model.recommendProducts(<span class="number">789</span>, <span class="number">10</span>)</div><div class="line">topKRecs</div></pre></td></tr></table></figure>
<p>[Rating(user=789, product=708, rating=5.645492560638761),<br>     Rating(user=789, product=482, rating=5.632324542725622),<br>     Rating(user=789, product=502, rating=5.621572563993868),<br>     Rating(user=789, product=603, rating=5.5589276689720055),<br>     Rating(user=789, product=23, rating=5.552174994200555),<br>     Rating(user=789, product=182, rating=5.429093418196553),<br>     Rating(user=789, product=484, rating=5.424060744309293),<br>     Rating(user=789, product=479, rating=5.416303074919905),<br>     Rating(user=789, product=1020, rating=5.350687998038177),<br>     Rating(user=789, product=494, rating=5.341673625528914)]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">movies = sc.textFile(<span class="string">'hdfs:///user/yy/ml-100k/u.item'</span>)</div><div class="line">movies.first()</div></pre></td></tr></table></figure>
<p>u’1|Toy Story (1995)|01-Jan-1995||<a href="http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0" target="_blank" rel="external">http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0</a>‘</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">movies_fields = movies.map(<span class="keyword">lambda</span> line: line.split(<span class="string">'|'</span>))</div><div class="line">title_data = movies_fields.map(<span class="keyword">lambda</span> fields: (int(fields[<span class="number">0</span>]), fields[<span class="number">1</span>])).collect()</div><div class="line">titles = dict(title_data)</div><div class="line">titles[<span class="number">123</span>]</div></pre></td></tr></table></figure>
<p>u’Frighteners, The (1996)’</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># keyBy从ratings RDD创建一个键值对RDD，选取user为主键</span></div><div class="line"><span class="comment"># lookup返回给定键的数据</span></div><div class="line">moviesForUser = ratings.keyBy(<span class="keyword">lambda</span> rating: rating.user).lookup(<span class="number">789</span>) <span class="comment"># 返回的是list</span></div><div class="line">moviesForUser[<span class="number">0</span>:<span class="number">10</span>] <span class="comment"># 结果为789对他看过的电影给出的评分</span></div></pre></td></tr></table></figure>
<p>[Rating(user=789, product=1012, rating=4.0),<br>     Rating(user=789, product=127, rating=5.0),<br>     Rating(user=789, product=475, rating=5.0),<br>     Rating(user=789, product=93, rating=4.0),<br>     Rating(user=789, product=1161, rating=3.0),<br>     Rating(user=789, product=286, rating=1.0),<br>     Rating(user=789, product=293, rating=4.0),<br>     Rating(user=789, product=9, rating=5.0),<br>     Rating(user=789, product=50, rating=5.0),<br>     Rating(user=789, product=294, rating=3.0)]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># sorted(list, key=lambda..., reverse=True)是对list的排序函数</span></div><div class="line"><span class="comment"># sc.parallelize(data)并行化数据，转换为rdd后才能用map方法</span></div><div class="line">moviesForUser = sorted(moviesForUser, key=<span class="keyword">lambda</span> r: r.rating, reverse=<span class="keyword">True</span>)[<span class="number">0</span>:<span class="number">10</span>]</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[(titles[r.product], r.rating) <span class="keyword">for</span> r <span class="keyword">in</span> moviesForUser]</div></pre></td></tr></table></figure>
<p>[(u’Godfather, The (1972)’, 5.0),<br>     (u’Trainspotting (1996)’, 5.0),<br>     (u’Dead Man Walking (1995)’, 5.0),<br>     (u’Star Wars (1977)’, 5.0),<br>     (u’Swingers (1996)’, 5.0),<br>     (u’Leaving Las Vegas (1995)’, 5.0),<br>     (u’Bound (1996)’, 5.0),<br>     (u’Fargo (1996)’, 5.0),<br>     (u’Last Supper, The (1995)’, 5.0),<br>     (u’Private Parts (1997)’, 4.0)]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[(titles[r.product], r.rating) <span class="keyword">for</span> r <span class="keyword">in</span> topKRecs]</div></pre></td></tr></table></figure>
<p>[(u’Sex, Lies, and Videotape (1989)’, 5.645492560638761),<br>     (u’Some Like It Hot (1959)’, 5.632324542725622),<br>     (u’Bananas (1971)’, 5.621572563993868),<br>     (u’Rear Window (1954)’, 5.5589276689720055),<br>     (u’Taxi Driver (1976)’, 5.552174994200555),<br>     (u’GoodFellas (1990)’, 5.429093418196553),<br>     (u’Maltese Falcon, The (1941)’, 5.424060744309293),<br>     (u’Vertigo (1958)’, 5.416303074919905),<br>     (u’Gaslight (1944)’, 5.350687998038177),<br>     (u’His Girl Friday (1940)’, 5.341673625528914)]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">itemId = <span class="number">567</span></div><div class="line">itemVec = model.productFeatures().lookup(itemId)[<span class="number">0</span>]</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> scipy.spatial.distance <span class="keyword">import</span> cosine</div><div class="line"></div><div class="line"><span class="comment"># cosine函数实际上是是求1-cosine,便于我们后面的排序，对1-cosine从小到大排等价于对cosine从大到小排</span></div><div class="line">sims = model.productFeatures().map(<span class="keyword">lambda</span> (id, factorVec): (id, cosine(factorVec, itemVec)))</div><div class="line">sims.first()</div></pre></td></tr></table></figure>
<p>(16, 0.48041293748773517)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sortedSims = sims.sortBy(<span class="keyword">lambda</span> s: s[<span class="number">1</span>]).take(<span class="number">10</span>)</div><div class="line">sortedSims</div></pre></td></tr></table></figure>
<p>[(567, 0.0),<br>     (413, 0.27774090532944073),<br>     (24, 0.28293701045346031),<br>     (184, 0.29302471333565439),<br>     (352, 0.29389332298954041),<br>     (1376, 0.30311195834153437),<br>     (201, 0.30636099292020724),<br>     (741, 0.31300444242427816),<br>     (685, 0.31398875037205187),<br>     (686, 0.31444575073270353)]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> titles[itemId]</div><div class="line">[(titles[id], sim) <span class="keyword">for</span> (id, sim) <span class="keyword">in</span> sortedSims]</div></pre></td></tr></table></figure>
<p>Wes Craven’s New Nightmare (1994)</p>
<p>[(u”Wes Craven’s New Nightmare (1994)”, 0.0),<br>     (u’Tales from the Crypt Presents: Bordello of Blood (1996)’,<br>      0.27774090532944073),<br>     (u’Rumble in the Bronx (1995)’, 0.28293701045346031),<br>     (u’Army of Darkness (1993)’, 0.29302471333565439),<br>     (u’Spice World (1997)’, 0.29389332298954041),<br>     (u’Meet Wally Sparks (1997)’, 0.30311195834153437),<br>     (u’Evil Dead II (1987)’, 0.30636099292020724),<br>     (u’Last Supper, The (1995)’, 0.31300444242427816),<br>     (u’Executive Decision (1996)’, 0.31398875037205187),<br>     (u’Perfect World, A (1993)’, 0.31444575073270353)]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">actualRating = moviesForUser[<span class="number">0</span>]</div><div class="line">predictedRating = model.predict(<span class="number">789</span>, actualRating.product)</div><div class="line">squaredError = (actualRating.rating - predictedRating) ** <span class="number">2</span></div><div class="line"><span class="keyword">print</span> <span class="string">"实际评分: %f, 预测评分: %f, 方差: %f. "</span> % (actualRating.rating, predictedRating, squaredError)</div></pre></td></tr></table></figure>
<p>实际评分: 5.000000, 预测评分: 5.042951, 方差: 0.001845. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">usersProducts = ratings.map(<span class="keyword">lambda</span> r: (r.user, r.product))</div><div class="line"><span class="comment"># predictAll方法以对(int, int)形式的rdd作为参数，这点与scala不同，scala直接用predict</span></div><div class="line">predictions = model.predictAll(usersProducts).map(<span class="keyword">lambda</span> r: ((r.user, r.product), r.rating))</div><div class="line">predictions.first()</div></pre></td></tr></table></figure>
<p>((368, 320), 4.883538186965982)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 形成一个(user, movie)做主键，(实际评分，预测评分)做值的rdd</span></div><div class="line">ratingsAndPredictions = ratings.map(<span class="keyword">lambda</span> r: ((r.user, r.product), r.rating)).join(predictions)</div><div class="line">ratingsAndPredictions.first()</div></pre></td></tr></table></figure>
<p>((506, 568), (5.0, 4.512168968112584))</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># MSE = ratingsAndPredictions.map(lambda ((user, product), (actual, predicted)): (actual - predicted) ** 2)\</span></div><div class="line"><span class="comment"># .reduce(lambda x,y: x + y) / ratingsAndPredictions.count()</span></div><div class="line"><span class="comment"># 用sum()和reduce(lambda x,y: x+y)是一样的</span></div><div class="line">MSE = ratingsAndPredictions.map(<span class="keyword">lambda</span> ((user, product), (actual, predicted)): (actual - predicted) ** <span class="number">2</span>).sum() \</div><div class="line">/ ratingsAndPredictions.count()</div><div class="line"><span class="keyword">print</span> <span class="string">"Mean Squared Error ="</span>, MSE</div><div class="line"></div><div class="line"><span class="keyword">import</span> math</div><div class="line">RMSE = math.sqrt(MSE)</div><div class="line"><span class="keyword">print</span> <span class="string">"Root Mean Squared Error ="</span>, RMSE</div></pre></td></tr></table></figure>
<p>Mean Squared Error = 0.0839340560353<br>    Root Mean Squared Error = 0.28971374844</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 计算APK(Average Precision at K metric)K值平均准确率</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">avgPrecisionK</span><span class="params">(actual, predicted, k)</span>:</span></div><div class="line">    predK = predicted[<span class="number">0</span>:k]</div><div class="line">    score = <span class="number">0.0</span></div><div class="line">    numHits = <span class="number">0.0</span></div><div class="line">    <span class="keyword">for</span> i, p <span class="keyword">in</span> enumerate(predK):</div><div class="line">        <span class="keyword">if</span>(p <span class="keyword">in</span> actual):</div><div class="line">            numHits += <span class="number">1</span></div><div class="line">            score += numHits / float(i + <span class="number">1</span>)</div><div class="line">    <span class="keyword">if</span>(len(actual) == <span class="number">0</span>):</div><div class="line">        <span class="keyword">return</span> <span class="number">1.0</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> score / float(min(len(actual), k))</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">actualMovies = [mu.product <span class="keyword">for</span> mu <span class="keyword">in</span> moviesForUser]</div><div class="line"><span class="keyword">print</span> actualMovies</div></pre></td></tr></table></figure>
<p>[127, 475, 9, 50, 150, 276, 129, 100, 741, 1012]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">predictedMovies = [tkr.product <span class="keyword">for</span> tkr <span class="keyword">in</span> topKRecs]</div><div class="line"><span class="keyword">print</span> predictedMovies</div></pre></td></tr></table></figure>
<p>[708, 482, 502, 603, 23, 182, 484, 479, 1020, 494]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">apk10 = avgPrecisionK(actualMovies, predictedMovies, <span class="number">10</span>)</div><div class="line"><span class="keyword">print</span> apk10</div><div class="line"><span class="comment"># 这里APK得分为0，表明模型在维该用户做相关电影预测上的表现并不理想</span></div></pre></td></tr></table></figure>
<p>0.0</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line">itemFactors = model.productFeatures().map(<span class="keyword">lambda</span> (id, factor): factor).collect()</div><div class="line">itemMatrix = np.array(itemFactors)</div><div class="line"><span class="keyword">print</span> itemMatrix.shape</div></pre></td></tr></table></figure>
<p>(1682, 50)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">imBroadcast = sc.broadcast(itemMatrix)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">scoresForUser = model.userFeatures().map(<span class="keyword">lambda</span> (userId, array): (userId, np.dot(imBroadcast.value, array)))</div><div class="line">allRecs = scoresForUser.map(<span class="keyword">lambda</span> (userId, scores): </div><div class="line">                            (userId, sorted(zip(np.arange(<span class="number">1</span>, scores.size), scores), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="keyword">True</span>))</div><div class="line">                           ).map(<span class="keyword">lambda</span> (userId, sortedScores): (userId, np.array(sortedScores, dtype=int)[:,<span class="number">0</span>]))</div><div class="line"><span class="keyword">print</span> allRecs.first()[<span class="number">0</span>]</div><div class="line"><span class="keyword">print</span> allRecs.first()[<span class="number">1</span>]</div></pre></td></tr></table></figure>
<p>16<br>    [1274  453  135 …,  631  412   96]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># groupByKey返回(int, ResultIterable), 其中ResultIterable.data才是数据</span></div><div class="line">userMovies = ratings.map(<span class="keyword">lambda</span> r: (r.user, r.product)).groupByKey()</div><div class="line"><span class="keyword">print</span> userMovies.first()[<span class="number">0</span>]</div><div class="line"><span class="keyword">print</span> userMovies.first()[<span class="number">1</span>].data</div></pre></td></tr></table></figure>
<p>2<br>    [237, 300, 100, 127, 285, 289, 304, 272, 278, 288, 286, 275, 302, 296, 292, 251, 50, 314, 297, 290, 312, 281, 13, 280, 303, 308, 307, 257, 316, 315, 301, 313, 279, 299, 298, 19, 277, 282, 111, 258, 295, 242, 283, 276, 1, 305, 14, 287, 291, 293, 294, 310, 309, 306, 25, 273, 10, 311, 269, 255, 284, 274]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">K = <span class="number">10</span></div><div class="line">MAPK = allRecs.join(userMovies).map(<span class="keyword">lambda</span> (userId, (predicted, actual)):</div><div class="line">                                    avgPrecisionK(actual.data, predicted, K)</div><div class="line">                                   ).sum() / allRecs.count()</div><div class="line"><span class="keyword">print</span> <span class="string">"Mean Average Precision at K ="</span>, MAPK</div></pre></td></tr></table></figure>
<p>Mean Average Precision at K = 0.024641131815</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 使用MLlib内置的评估函数计算MSE,RMSE</span></div><div class="line"><span class="keyword">from</span> pyspark.mllib.evaluation <span class="keyword">import</span> RegressionMetrics</div><div class="line">predictedAndTrue = ratingsAndPredictions.map(<span class="keyword">lambda</span> ((user, product), (predicted, actual)): (predicted, actual))</div><div class="line">regressionMetrics = RegressionMetrics(predictedAndTrue)</div><div class="line"><span class="keyword">print</span> <span class="string">"Mean Squared Error ="</span>, regressionMetrics.meanSquaredError</div><div class="line"><span class="keyword">print</span> <span class="string">"Root Mean Squared Error ="</span>, regressionMetrics.rootMeanSquaredError</div></pre></td></tr></table></figure>
<p>Mean Squared Error = 0.0839340560353<br>    Root Mean Squared Error = 0.28971374844</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 使用MLlib内置的评估函数计算MAP, 它取所有物品来计算，不是取前K个，因此不用设定K值,故不叫MAPK</span></div><div class="line"><span class="keyword">from</span> pyspark.mllib.evaluation <span class="keyword">import</span> RankingMetrics</div><div class="line">predictedAndTrueForRanking = allRecs.join(userMovies).map(<span class="keyword">lambda</span> (userId, (predicted, actual)):</div><div class="line">                                                        (map(int, list(predicted)), actual.data))</div><div class="line">rankingMetrics = RankingMetrics(predictedAndTrueForRanking)</div><div class="line"><span class="keyword">print</span> <span class="string">"Mean Average Precision ="</span>, rankingMetrics.meanAveragePrecision</div></pre></td></tr></table></figure>
<p>Mean Average Precision = 0.0668399759999</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 用我们自己实现的方法来计算MAPK，当K值较大时，结果同上面一样</span></div><div class="line">K = <span class="number">2000</span></div><div class="line">MAPK2000 = allRecs.join(userMovies).map(<span class="keyword">lambda</span> (userId, (predicted, actual)):</div><div class="line">                                    avgPrecisionK(actual.data, predicted, K)</div><div class="line">                                   ).sum() / allRecs.count()</div><div class="line"><span class="keyword">print</span> <span class="string">"Mean Average Precision at 2000 ="</span>, MAPK2000</div></pre></td></tr></table></figure>
<p>Mean Average Precision at 2000 = 0.0668399759999</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/7233064.jpg"
               alt="Yiyang Peng" />
          <p class="site-author-name" itemprop="name">Yiyang Peng</p>
           
              <p class="site-description motion-element" itemprop="description">Try try try Never mind</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">27</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">27</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/yiyang186" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.zhihu.com/people/peng-yiyang-88" target="_blank" title="知乎">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  知乎
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yiyang Peng</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



  


  




	





  





  






  





  

  

  

  

  

  

</body>
</html>
