<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="Try try try Never mind">
<meta property="og:type" content="website">
<meta property="og:title" content="Yiyang&#39;s Blog">
<meta property="og:url" content="http://yoursite.com/page/3/index.html">
<meta property="og:site_name" content="Yiyang&#39;s Blog">
<meta property="og:description" content="Try try try Never mind">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Yiyang&#39;s Blog">
<meta name="twitter:description" content="Try try try Never mind">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/3/"/>





  <title>Yiyang's Blog</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?3b9de7582df94dad7be13b2e75675386";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->










</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Yiyang's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404.html" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br />
            
            公益404
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/03/23/在vs2008中配置OpenMP/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yiyang Peng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/7233064.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yiyang's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/03/23/在vs2008中配置OpenMP/" itemprop="url">在vs2008中配置OpenMP</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-03-23T11:37:00+08:00">
                2016-03-23
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/操作/" itemprop="url" rel="index">
                    <span itemprop="name">操作</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="在vs2008上编译OpenMP"><a href="#在vs2008上编译OpenMP" class="headerlink" title="在vs2008上编译OpenMP"></a>在vs2008上编译OpenMP</h1><ol>
<li>试了好多方法，感觉直接在vs2008上写最简单，右键点击解决方案下面的项目名，在弹出的右键菜单选择最后一个“属性”。<br><img src="http://img.blog.csdn.net/20160323112356122" alt="这里写图片描述"></li>
<li>依次点击 配置属性 =》C/C++ =》语言，把右侧的OpenMP支持一栏的否改为是。这样你的OpenMP程序就可以编译了。<br><img src="http://img.blog.csdn.net/20160323112557920" alt="这里写图片描述"></li>
<li>如果运行程序时报错，找不到vcomp90.dll或者vcomp90d.dll，那么就到c:\windows\winsxs\目录下搜索vcomp90，并把vcomp90.dll和vcomp90d.dll这两个文件复制到你的项目根目录处，即有.vcproj的目录，而不是最外层的目录。这两个文件也可以到我的网盘下载<br><a href="http://pan.baidu.com/s/1skpWeKH" target="_blank" rel="external">点击进入网盘下载</a><br><img src="http://img.blog.csdn.net/20160323113217567" alt="这里写图片描述"></li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/03/16/为jupyter配置密码/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yiyang Peng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/7233064.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yiyang's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/03/16/为jupyter配置密码/" itemprop="url">为Jupyter配置密码</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-03-16T16:51:00+08:00">
                2016-03-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/操作/" itemprop="url" rel="index">
                    <span itemprop="name">操作</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>在Python中生成密码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">from notebook.auth import passwd</div><div class="line">passwd(&apos;123456&apos;)</div><div class="line">&apos;sha1:1996ed5b2fc6:40da178c53092195aab3e1ce840e8c5c9e335fab&apos;</div></pre></td></tr></table></figure>
<p>修改jupyter配置文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">c = get_config() </div><div class="line">c.NotebookApp.ip = ‘*’ </div><div class="line">c.NotebookApp.password = u’sha1:1996ed5b2fc6:40da178c53092195aab3e1ce840e8c5c9e335fab’ </div><div class="line">c.NotebookApp.open_browser = False </div><div class="line">c.NotebookApp.port = 9999</div></pre></td></tr></table></figure>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/03/06/怎么在mac终端上执行R脚本/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yiyang Peng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/7233064.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yiyang's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/03/06/怎么在mac终端上执行R脚本/" itemprop="url">在mac终端上执行R脚本</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-03-06T10:31:00+08:00">
                2016-03-06
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/操作/" itemprop="url" rel="index">
                    <span itemprop="name">操作</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ol>
<li>创建file.R文件</li>
<li>键入R代码</li>
<li><p>在输出图像（而非保存文本）如png(),jpeg(),…等函数后，一定要加上一行</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">dev.off()</div></pre></td></tr></table></figure>
<p> 关闭虚拟显示设备。</p>
</li>
<li><p>注意将数据处理结果输出到文件</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">write.table(x=df , file=output.csv , sep=&apos;,&apos;, row.names=FALSE, quote=FALSE)</div></pre></td></tr></table></figure>
</li>
</ol>
<ol>
<li>保存成.R文件</li>
<li><p>在工作目录下，在终端中输入以下命令:(xxx是脚本文件名，其他的照抄)</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">R CMD BATCH --args xxx.R</div></pre></td></tr></table></figure>
</li>
<li><p>等待执行结束。用这种方式执行脚本，终端不会输出执行过程代码，这些代码会保存到xxx.Rout文件中</p>
</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/03/01/matplotlib cannot import name _thread on mac/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yiyang Peng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/7233064.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yiyang's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/03/01/matplotlib cannot import name _thread on mac/" itemprop="url">matplotlib cannot import name _thread on mac</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-03-01T19:55:00+08:00">
                2016-03-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/操作/" itemprop="url" rel="index">
                    <span itemprop="name">操作</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>最后的2行错误信息是<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">    from six.moves import _thread</div><div class="line">ImportError: cannot import name _thread</div></pre></td></tr></table></figure></p>
<p>发现是six出现了问题，用pip更新一下six，问题并没有解决，原因是并没有真正更新six的文件。<br>在python下输入：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">import six</div><div class="line">print six.__file__</div></pre></td></tr></table></figure></p>
<p>/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/six.pyc</p>
<p>这是我们的python实际使用的six，而我们手动更新的six却是装在/Library/Python/2.7/site-packages/，我们把six.__file__的文件删除掉，python就只能用我们更新的six了<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo rm -rf /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/six.*</div></pre></td></tr></table></figure></p>
<p>重启ipython/python就行了，如果之前并未有更新six, 应该在这一步中更新six。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo pip install --upgrade six</div></pre></td></tr></table></figure></p>
<p>另外，在很多时候我们希望忽略过去下载的安装包，直接下载安装可以使用–ignore-installed这个参数，比如我发现的的matplotlib的mplot3d部分有点问题，我想再重新下载安装一遍，可以这么做<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo pip install --upgrade --ignore-installed matplotlib</div></pre></td></tr></table></figure></p>
<p>这会把相关的包（numpy, pytz, six, python-dateutil, cycler, pyparsing, matplotlib）都下载安装一遍</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/02/12/4 矩阵分析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yiyang Peng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/7233064.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yiyang's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/02/12/4 矩阵分析/" itemprop="url">矩阵的范数与导数</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-02-12T22:10:00+08:00">
                2016-02-12
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/数学/" itemprop="url" rel="index">
                    <span itemprop="name">数学</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="向量范数"><a href="#向量范数" class="headerlink" title="向量范数"></a>向量范数</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>向量x属于空间V，若有一种实值函数f(x)能将向量x映射为一个实数，记作f(x)=||x||，只要这个实值函数||x||满足<br>1）正定性：           ||x|| ≥ 0<br>2）齐次性：            ||kx|| = |k|||x||（$k \in N$）<br>3）三角不等式：    ||x+y|| ≤ ||x||+||y|| ( x,y均为V空间的向量)<br>那么这个函数||x||就可以用来表征向量x的大小，叫做向量x的范数。凡是满足这三个条件的的实值函数都能当做向量范数。这个有了范数的空间V也叫做赋范线性空间。</p>
<h2 id="常用的向量范数"><a href="#常用的向量范数" class="headerlink" title="常用的向量范数"></a>常用的向量范数</h2><p>p-范数<br>向量$x=(x_1,x_2,...x_n)$, 定义向量x的p-范数为<br>$$||x||_p=(\sum_{i=1}^n|x_i|^p)^{1/p}, 1 \leq p \leq + \infty $$</p>
<table>
<thead>
<tr>
<th>常用的向量范数</th>
<th>求法</th>
</tr>
</thead>
<tbody>
<tr>
<td>$||x||_1$</td>
<td>向量中所有元素的模的和</td>
</tr>
<tr>
<td>$||x||_2$</td>
<td>向量中所有元素的模的平方和，再求和的平方根</td>
</tr>
<tr>
<td>$||x||_p$</td>
<td>向量中所有元素的模的p次幂的和，再对和开p次方</td>
</tr>
<tr>
<td>$||x||_\infty$</td>
<td>向量中所有元素的模的最大值</td>
</tr>
</tbody>
</table>
<h1 id="矩阵范数"><a href="#矩阵范数" class="headerlink" title="矩阵范数"></a>矩阵范数</h1><h2 id="概念-1"><a href="#概念-1" class="headerlink" title="概念"></a>概念</h2><p>定于矩阵A的一个实函数，记作f(A)=||A||，只要这个函数||A||满足<br>1）正定性：            || A || ≥ 0<br>2）齐次性：            ||k A || = |k||| A ||<br>3）三角不等式：    || A +B|| ≤ || A ||+||B||<br>4)  相容性：            ||AB|| ≤ ||A||||B||    （乘积不等式）<br>此时称||A||是矩阵A的范数，如果只满足前3个条件，那只是广义矩阵范数。</p>
<h2 id="几种常见的矩阵范数"><a href="#几种常见的矩阵范数" class="headerlink" title="几种常见的矩阵范数"></a>几种常见的矩阵范数</h2><p><img src="http://img.blog.csdn.net/20160211144645736" alt="这里写图片描述"></p>
<table>
<thead>
<tr>
<th style="text-align:left">常用的矩阵范数</th>
<th style="text-align:left">名称</th>
<th style="text-align:left">求法</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">$||A||_1$</td>
<td style="text-align:left">列和范数/列范数</td>
<td style="text-align:left">对每一列求各个元素的模的和，有n列就有n个和，再取这些和的最大值</td>
</tr>
<tr>
<td style="text-align:left">$||A||_∞$</td>
<td style="text-align:left">行和范数/行范数</td>
<td style="text-align:left">对每一行求各个元素的模的和，有n行就有n个和，再后取这些和的最大值</td>
</tr>
<tr>
<td style="text-align:left">$||A||_2$</td>
<td style="text-align:left">谱范数</td>
<td style="text-align:left">$A^HA$的所有特征值中的最大值的平方根</td>
</tr>
</tbody>
</table>
<h1 id="特征值估计"><a href="#特征值估计" class="headerlink" title="特征值估计"></a>特征值估计</h1><h2 id="盖尔圆"><a href="#盖尔圆" class="headerlink" title="盖尔圆"></a>盖尔圆</h2><p>方阵的盖尔圆所在的平面为复平面，x轴为实数，y轴为虚数，方阵的特征值只会出现在盖尔圆内。N阶方阵$A(a_{ij})$共有n个盖尔圆，它的第i个盖尔圆以$a_{ii}$为圆心,以<br>$$R_i = |a_{i1}| + |a_{i2}| + … + |a_{in}| - |a_{ii}|$$<br>为半径，即第i个盖尔圆的半径以矩阵第i行，除去对角元素的，其他所有元素的模的和。<br>第i个盖尔圆$G_i$的表示为<br>$$G_i = \{ Z |  |Z-a_{ii}| \leq Ri \}, Z \in C$$<br>有k个孤立的盖尔圆内则至少有k个相异的特征值，相交的盖尔圆内可能有重根。</p>
<h1 id="矩阵函数"><a href="#矩阵函数" class="headerlink" title="矩阵函数"></a>矩阵函数</h1><h2 id="概念-2"><a href="#概念-2" class="headerlink" title="概念"></a>概念</h2><ul>
<li><p>矩阵函数<br>如果矩阵A中的每个元素$a_{ij}(t)$都是变量t的函数，则称A(t)为矩阵函数。如果矩阵的每个元素都有极限，则这个矩阵函数也有极限。</p>
</li>
<li><p>矩阵序列<br>矩阵序列$A(k)_{m \times n}, k  \in N$, 共有$m \times n$个元素，那么就有$m \times n$组数列， 当每个数列$\{a_{ij}(k)\}$均分别收敛于相应的极限$a_{ij}$时，则矩阵序列{A(t)}收敛于A, 其中A由$a_{ij}$组成。</p>
</li>
<li><p>谱半径<br>矩阵A所有特征值的模的最大值</p>
</li>
<li><p>单纯矩阵与矩阵函数<br>对于可对角化的单纯矩阵而言，f(A)的特征值就是f(λ)，可用来求f(A)的谱分解和谱半径</p>
</li>
</ul>
<h2 id="判断矩阵幂级数敛散性"><a href="#判断矩阵幂级数敛散性" class="headerlink" title="判断矩阵幂级数敛散性"></a>判断矩阵幂级数敛散性</h2><ol>
<li>考虑矩阵幂级数$\sum A(k)$, 先把矩阵A换成未知数x，计算这个数项幂级数$\sum x(k)$的收敛半径R</li>
<li>求矩阵A的特征值，并计算其谱半径$\rho (λ)$  (特征值模的最大值)</li>
<li>若$\rho (\lambda)<r$,则矩阵幂级数绝对收敛;<br>若$\rho (\lambda)>R$,则发散.</r$,则矩阵幂级数绝对收敛;<br></li>
<li>若$\rho (λ)=R$，上述方法失效，可计算A(k)的Jordan形，$A(n)=P^{-1}J(k)P$，通过证明J(k)的敛散来证明A(k)的敛散，进而证明$\sum A(k)$的敛散。</li>
<li>J(k)的每个元素都是关于n的级数，看看当n-&gt;∞时，所有元素是不是都收敛，有一个不收敛就是发散，都收敛时，A的矩阵幂级数才收敛<br><img src="http://img.blog.csdn.net/20160211151215293" alt="这里写图片描述"></li>
</ol>
<h2 id="矩阵函数的计算方法"><a href="#矩阵函数的计算方法" class="headerlink" title="矩阵函数的计算方法"></a>矩阵函数的计算方法</h2><ul>
<li>Jordan标准型法（不推荐）<br>1）求m阶矩阵A的Jordan标准形J和可逆阵P, $P^{-1}$，使得$P^{-1}AP=J$<br>2）求f(J), $f(J)=diag(f(J_1), f(J_2), \dots f(J_m))$，其中$f(J_i)_{r \times r}$<br>3）$f(A)=Pf(J)P^{-1}$</li>
</ul>
<p><img src="http://img.blog.csdn.net/20160211152030968" alt="这里写图片描述"></p>
<ul>
<li>待定系数法(推荐)<br>1）求A的最小式，得到最小次的总次数degmA(λ)=k<br>2）令$p(λ)=b_0+b_1λ+b_2λ^2+…+b_{k-1}λ^{k-1}$， k是几就有几个b, $b_0 \dots b_{k-1}$<br>3）列方程组$p(λ_i)= f(λ_i)$
若$λ_i$是2重根，则再设$p’(λ_i)= f’(λ_i)$<br>如f(A)=sinA, $m_{A(λ)}=( λ-2)^2( λ-1)$，令$p(λ)= b_0+b_1λ+b_2λ^2$,要满足的方程组为</li>
</ul>

$$
\left\{
\begin{array}{c}
P(1)=sin1 \\
P(2)=sin2 \\
P’(2)=cos2
\end{array}
\right.
$$
    
<p>即</p>

$$
\left\{
\begin{array}{c}
b0+b1+b2=sin1 \\
b0+2b1+4b2=sin2 \\
b1+4b2=cos2
\end{array}
\right.
$$

<p>4）解出$b_i$，即解出了p(λ), 把p(λ)换成A就是p(A), 最后f (A)= p(A)<br><img src="http://img.blog.csdn.net/20160211153159811" alt="这里写图片描述"></p>
<h1 id="矩阵求导"><a href="#矩阵求导" class="headerlink" title="矩阵求导"></a>矩阵求导</h1><p>矩阵求导包括标量，行向量$x^T$, 列向量x，矩阵之间的求导。</p>
<h2 id="矩阵Y-F-x-对标量x求导"><a href="#矩阵Y-F-x-对标量x求导" class="headerlink" title="矩阵Y=F(x)对标量x求导"></a>矩阵Y=F(x)对标量x求导</h2><p>相当于矩阵$Y_{m \times n}$中的每个元素对x求导，转化为$m \times n$次普通的求导<br><img src="http://img.blog.csdn.net/20160212165402569" alt="这里写图片描述"></p>
<h2 id="标量y对列向量x求导"><a href="#标量y对列向量x求导" class="headerlink" title="标量y对列向量x求导"></a>标量y对列向量x求导</h2><p>相当于标量y对列向量x的每个分量求偏导，再组成一个新的列向量<br><img src="http://img.blog.csdn.net/20160212165451757" alt="这里写图片描述"></p>
<h2 id="行向量-y-T-对列向量x求导"><a href="#行向量-y-T-对列向量x求导" class="headerlink" title="行向量$y^T$对列向量x求导"></a>行向量$y^T$对列向量x求导</h2><p>相当于行向量$y^T$的每一个分量作为标量对列向量x求导，转化为标量对列向量x求导的情况。考虑$y^T=(y_1, y_2, \dots y_n)^T, x=(x_1, x_2, \dots, x_m)$，则y的n个分量都对x的求导，得到n个维度为m的列向量，最后这n个列向量再组成m行n列的矩阵。<br><img src="http://img.blog.csdn.net/20160212165526790" alt="这里写图片描述"></p>
<p>注意：</p>
<ol>
<li>$1 \times n$的行向量对$m \times 1$的列向量求导后是$m \times n$的矩阵。</li>
<li>重要结论：<br>$${dx^T \over dx} = I$$$${d(Ax)^T \over dx} = A^T$$</li>
</ol>
<h2 id="列向量y对行向量-x-T-求导"><a href="#列向量y对行向量-x-T-求导" class="headerlink" title="列向量y对行向量$x^T$求导"></a>列向量y对行向量$x^T$求导</h2><p>转化为行向量$y^T$对列向量 x 的导数，然后转置。<br><img src="http://img.blog.csdn.net/20160212165614369" alt="这里写图片描述"><br>注意</p>
<ol>
<li>m×1 向量对 1×n 向量求导结果为 m×n 矩阵。</li>
<li>重要结论：<br>$${dx \over dx^T} = ({dx^T \over dx})^T=I$$$${d(Ax) \over dx^T} =({d(Ax)^T \over dx})^T = (A^T)^T=A$$</li>
</ol>
<h2 id="向量积-u-Tv-对列向量x求导的运算法则"><a href="#向量积-u-Tv-对列向量x求导的运算法则" class="headerlink" title="向量积$u^Tv$对列向量x求导的运算法则"></a>向量积$u^Tv$对列向量x求导的运算法则</h2><p>$${d(u^Tv) \over dx}={d(u^T) \over dx} \cdot v+{d(v^T) \over dx} \cdot u$$<br>例如：$${d(x^Tx) \over dx}={d(x^T) \over dx} \cdot x+{d(x^T) \over dx} \cdot x=I \cdot x + I \cdot x =2x$$$${d(x^TAx) \over dx}={d(x^T) \over dx} \cdot Ax+{d(Ax)^T \over dx} \cdot x=I \cdot Ax + A^T \cdot x =(A+A^T)x$$</p>
<h2 id="矩阵Y对列向量x求导"><a href="#矩阵Y对列向量x求导" class="headerlink" title="矩阵Y对列向量x求导"></a>矩阵Y对列向量x求导</h2><p>将Y对x的每一个分量求偏导，构成一个超列向量，超向量中的每个分量都是一个矩阵。转化为矩阵对标量求导的情况。<br><img src="http://img.blog.csdn.net/20160212215141519" alt="这里写图片描述"><br>注意：矩阵对列向量求导的结果是以矩阵作为分量的超向量。</p>
<h2 id="矩阵Y对行向量-x-T-求导"><a href="#矩阵Y对行向量-x-T-求导" class="headerlink" title="矩阵Y对行向量$x^T$求导"></a>矩阵Y对行向量$x^T$求导</h2><p>相当于Y对$x^T$的每一个分量求偏导，结果是个超级行向量。<br>$$Y=F(x) \rightarrow {dY \over dx^T}=[{∂F \over ∂x_1} \ {∂F \over ∂x_2}\  \dots \ {∂F \over ∂x_n}] $$</p>
<h2 id="标量y对矩阵X求导"><a href="#标量y对矩阵X求导" class="headerlink" title="标量y对矩阵X求导"></a>标量y对矩阵X求导</h2><p>相当于标量y对矩阵X中的每个元素求导，结果是个和矩阵X行列相等的矩阵<br><img src="http://img.blog.csdn.net/20160212215644947" alt="这里写图片描述"></p>
<p>重要结论：$${d(u^TXv) \over dX} = u \cdot v^T$$$${d[(Xu)^TXu] \over dX} = 2Xu \cdot u^T$$$${d[(Xu-v)^T(Xu-v)] \over dX} = 2(Xu-v)u^T$$</p>
<h2 id="矩阵Y对矩阵X求导"><a href="#矩阵Y对矩阵X求导" class="headerlink" title="矩阵Y对矩阵X求导"></a>矩阵Y对矩阵X求导</h2><p>将矩阵$Y_{m \times n}$的每个元素对矩阵X求导，转化为$m \times n$个标量对矩阵$X_{s \times r}$求导，最后排起来得到$m \times n$的超级矩阵，其中每个元素为$s \times r$的矩阵。<br>矩阵对矩阵求导的结果是以矩阵作为元素的超级矩阵。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/02/01/3 广义逆矩阵/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yiyang Peng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/7233064.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yiyang's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/02/01/3 广义逆矩阵/" itemprop="url">矩阵的广义逆</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-02-01T17:30:00+08:00">
                2016-02-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/数学/" itemprop="url" rel="index">
                    <span itemprop="name">数学</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h1><ul>
<li>广义逆<br>$A_{m \times n}, X_{m \times n}$，若X满足moore-penrose条件</li>
</ul>
<ol>
<li>AXA=A</li>
<li>XAX=X</li>
<li>$(AX)^H=AX$</li>
<li>$(XA)^H=XA$<br>中的一部分，称X是A的广义逆矩阵, 简称广义逆</li>
</ol>
<ul>
<li><p>伪逆$A^+$</p>
<ul>
<li>如果X满足上述所有moore-penrose条件，则称X是A的伪逆，或加号逆（M-P逆），记为$A^+$, 若A可逆，则$A^{-1} = A^+$。</li>
<li>$\forall A_{n \times n} \in C，A^+$ 存在且唯一。</li>
<li>性质</li>
</ul>
<ol>
<li>$AA^+A=A$</li>
<li>$A^+A A^+= A^+$</li>
<li>$(AA^+)^H = AA^+$</li>
<li>$(A^+A)^H = A^+A$</li>
</ol>
</li>
<li><p>伪逆的运算<br>设$A_{n \times n} \in C$，则</p>
</li>
</ul>
<ol>
<li>伪逆的伪逆是自己，$(A^+)^+ = A$</li>
<li>共轭转置的伪逆=伪逆的共轭转置，$(A^H)^+ = (A^+)^H$</li>
<li>转置的伪逆=伪逆的转置，$(A^T)^+ = (A^+)^T$</li>
<li>$(A^HA)^+ = A^+(A^H)^+，(AA^H)^+ = (A^H)^+A^+$</li>
<li>一般的伪逆不能去括号，$(AB)^+ ≠ B^+A^+$</li>
<li>一般地，A乘A的伪逆不等于单位阵，$A^+A ≠ AA^+ ≠ I$</li>
<li>伪逆的秩=本身的秩，$r(A^+) = r(A)$</li>
<li>$A^+ = (A^HA)^+A^H = A^H (AA^H)^+$ </li>
<li>伪逆的像空间=共轭转置的像空间$R(A^+) = R(A^H)$</li>
<li>伪逆的核空间=共轭转置的核空间$N(A^+) = N(A^H)$<br><img src="http://img.blog.csdn.net/20160201113818041" alt="这里写图片描述"></li>
</ol>
<ul>
<li>A的{n}逆<br>满足第n个moore-pensore条件的广义逆叫做A的{n}逆，记作A(n), n=1,2,3,4，如：</li>
</ul>
<ol>
<li>满足第1个mp条件为A的{1}逆，可写作A(1)，常记作$A^-$，也叫A的减号逆</li>
<li>满足第2,3个mp条件的为A的{2,3}逆，可写作A(2,3)<br>以上均是A的广义逆</li>
</ol>
<h1 id="伪逆-A-的求法"><a href="#伪逆-A-的求法" class="headerlink" title="伪逆$A^+$的求法"></a>伪逆$A^+$的求法</h1><ul>
<li>满秩分解求A+<br>对于$A_{m \times n}^r$, r &gt; 0, A有满秩分解 $A=F_{m \times r}G_{r \times n}$(列满秩×行满秩),则<br>$A^+ = G^H(GG^H)^{-1}(F^HF)^{-1}F^H = G^H(F^HAG^H)^{-1}F^H$<br>特别地，<br>当A列满秩，r=n时，$A^+ = (A^HA)^{-1}A^H$<br>当A行满秩，r=m时，$A^+ = A^H (AA^H)^{-1}$</li>
</ul>
<ul>
<li>奇异值分解求$A^+$<br>对于$A_{m \times n}^r, r > 0$, A有奇异值分解</li>
</ul>

$$A=V\left(
\begin{matrix}
S_r & 0 \\
0 & 0
\end{matrix}
\right)U^H$$

<p>则有</p>

$$A^+=U\left(
\begin{matrix}
S_r^{-1} & 0 \\
0 & 0
\end{matrix}
\right)V^H$$

<p>即UV位置对换，Sr取逆，对角元全变倒数：$Sr^{-1} = diag(σ_1^{-1}, … σ_r^{-1})$<br>或者，只需要U, $U=(U_1, U_2)$, 则$A^+ = U_1Λ_r^{-1}U_1^HA^H$, 这里$Λ_r=S_r^2=diag(λ_1, …, λ_n)$</p>
<ul>
<li>奇异值分解求A+的简化步骤：</li>
</ul>
<ol>
<li>求出$A^HA$的r个非0特征值</li>
<li>求出相应的特征向量，并schmidt正交化，组成酉高矩阵$U_1$</li>
<li></li>
</ol>

$$A^+=U_1\left(
\begin{matrix}
λ_1^{-1} &  & \\
 &  \ddots  &  \\
 & & λ_r^{-1} \\
\end{matrix}
\right)U_1^HA^H$$

<ul>
<li>秩1公式求$A^+$：若r(A)=1, 则$$A^+={1 \over \sum |a_{ij}|^2}A^H$$</li>
</ul>
<ul>
<li>谱分解求$A^+$ (这个部分有些问题。。。有空再改)<br>$A^HA$有k个相异的特征值，$A^HA$的谱分解为$$A^HA= \sum_{i=1}^k λ_iG_i$$<br>这里$G_i = X_iY_i$，$X_i$是P的各列向量，$Y_i$是$P^{-1}$的各行向量，P是$A^HA$相似对角化时的可逆阵P, 则$$A^+=\sum_{i=1}^k λ_i{ \phi_i(A^HA) \over \phi_i(\lambda_i)}A^H$$
其中$$\phi_i(\lambda)= \prod^k_{j=1, i≠j} (\lambda - \lambda_j)$$</li>
</ul>
<h1 id="广义逆与线性方程组"><a href="#广义逆与线性方程组" class="headerlink" title="广义逆与线性方程组"></a>广义逆与线性方程组</h1><ul>
<li><p>方程组相容：<br>即Ax=b有解（当且仅当A列满秩时解唯一, $A_{m \times n}$）<br>Ax=b相容的充要条件为$AA^-b=b$, 其通解为：$$x=A^-b+(I_n-A^-A)y$$<br>y为n阶任意列向量，因为$A^+$是$A^-$的子集，所以将$A^-$替换为$A^+$也成立(这里的$I_n$的阶数与A的列数相等)： $$x=A^+b+(I_n-A^+A)y$$<br>极小范数解为：$$x_0=A^+b$$</p>
</li>
<li><p>方程组不相容：<br>x的最小二乘解的通解为：</p>
$$x=A^+b+(I_n-A^+A)y$$
<p>当且仅当A列满秩时，不相容方程组Ax=b的最小二乘解唯一，是：</p>
$$x_0=A^+b$$
<p>当A非列满秩时,最小二乘解不唯一，但上式是极小范数最小二乘解, 且唯一。</p>
</li>
</ul>
<h1 id="A的-1-逆-A-的求法"><a href="#A的-1-逆-A-的求法" class="headerlink" title="A的{1}逆$A^-$的求法"></a>A的{1}逆$A^-$的求法</h1><p>对于$A_{m \times n}, \exists  P_m, Q_n$可逆，使得</p>

$$PAQ=\left(
\begin{matrix}
I_r & 0 \\
0 & 0
\end{matrix}
\right)U^H$$

<p>则 </p>

$$A^-=\left \{
\begin{array}{c|c}
Q\left(\begin{matrix}I_r & X_{12} \\
X_{21} & X_{22} 
\end{matrix} \right)P &X_{12},X_{21},X_{22}为任意适当阶子块
\end{array} \right \}$$

$X_{12}^{r \times (m-r)}， X_{12}^{(n-r) \times r}，X_{22}^{(n-r) \times (m-r)}$可取0, 则<br><br>
$$A^-=Q\left( \begin{matrix} I_r & 0 \\
 0 & 0 \end{matrix} \right)P$$

<p>特别地，当$A_{n \times n}$ 为方阵且可逆时，有$$PAQ=I_n$$此时$$A^- = QI_nP=QP=A^{-1}$$</p>
<ul>
<li>初等行变换求P, Q</li>
</ul>

$$
\left(\begin{matrix}A_{m \times n} & I_m \\
I_n & 0\end{matrix}\right) \longrightarrow \left(\begin{matrix} \left(\begin{matrix}I_n & 0 \\
 0 & 0\end{matrix}\right) & P \\
 Q & 0\end{matrix}\right)
$$

<p><div id="container"></div></p>
<p><link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css"></p>
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script>
var gitment = new Gitment({
  id: 'inverse_matrix',
  title: '广义逆矩阵',
  owner: 'yiyang186',
  repo: 'blog_comment',
  oauth: {
    client_id: '2786ddc8538588bfc0c8',
    client_secret: '83713f049f4b7296d27fe579a30cdfe9e2e45215',
  },
})
gitment.render('container')
</script>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/01/31/2 矩阵的分解/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yiyang Peng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/7233064.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yiyang's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/01/31/2 矩阵的分解/" itemprop="url">几种常用矩阵分解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-01-31T12:40:00+08:00">
                2016-01-31
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/数学/" itemprop="url" rel="index">
                    <span itemprop="name">数学</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>矩阵分解 (decomposition, factorization)是将矩阵拆解为数个矩阵的乘积或加和的过程，可分为三角分解、满秩分解、QR分解、Jordan分解、SVD（奇异值）分解和谱分解等，其中三角分解(LU分解)是高斯消元法的另一种表现形式，在本科的线性代数里已经被我们用烂了，Jordan分解在上一章线性代数引论“求Jordan标准形”里已经介绍。这一章只介绍QR分解、满秩分解、SVD（奇异值）分解和谱分解。</p>
<h1 id="QR分解"><a href="#QR分解" class="headerlink" title="QR分解"></a>QR分解</h1><ul>
<li><p>描述<br>A=QR<br>A是满秩方阵，Q是正交矩阵，R是上三角阵，分解唯一<br>A=UR(把正交矩阵换成酉矩阵也一样)<br>如果A只是列满秩，($A_{m×n}, n≤m$, 秩为n)那么<br>$A_{m×n} = Q_{m×n}R_{n×n}$, Q只要满足n个列向量标准正交即可，R还是上三角阵</p>
</li>
<li><p>QR分解步骤</p>
</li>
</ul>
<ol>
<li>求r(A)判断A是否满秩</li>
<li>按列分块$A=(x_1,  x_2,  x_3)$，正交化为$y_1, y_2,y_3$, 单位化为$z_1, z_2, z_3$</li>
<li>令
$$Q=(z_1,z_2,z_3)$$
$$
R= \left(
 \begin{matrix}
   ||y_1|| & (x_2, z_1) & (x_3, z_1) \\
   0 & ||y_2|| & (x_3, z_2) \\
   0 & 0 & ||y_3||
  \end{matrix}
  \right)
$$
</li>
<li>最后，A=QR</li>
</ol>
<ul>
<li>scipy代码演示<br><img src="http://img.blog.csdn.net/20160929153348292" alt="这里写图片描述"></li>
</ul>
<h1 id="满秩分解"><a href="#满秩分解" class="headerlink" title="满秩分解"></a>满秩分解</h1><ul>
<li><p>描述<br>任一矩阵可分解为一个列满秩与行满秩矩阵的乘积，但分解不唯一<br>$A_{m×n} = F_{m×r} G_{r×n}$ (A的秩为r)</p>
</li>
<li><p>满秩分解方法</p>
</li>
</ul>
<ol>
<li>经初等行变换化为简化阶梯型<br><img src="http://img.blog.csdn.net/20160131104725445" alt="这里写图片描述"></li>
<li>取H中是单位向量的列的序号，找出A中对应序号的列组成F</li>
<li>取H中的非0行（前r行）作为G</li>
<li>最后，A=FG</li>
</ol>
<h1 id="奇异值分解"><a href="#奇异值分解" class="headerlink" title="奇异值分解"></a>奇异值分解</h1><ul>
<li><p>描述</p>
<ul>
<li><strong>奇异值</strong>：复矩阵$A_{m \times n}^r$(秩为r)，$A^HA$有n个特征值，按<strong>从大到小</strong>的顺序排列，保证$ \lambda_1 \geq  \lambda_2 \geq   ... \geq \lambda_n$，有前r个为正，后n-r个为0，称 $σ_i=\sqrt{λ_i}$为A的奇异值，前r个$\sigma_1 \geq \sigma_2 \geq ... \geq \sigma_r$为正奇异值。</li>
<li><strong>奇异值分解</strong>：$A=USV^H$$A_{m×n}^r  = U_{m×m} S_{m×n} V^H_{n×n}$
其中，U和V为酉矩阵(见上一章)，S为A的奇异值组成的对角阵，前r个为正奇异值，后n-r个全为0
$$A=U\left(
\begin{matrix}
S_r & 0 \\
0 & 0
\end{matrix}
\right)V^H$$

</li>
</ul>
</li>
<li><p>奇异值分解步骤：</p>
</li>
</ul>
<ol>
<li>计算$A^HA$的n个特征值并按从大到小排序得到$λ_i(i=1...n)$, 取平方根得到奇异值$σ_i$</li>
<li>计算这n个特征值$λ_i$对应的特征向量$α_i$，并schmidt正交化，得到标准正交特征向量$α_1, α_2, … α_r, α_{r+1}, … , α_n$。令$V_1=(α_1, … α_r), V_2=(α_{r+1}, … , α_n), V=(V_1, V_2)$;令$S_r=diag(σ_1, … σ_r),(\sigma_1 \geq \sigma_2 \geq ... \geq \sigma_r)$</li>
<li>计算$U_1=(β_1, … β_r) =AV_1S_r^{-1}$</li>
<li>求出$N(A^H)$的一组标准正交基$β_{r+1}, … β_m$(即求$A^H$齐次方程组的一组基础解系，也需要schmidt正交化)。令$U_2=(β_{r+1}, … β_m), U=(U_1, U_2)$, 则</li>
</ol>

$$A=U\left(
\begin{matrix}
S_r & 0 \\
0 & 0
\end{matrix}
\right)V^H$$

<ul>
<li>scipy演示代码<br><img src="http://img.blog.csdn.net/20160929152827925" alt="这里写图片描述"></li>
</ul>
<h1 id="谱分解"><a href="#谱分解" class="headerlink" title="谱分解"></a>谱分解</h1><ul>
<li><p>描述<br>N阶方阵$A_{n \times n}$的n个特征值称为A的谱（谱分解是对于单纯矩阵而言的）</p>
</li>
<li><p>谱分解步骤：</p>
</li>
</ul>
<ol>
<li>以A的线性无关的特征向量为列组成矩阵P，将P按列分块$P=(X_1, X_2, …, X_n)$</li>
<li>求$P^{-1}$, 将$P^{-1}$按行分块   $P^{-1}=(Y_1, Y_2, …, Y_n)^T$</li>
<li>则A的谱分解为$A = λ_1X_1Y_1 +λ_2X_2Y_2 + … + λ_kX_kY_k$  
或$A = λ_1G_1 +λ_2G_2 + … + λ_kG_k$ 
其中，$G_i = X_iY_i$, 这里的$G_i$是幂等矩阵, 且有如下性质: $G_i$两两正交，所有$G_i$的和为$I_n$</li>
</ol>
<ul>
<li>特殊情况<br>若A是正规矩阵($A^HA=AA^H$)，则上述的$G_i$为幂等厄米特阵，A酉相似于对角阵，那么，将U按列分块<br>$U=( X_1, X_2, …, X_n)$,  取$G_i = X_iX_i^H$即可！</li>
</ul>
<h1 id="补充：幂等阵"><a href="#补充：幂等阵" class="headerlink" title="补充：幂等阵"></a>补充：幂等阵</h1><ul>
<li><p>描述<br>幂等阵：$A∈C_{n×n}$, 若满足$A^2=A$, 则称A为幂等阵。</p>
</li>
<li><p>A为幂等阵的等价命题</p>
</li>
</ul>
<ol>
<li>与A相似的任意矩阵也是幂等阵；</li>
<li>$A^H,A^T,A^*，I-A^H，I-A^T$都是幂等阵</li>
<li>$A^k$是幂等阵, $k \in N$</li>
</ol>
<ul>
<li>幂等阵的主要性质：</li>
</ul>
<ol>
<li>幂等阵的特征值只可能是0，1；</li>
<li>幂等阵可对角化；</li>
<li>幂等阵的迹等于幂等阵的秩，即tr(A)=rank(A)；</li>
<li>可逆的幂等阵为I；</li>
<li>零方阵和单位矩阵都是幂等阵；</li>
<li>幂等阵A满足：A(I-A)=(I-A)A=0；</li>
<li>幂等阵A有Ax=x的充要条件是x∈R(A)；</li>
<li>A的核空间N(A)等于I-A的像空间R(I-A), 且N(I-A)=R(A)。　</li>
</ol>
<ul>
<li>幂等阵的运算：<br>设 $A_1,A_2$都是幂等阵</li>
</ul>
<ol>
<li>$A_1+A_2$ 为幂等阵的充分必要条件为：$A_1A_2 =A_2A_1 = 0$且有：<br>$R(A_1+A_2) =R (A_1) ⊕R (A_2)$；(⊕表示直积)<br>$N(A_1+A_2) =N (A_1)∩N(A_2)$；</li>
<li>$A_1-A_2$ 为幂等阵的充分必要条件为：$A_1A_2 =A_2A_1=A_2$且有：$R(A_1-A_2) =R(A_1)∩N (A_2 )$；<br>$N (A_1 - A_2 ) =N (A_1 )⊕R (A_2)$；</li>
<li>若$A_1A_2 =A_2A_1$，则$A_1A_2$ 为幂等阵，且有：<br>$R (A_1A_2 ) =R (A_1 ) ∩R (A_2 )$；<br>$N (A_1A_2 ) =N (A_1 ) +N (A_2 )$。</li>
</ol>
<p><div id="container"></div></p>
<p><link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css"></p>
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script>
var gitment = new Gitment({
  id: 'matrix_decomposition',
  title: '矩阵的分解',
  owner: 'yiyang186',
  repo: 'blog_comment',
  oauth: {
    client_id: '2786ddc8538588bfc0c8',
    client_secret: '83713f049f4b7296d27fe579a30cdfe9e2e45215',
  },
})
gitment.render('container')
</script>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/01/31/1-线性代数引论/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yiyang Peng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/7233064.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yiyang's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/01/31/1-线性代数引论/" itemprop="url">矩阵论的线性代数基础</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-01-31T11:35:00+08:00">
                2016-01-31
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/数学/" itemprop="url" rel="index">
                    <span itemprop="name">数学</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Jordan标准形"><a href="#Jordan标准形" class="headerlink" title="Jordan标准形"></a>Jordan标准形</h1><ul>
<li><p>Jordan块<br>主对角元素为<strong>某一特征值</strong>，副对角元素为1，如：<br>1阶J块：($\lambda$)<br>2阶J块：$\left(\begin{matrix}\lambda & 1 \\
& \lambda \end{matrix}\right)$<br>3阶J块：$\left(\begin{matrix}\lambda & 1 &  \\
& \lambda & 1 \\
&  & \lambda \end{matrix}\right)$<br>4阶J块：$\left(\begin{matrix}\lambda & 1 &  &  \\
  & \lambda & 1 &  \\
  &  & \lambda & 1 \\
  &  &  & \lambda\end{matrix}\right)$<br>……<br>n阶J块：$\left(\begin{matrix}\lambda & 1 &  &  &\\
  & \lambda & 1 & & \\
  &  & \ddots & \ddots \\
  &  &  & \ddots & 1\\
  &  &  & & \lambda \end{matrix}\right)$</p>
</li>
<li><p>Jordan标准形<br>由Jordan块组成的对角阵，如</p>

$$\left(\begin{matrix}
  J_1 &  &  &  \\
  & J_2 &  &  \\
  &  & \ddots &  \\
  &  &  & J_n \end{matrix}\right)$$
</li>
<li>求矩阵A的Jordan标准形</li>
</ul>
<ol>
<li>先求A的特征多项式，解出特征值</li>
<li>特征值单重根为1阶J块，2重根为1个2阶J块或2个1阶J块，即副对角线元素为1或0，先设为*（3重以上的差不多，可能是3个1阶J块，或1个3阶J块，或1个1阶J块+1个2阶J块）</li>
<li>对多重根算n-r(A- Iλ)=k，（r(A- Iλ)= r(Iλ-A)，实际上跟证相似对角化是一样的套路）k是多少那么那个特征值就对应几个J块，如k=1，则这个2重特征值对应1个2阶J块，*=1,。如k=2，则对应2个1阶J块，*=0。</li>
</ol>
<ul>
<li><p>注意</p>
<ul>
<li>矩阵A有多少个正交的特征向量，就有多少个Jordan块</li>
<li>A有n个相异的特征值，就有n个1阶J块</li>
<li>不考虑J块次序，复矩阵A的Jordan形由A唯一确定</li>
</ul>
</li>
<li><p>定理<br>任意n阶矩阵A都可相似于Jordan标准形</p>
</li>
</ul>
<h1 id="λ矩阵理论"><a href="#λ矩阵理论" class="headerlink" title="λ矩阵理论"></a>λ矩阵理论</h1><p>λ矩阵——A(λ)表示矩阵元素含λ</p>
<ul>
<li><p>最小多项式<br>首1的，次数最低的，A的零化式，为A的最小多项式$m_A(λ)$ 。能让f(A)=0的就是A的零化式</p>
</li>
<li><p>求最小式<br>先求特征多项式 $f(λ)=| λI-A |$，设$g(λ)=( λ-a)^i(λ-b)^j…$从次数最低的开始尝试如$g_1(λ)=( λ-a)(λ-b)…$，算一算是否有$g_1(A)= 0$，不断提高次数直到遇到$g_X(A)=0$，它就是最小式</p>
</li>
<li><p>A的最小式无重根 等价于</p>
</li>
</ul>
<ol>
<li>A可对角化</li>
<li>λI-A的不变因子无重根</li>
<li>λI-A的初等因子均一次</li>
</ol>
<ul>
<li><p>求初等因子<br><img src="http://img.blog.csdn.net/20160131000927987" alt="img{300x500}"><br>方法2中第2步所谓的分解因式是把不同类型的因式拆开，$(λ-1)^2(λ+1)^3$，同类型带次数的不要把次数拆开<br>方法3 常用，一般不考r&gt;3的清醒<br>初等因子可能有重复的，如北航矩阵论教材27页例5</p>
</li>
<li><p>求不变因子<br>A为几阶方阵就有几个不变因子，从第n个往前求。从初等因子组中取出同类型因子次数最高的项（如：λ-1, (λ-1)2, λ+2 ,( λ+2)3，带λ-1的是一个类型的，取出最高次(λ-1)2 ，带λ+1的是一个类型的，取出最高次(λ+1)3，组成(λ-1)2(λ+1)3）作为第n个不变因子dn(λ)，重复上述步奏直到初等因子全部用完，不变因子不足n个，用1补齐，如…=d2(λ)= d1(λ) = 1</p>
</li>
<li><p>求Smith标准形<br>不变因子顺序排下来，写在主对角线上，就是smith标准形<br>也可以直接由A(λ)经初等行变换化得，要保证第i项能被第i+1项整除，非常麻烦</p>
</li>
</ul>
<h1 id="Hermite转置"><a href="#Hermite转置" class="headerlink" title="Hermite转置"></a>Hermite转置</h1><ul>
<li>共轭转置:  $A^H$,对A取转置后再取共轭</li>
<li>厄米特阵: $A^H=A$，若$x^HAx &gt; $0 则称A厄米特正定</li>
<li>酉矩阵: $U^HU=I$ 类似正交阵($Q^TQ=I$)，但U是复数阵</li>
<li>共轭转置Hermite转置的计算</li>
</ul>
<ol>
<li>$(AB)^H = B^HA^H$，其中A为m行n列的矩阵，B为n行p列矩阵。</li>
<li>$(A^H)^H = A$</li>
<li>$(A +B)^H = A^H + B^H$。</li>
<li>$(rA)^H = \overline rA^H$，其中r为复数，$\overline r$为r的共轭</li>
<li>若A为方阵，则 $|A^H| = |A|^H$，且$tr(A^H) = (tr A)^H$</li>
<li>A是可逆矩阵， 当且仅当 $A^H$可逆，且有$(A^H)^{-1} = (A^{-1})^H$</li>
<li>$A^H$的特征值是A的特征值的复共轭。</li>
<li>$(Ax,y) = (x, A^Hy)$，其中A为m行n列的矩阵，复向量x为n维列向量，复向量y为m维列向量，( , )为复数的内积。</li>
<li>分块矩阵的运算与转置相同，先交换行列，在求每个分块的共轭转置</li>
</ol>
<h1 id="酉空间"><a href="#酉空间" class="headerlink" title="酉空间"></a>酉空间</h1><p>其实就是把欧式空间里的实数变成复数, 欧式空间是有限维的实内积空间，酉空间是有限维的复内积空间</p>
<ul>
<li>实对称阵，正交阵，厄米特阵与酉矩阵</li>
</ul>
<table>
<thead>
<tr>
<th>.</th>
<th>实数域</th>
<th>复数域</th>
</tr>
</thead>
<tbody>
<tr>
<td>对称</td>
<td>实对称阵($A^T=A$)</td>
<td>厄米特阵($A^H=A$)</td>
</tr>
<tr>
<td>正交</td>
<td>正交阵($A^TA=I$)</td>
<td>酉矩阵($A^HA=I$)</td>
</tr>
</tbody>
</table>
<ol>
<li>A是实对称阵（$A^T=A$）等价于 存在正交阵Q使得 A相似于 对角阵，即$Q^TAQ = diag(λ_i…)$，且$λ_i$为实数</li>
<li>A是正交矩阵（$A^T=A^{-1}$） 等价于 存在酉矩阵U使得 A酉相似于 对角阵，即$U^HAU = diag(λ_i…)$, 且$|λ_i|=1$</li>
<li>A是厄米特阵（$A^H=A$） 等价于 A酉相似于 对角阵，且特征值为实数</li>
<li>A是酉矩阵（$A^H=A^{-1}$） 等价于 A酉相似于 对角阵，且特征值模为1</li>
</ol>
<ul>
<li>相似, 正交相似与酉相似：</li>
</ul>
<ol>
<li>$\exists$可逆阵P, 使得$P^{-1}AP = B$, 即A 相似于B</li>
<li>$\exists$正交阵Q, 使得$Q^TAQ = B$, 即A 正交相似于B</li>
<li>$\exists$酉矩阵U, 使得$U^HAU = B$, 即A 酉相似于B</li>
</ol>
<ul>
<li><p>许尔引理（Schur）：$\forall A_{n \times n} \in C$, A都可 酉相似于 一个上三角阵，其主对角元为A的特征值    </p>
</li>
<li><p>正规矩阵（规范阵）：$\forall A_{n \times n} \in C$，有 $A^HA=AA^H$ </p>
<ul>
<li>实对称阵（$A^T=A$）    反实对称阵（$A^T= -A$）    正交阵（$A^T=A^{-1}$）</li>
<li>厄米特阵（$A^H=A$）    反厄米特阵（$A^H= -A$）    酉矩阵（$A^H=A^{-1}$）<br>均是正规矩阵</li>
</ul>
</li>
</ul>
<h1 id="补充：正定矩阵"><a href="#补充：正定矩阵" class="headerlink" title="补充：正定矩阵"></a>补充：正定矩阵</h1><ul>
<li><p>描述<br>设方阵$M_{n \times n}$，若对任何非零向量z，都有$z^TMz&gt; 0$，则称M为正定矩阵。</p>
</li>
<li><p>判定<br>正定矩阵在合同变换下可化为标准型， 即对角矩阵。<br>所有特征值大于零的对称矩阵（或厄米矩阵）也是正定矩阵。<br>判定定理1：对称阵A为正定的充分必要条件是 A的特征值全为正。<br>判定定理2：对称阵A为正定的充分必要条件是 A的各阶顺序主子式都为正。<br>判定定理3：任意阵A为正定的充分必要条件是 A合同于单位阵。</p>
</li>
<li><p>性质：</p>
</li>
</ul>
<ol>
<li>正定矩阵一定是非奇异的。（奇异矩阵的定义：若n阶矩阵A为奇异阵，则其的行列式为零，即 |A|=0）</li>
<li>正定矩阵的任一主子矩阵也是正定矩阵。</li>
</ol>
<p><div id="container"></div></p>
<p><link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css"></p>
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script>
var gitment = new Gitment({
  id: 'matrix_elements',
  title: '矩阵论的线性代数基础',
  owner: 'yiyang186',
  repo: 'blog_comment',
  oauth: {
    client_id: '2786ddc8538588bfc0c8',
    client_secret: '83713f049f4b7296d27fe579a30cdfe9e2e45215',
  },
})
gitment.render('container')
</script>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/01/19/spark构建回归模型/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yiyang Peng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/7233064.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yiyang's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/01/19/spark构建回归模型/" itemprop="url">在spark上做简单的回归</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-01-19T15:24:00+08:00">
                2016-01-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>###加载数据集<br>数据集为<a href="http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset" target="_blank" rel="external">Bike-Sharing-Dataset</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">path = <span class="string">"hdfs:///user/yy/Bike-Sharing-Dataset/hour_noheader.csv"</span></div><div class="line">raw_data = sc.textFile(path)</div><div class="line">num_data = raw_data.count()</div><div class="line">records = raw_data.map(<span class="keyword">lambda</span> x: x.split(<span class="string">","</span>))</div><div class="line">records.cache()</div><div class="line">first = records.first()</div><div class="line"><span class="keyword">print</span> first</div><div class="line"><span class="keyword">print</span> num_data</div></pre></td></tr></table></figure></p>
<pre><code>[u&apos;1&apos;, u&apos;2011-01-01&apos;, u&apos;1&apos;, u&apos;0&apos;, u&apos;1&apos;, u&apos;0&apos;, u&apos;0&apos;, u&apos;6&apos;, u&apos;0&apos;, u&apos;1&apos;, u&apos;0.24&apos;, u&apos;0.2879&apos;, u&apos;0.81&apos;, u&apos;0&apos;, u&apos;3&apos;, u&apos;13&apos;, u&apos;16&apos;]
17379
</code></pre><hr>
<p>###为线性回归模型准备数据集<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 将特征映射到二元编码向量的映射函数</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_mapping</span><span class="params">(rdd, idx)</span>:</span></div><div class="line">    <span class="keyword">return</span> rdd.map(<span class="keyword">lambda</span> fields: fields[idx])\</div><div class="line">              .distinct()\</div><div class="line">              .zipWithIndex()\</div><div class="line">              .collectAsMap()</div></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 查看映射字典结构</span></div><div class="line"><span class="keyword">print</span> <span class="string">"Mapping of first categorical feature column: %s"</span> % get_mapping(records, <span class="number">2</span>)</div></pre></td></tr></table></figure>
<pre><code>Mapping of first categorical feature column: {u&apos;1&apos;: 0, u&apos;3&apos;: 1, u&apos;2&apos;: 2, u&apos;4&apos;: 3}
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 建立将特征映射到二元编码向量的映射字典</span></div><div class="line">mappings = [get_mapping(records, i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>, <span class="number">10</span>)]</div><div class="line">cat_len = sum(map(len, mappings))</div><div class="line">num_len = len(records.first()[<span class="number">11</span>:<span class="number">15</span>])</div><div class="line">total_len = num_len + cat_len</div><div class="line"><span class="keyword">print</span> <span class="string">"Feature vector length for categorical features: %d"</span> % cat_len</div><div class="line"><span class="keyword">print</span> <span class="string">"Feature vector length for numerical features: %d"</span> % num_len</div><div class="line"><span class="keyword">print</span> <span class="string">"Total feature vector length: %d"</span> % total_len</div></pre></td></tr></table></figure>
<pre><code>Feature vector length for categorical features: 57
Feature vector length for numerical features: 4
Total feature vector length: 61
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pyspark.mllib.regression <span class="keyword">import</span> LabeledPoint</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"><span class="comment"># 用于建立二元编码的特征向量</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_features</span><span class="params">(record)</span>:</span></div><div class="line">    cat_vec = np.zeros(cat_len)</div><div class="line">    i = <span class="number">0</span></div><div class="line">    step = <span class="number">0</span></div><div class="line">    <span class="keyword">for</span> field <span class="keyword">in</span> record[<span class="number">2</span>:<span class="number">9</span>]:</div><div class="line">        m = mappings[i]</div><div class="line">        idx = m[field]</div><div class="line">        cat_vec[idx+step] = <span class="number">1</span></div><div class="line">        i += <span class="number">1</span></div><div class="line">        step += len(m)</div><div class="line">    num_vec = np.array([float(field) <span class="keyword">for</span> field <span class="keyword">in</span> record[<span class="number">10</span>:<span class="number">14</span>]])</div><div class="line">    <span class="keyword">return</span> np.concatenate((cat_vec, num_vec))</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_label</span><span class="params">(record)</span>:</span></div><div class="line">    <span class="keyword">return</span> float(record[<span class="number">-1</span>])</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 对每条记录提取特征向量（使用二元编码）和标签</span></div><div class="line">data = records.map(<span class="keyword">lambda</span> r: LabeledPoint(extract_label(r), extract_features(r)))</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 查看使用了二元编码的训练样本结构</span></div><div class="line">first_point = data.first()</div><div class="line"><span class="keyword">print</span> <span class="string">"Raw data: "</span> + str(first[<span class="number">2</span>:])</div><div class="line"><span class="keyword">print</span> <span class="string">"Label: "</span> + str(first_point.label)</div><div class="line"><span class="keyword">print</span> <span class="string">"Linear Model feature vector:\n"</span> + str(first_point.features)</div><div class="line"><span class="keyword">print</span> <span class="string">"Linear Model feature vector length: "</span> + str(len(first_point.features))</div></pre></td></tr></table></figure>
<pre><code>Raw data: [u&apos;1&apos;, u&apos;0&apos;, u&apos;1&apos;, u&apos;0&apos;, u&apos;0&apos;, u&apos;6&apos;, u&apos;0&apos;, u&apos;1&apos;, u&apos;0.24&apos;, u&apos;0.2879&apos;, u&apos;0.81&apos;, u&apos;0&apos;, u&apos;3&apos;, u&apos;13&apos;, u&apos;16&apos;]
Label: 16.0
Linear Model feature vector:
[1.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.24,0.2879,0.81,0.0]
Linear Model feature vector length: 61
</code></pre><hr>
<p>###为决策回归树准备数据集<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 决策回归树不需要将类型数据用二元编码表示</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_features_dt</span><span class="params">(record)</span>:</span></div><div class="line">    <span class="keyword">return</span> np.array(map(float, record[<span class="number">2</span>:<span class="number">14</span>]))</div></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 对每条记录提取特征向量（未使用二元编码）和标签</span></div><div class="line">data_dt = records.map(<span class="keyword">lambda</span> r: LabeledPoint(extract_label(r), extract_features_dt(r)))</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 查看未使用二元编码的训练样本结构</span></div><div class="line">first_point_dt = data_dt.first()</div><div class="line"><span class="keyword">print</span> <span class="string">"Label: "</span> + str(first_point_dt.label)</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree feature vector: "</span> + str(first_point_dt.features)</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree feature vector length: "</span> + str(len(first_point_dt.features))</div></pre></td></tr></table></figure>
<pre><code>Label: 16.0
Decision Tree feature vector: [1.0,0.0,1.0,0.0,0.0,6.0,0.0,1.0,0.24,0.2879,0.81,0.0]
Decision Tree feature vector length: 12
</code></pre><hr>
<p>###线性回归和决策回归树的帮助文档<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pyspark.mllib.regression <span class="keyword">import</span> LinearRegressionWithSGD</div><div class="line"><span class="keyword">from</span> pyspark.mllib.tree <span class="keyword">import</span> DecisionTree</div></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">help(LinearRegressionWithSGD.train)</div></pre></td></tr></table></figure>
<pre><code>Help on method train in module pyspark.mllib.regression:

train(cls, data, iterations=100, step=1.0, miniBatchFraction=1.0, initialWeights=None, regParam=0.0, regType=None, intercept=False, validateData=True) method of __builtin__.type instance
    Train a linear regression model using Stochastic Gradient
    Descent (SGD).
    This solves the least squares regression formulation
            f(weights) = 1/n ||A weights-y||^2^
    (which is the mean squared error).
    Here the data matrix has n rows, and the input RDD holds the
    set of rows of A, each with its corresponding right hand side
    label y. See also the documentation for the precise formulation.

    :param data:              The training data, an RDD of
                              LabeledPoint.
    :param iterations:        The number of iterations
                              (default: 100).
    :param step:              The step parameter used in SGD
                              (default: 1.0).
    :param miniBatchFraction: Fraction of data to be used for each
                              SGD iteration (default: 1.0).
    :param initialWeights:    The initial weights (default: None).
    :param regParam:          The regularizer parameter
                              (default: 0.0).
    :param regType:           The type of regularizer used for
                              training our model.

                              :Allowed values:
                                 - &quot;l1&quot; for using L1 regularization (lasso),
                                 - &quot;l2&quot; for using L2 regularization (ridge),
                                 - None for no regularization

                                 (default: None)

    :param intercept:         Boolean parameter which indicates the
                              use or not of the augmented representation
                              for training data (i.e. whether bias
                              features are activated or not,
                              default: False).
    :param validateData:      Boolean parameter which indicates if
                              the algorithm should validate data
                              before training. (default: True)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">help(DecisionTree.trainRegressor)</div></pre></td></tr></table></figure>
<pre><code>Help on method trainRegressor in module pyspark.mllib.tree:

trainRegressor(cls, data, categoricalFeaturesInfo, impurity=&apos;variance&apos;, maxDepth=5, maxBins=32, minInstancesPerNode=1, minInfoGain=0.0) method of __builtin__.type instance
    Train a DecisionTreeModel for regression.

    :param data: Training data: RDD of LabeledPoint.
                 Labels are real numbers.
    :param categoricalFeaturesInfo: Map from categorical feature
             index to number of categories.
             Any feature not in this map is treated as continuous.
    :param impurity: Supported values: &quot;variance&quot;
    :param maxDepth: Max depth of tree.
             E.g., depth 0 means 1 leaf node.
             Depth 1 means 1 internal node + 2 leaf nodes.
    :param maxBins: Number of bins used for finding splits at each
             node.
    :param minInstancesPerNode: Min number of instances required at
             child nodes to create the parent split
    :param minInfoGain: Min info gain required to create a split
    :return: DecisionTreeModel

    Example usage:

    &gt;&gt;&gt; from pyspark.mllib.regression import LabeledPoint
    &gt;&gt;&gt; from pyspark.mllib.tree import DecisionTree
    &gt;&gt;&gt; from pyspark.mllib.linalg import SparseVector
    &gt;&gt;&gt;
    &gt;&gt;&gt; sparse_data = [
    ...     LabeledPoint(0.0, SparseVector(2, {0: 0.0})),
    ...     LabeledPoint(1.0, SparseVector(2, {1: 1.0})),
    ...     LabeledPoint(0.0, SparseVector(2, {0: 0.0})),
    ...     LabeledPoint(1.0, SparseVector(2, {1: 2.0}))
    ... ]
    &gt;&gt;&gt;
    &gt;&gt;&gt; model = DecisionTree.trainRegressor(sc.parallelize(sparse_data), {})
    &gt;&gt;&gt; model.predict(SparseVector(2, {1: 1.0}))
    1.0
    &gt;&gt;&gt; model.predict(SparseVector(2, {1: 0.0}))
    0.0
    &gt;&gt;&gt; rdd = sc.parallelize([[0.0, 1.0], [0.0, 0.0]])
    &gt;&gt;&gt; model.predict(rdd).collect()
    [1.0, 0.0]
</code></pre><hr>
<p>###训练回归模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 训练线性回归模型,后面会慢慢改进</span></div><div class="line">linear_model = LinearRegressionWithSGD.train(data, iterations=<span class="number">50</span>, step=<span class="number">0.1</span>, intercept=<span class="keyword">False</span>)</div><div class="line">true_vs_predicted = data.map(<span class="keyword">lambda</span> p: (p.label, linear_model.predict(p.features)))</div><div class="line"><span class="keyword">print</span>  <span class="string">"Linear Model predictions: "</span> + str(true_vs_predicted.take(<span class="number">5</span>))</div></pre></td></tr></table></figure>
<pre><code>Linear Model predictions: [(16.0, 110.54561916607503), (40.0, 107.92836240337226), (32.0, 107.45239452594706), (13.0, 107.46860142170017), (1.0, 107.19840815670955)]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 训练决策回归模型,后面会慢慢改进</span></div><div class="line">dt_model = DecisionTree.trainRegressor(data_dt, &#123;&#125;)</div><div class="line">preds = dt_model.predict(data_dt.map(<span class="keyword">lambda</span> p: p.features))</div><div class="line">actual = data.map(<span class="keyword">lambda</span> p: p.label)</div><div class="line">true_vs_predicted_dt = actual.zip(preds)</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree predictions: "</span> + str(true_vs_predicted_dt.take(<span class="number">5</span>))</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree depth: "</span> + str(dt_model.depth())</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree number of nodes: "</span> + str(dt_model.numNodes())</div></pre></td></tr></table></figure>
<pre><code>Decision Tree predictions: [(16.0, 54.913223140495866), (40.0, 54.913223140495866), (32.0, 53.171052631578945), (13.0, 14.284023668639053), (1.0, 14.284023668639053)]
Decision Tree depth: 5
Decision Tree number of nodes: 63
</code></pre><hr>
<p>###评估回归模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 几个计算误差的函数</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">squared_error</span><span class="params">(actual, pred)</span>:</span></div><div class="line">    <span class="keyword">return</span> (pred - actual) ** <span class="number">2</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">abs_error</span><span class="params">(actual, pred)</span>:</span></div><div class="line">    <span class="keyword">return</span> np.abs(pred - actual)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">squared_log_error</span><span class="params">(pred, actual)</span>:</span></div><div class="line">    <span class="keyword">return</span> (np.log(pred+<span class="number">1</span>) - np.log(actual+<span class="number">1</span>)) ** <span class="number">2</span></div><div class="line"></div><div class="line"><span class="comment"># 评估函数</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">myEvaluation</span><span class="params">(true_vs_predicted)</span>:</span></div><div class="line">    mse = true_vs_predicted.map(<span class="keyword">lambda</span> (t,p): squared_error(t,p)).mean()</div><div class="line">    mae = true_vs_predicted.map(<span class="keyword">lambda</span> (t,p): abs_error(t,p)).mean()</div><div class="line">    rmsle = np.sqrt(true_vs_predicted.map(<span class="keyword">lambda</span> (t,p): squared_log_error(t,p)).mean())</div><div class="line">    <span class="keyword">return</span> (mse, mae, rmsle)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估线性回归模型</span></div><div class="line">mse ,mae ,rmsle = myEvaluation(true_vs_predicted)</div><div class="line"><span class="keyword">print</span> <span class="string">"Linear Model - Mean Squared Error: %2.4f"</span> % mse</div><div class="line"><span class="keyword">print</span> <span class="string">"Linear Model - Mean Absolute Error: %2.4f"</span> % mae</div><div class="line"><span class="keyword">print</span> <span class="string">"Linear Model - Root Mean Squared Log Error: %2.4f"</span> % rmsle</div><div class="line"><span class="comment"># 1.46只达到了kaggle上的平均成绩</span></div></pre></td></tr></table></figure>
<pre><code>Linear Model - Mean Squared Error: 27408.1527
Linear Model - Mean Absolute Error: 127.4103
Linear Model - Root Mean Squared Log Error: 1.4847
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估决策回归模型</span></div><div class="line">mse_dt ,mae_dt ,rmsle_dt = myEvaluation(true_vs_predicted_dt)</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree - Mean Squared Error: %2.4f"</span> % mse_dt</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree - Mean Absolute Error: %2.4f"</span> % mae_dt</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree - Root Mean Squared Log Error: %2.4f"</span> % rmsle_dt</div><div class="line"><span class="comment"># 最好成绩是0.2左右，0.6只能算马马虎虎</span></div></pre></td></tr></table></figure>
<pre><code>Decision Tree - Mean Squared Error: 11560.7978
Decision Tree - Mean Absolute Error: 71.0969
Decision Tree - Root Mean Squared Log Error: 0.6259
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">%matplotlib inline</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line"><span class="comment"># 通过画直方图来检查目标值的分布情况</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">checkTargets</span><span class="params">(targets)</span>:</span></div><div class="line">    plt.hist(targets, bins=<span class="number">40</span>, color=<span class="string">'lightblue'</span>, normed=<span class="keyword">True</span>)</div><div class="line">    fig = plt.gcf()</div><div class="line">    fig.set_size_inches(<span class="number">16</span>,<span class="number">10</span>)</div></pre></td></tr></table></figure>
<hr>
<p>###目标变量分布</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 对于线性回归模型,当目标变量服从正态分布,误差项满足高斯--马尔科夫条件（零均值、等方差、不相关）时,回归参数的最小二乘估计是一致最小方差无偏估计. 显然这里的响应变量并不服从正态分布</span></div><div class="line">targets = records.map(<span class="keyword">lambda</span> r: float(r[<span class="number">-1</span>])).collect()</div><div class="line">checkTargets(targets)</div></pre></td></tr></table></figure>
<p><img src="http://img.blog.csdn.net/20160119151242014" alt="这里写图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 对目标值，即响应变量（因变量）进行对数变换，并查看变换后的分布</span></div><div class="line">log_targets = records.map(<span class="keyword">lambda</span> r: np.log(float(r[<span class="number">-1</span>]))).collect()</div><div class="line">checkTargets(log_targets)</div></pre></td></tr></table></figure>
<p><img src="http://img.blog.csdn.net/20160119151303592" alt="这里写图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 对目标值，即响应变量（因变量）进行平方根变换，并查看变换后的分布</span></div><div class="line">log_targets = records.map(<span class="keyword">lambda</span> r: np.sqrt(float(r[<span class="number">-1</span>]))).collect()</div><div class="line">checkTargets(log_targets)</div></pre></td></tr></table></figure>
<p><img src="http://img.blog.csdn.net/20160119151334608" alt="这里写图片描述"></p>
<hr>
<p>###对目标变量作对数变换后重新训练并评估<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 用对数变换后的目标值重新训练线性回归模型</span></div><div class="line">data_log = data.map(<span class="keyword">lambda</span> lp: LabeledPoint(np.log(lp.label), lp.features))</div><div class="line">model_log = LinearRegressionWithSGD.train(data_log, iterations=<span class="number">50</span>, step=<span class="number">0.1</span>)</div><div class="line">true_vs_predicted_log = data_log.map(<span class="keyword">lambda</span> p: (np.exp(p.label), np.exp(model_log.predict(p.features))))</div></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估</span></div><div class="line">mse_log, mae_log, rmsle_log = myEvaluation(true_vs_predicted_log)</div><div class="line"><span class="keyword">print</span> <span class="string">"Linear Model - Mean Squared Error: %2.4f"</span> % mse_log</div><div class="line"><span class="keyword">print</span> <span class="string">"Linear Model - Mean Absolute Error: %2.4f"</span> % mae_log</div><div class="line"><span class="keyword">print</span> <span class="string">"Linear Model - Root Mean Squared Log Error: %2.4f"</span> % rmsle_log</div><div class="line"><span class="keyword">print</span> <span class="string">"Non log-transformed predictions:\n"</span> + str(true_vs_predicted.take(<span class="number">3</span>))</div><div class="line"><span class="keyword">print</span> <span class="string">"Log-transformed predictions:\n"</span> + str(true_vs_predicted_log.take(<span class="number">3</span>))</div></pre></td></tr></table></figure>
<pre><code>Linear Model - Mean Squared Error: 37837.3776
Linear Model - Mean Absolute Error: 133.6572
Linear Model - Root Mean Squared Log Error: 1.3315
Non log-transformed predictions:
[(16.0, 110.54561916607503), (40.0, 107.92836240337226), (32.0, 107.45239452594706)]
Log-transformed predictions:
[(15.999999999999998, 45.336304060846494), (40.0, 42.455963122588777), (32.0, 41.297013243855893)]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 用对数变换后的目标值重新训练决策回归树模型</span></div><div class="line">data_dt_log = data_dt.map(<span class="keyword">lambda</span> lp: LabeledPoint(np.log(lp.label), lp.features))</div><div class="line">dt_model_log = DecisionTree.trainRegressor(data_dt_log, &#123;&#125;)</div><div class="line">preds_log = dt_model_log.predict(data_dt_log.map(<span class="keyword">lambda</span> p: p.features))</div><div class="line">actual_log = data_dt_log.map(<span class="keyword">lambda</span> p: p.label)</div><div class="line">true_vs_predicted_dt_log = actual_log.zip(preds_log).map(<span class="keyword">lambda</span> (t,p): (np.exp(t), np.exp(p)))</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估</span></div><div class="line">mse_log_dt, mae_log_dt, rmsle_log_dt = myEvaluation(true_vs_predicted_dt_log)</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree - Mean Squared Error: %2.4f"</span> % mse_log_dt</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree - Mean Absolute Error: %2.4f"</span> % mae_log_dt</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree - Root Mean Squared Log Error: %2.4f"</span> % rmsle_log_dt</div><div class="line"><span class="keyword">print</span> <span class="string">"Non log-transformed predictions:\n"</span> + str(true_vs_predicted_dt.take(<span class="number">3</span>))</div><div class="line"><span class="keyword">print</span> <span class="string">"Log-transformed predictions:\n"</span> + str(true_vs_predicted_dt_log.take(<span class="number">3</span>))</div></pre></td></tr></table></figure>
<pre><code>Decision Tree - Mean Squared Error: 14781.5760
Decision Tree - Mean Absolute Error: 76.4131
Decision Tree - Root Mean Squared Log Error: 0.6406
Non log-transformed predictions:
[(16.0, 54.913223140495866), (40.0, 54.913223140495866), (32.0, 53.171052631578945)]
Log-transformed predictions:
[(15.999999999999998, 37.530779787154522), (40.0, 37.530779787154522), (32.0, 7.2797070993907287)]
</code></pre><hr>
<p>###为数据集划分训练集与测试集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 对用于线性回归的数据集，按2：8划分测试集与训练集</span></div><div class="line">data_with_idx = data.zipWithIndex().map(<span class="keyword">lambda</span> (k,v): (v,k)) <span class="comment"># 给每个样本加上序号，再反转键值对</span></div><div class="line">test = data_with_idx.sample(<span class="keyword">False</span>, <span class="number">0.2</span>, <span class="number">42</span>) <span class="comment"># 参数：不重复抽样，抽样20%，随机数种子42</span></div><div class="line">train = data_with_idx.subtractByKey(test) <span class="comment"># 从data_with_idx中抽掉（去掉）与test的key（样本序号）相等的样本</span></div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 形成可用于训练和测试的</span></div><div class="line">train_data = train.map(<span class="keyword">lambda</span> (idx,p): p)</div><div class="line">test_data = test.map(<span class="keyword">lambda</span> (idx,p): p)</div><div class="line">train_size = train_data.count()</div><div class="line">test_size = test_data.count()</div><div class="line"><span class="keyword">print</span> <span class="string">"Train data size: %d"</span> % train_size</div><div class="line"><span class="keyword">print</span> <span class="string">"Test data size: %d"</span> % test_size</div><div class="line"><span class="keyword">print</span> <span class="string">"Total data size: %d"</span> % num_data</div><div class="line"><span class="keyword">print</span> <span class="string">"Train + Test size: %d"</span> % (train_size+test_size)</div></pre></td></tr></table></figure>
<pre><code>Train data size: 13934
Test data size: 3445
Total data size: 17379
Train + Test size: 17379
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 对用于决策回归的数据集，按2：8划分测试集与训练集</span></div><div class="line">data_with_idx_dt = data_dt.zipWithIndex().map(<span class="keyword">lambda</span> (k,v): (v,k))</div><div class="line">test_dt = data_with_idx_dt.sample(<span class="keyword">False</span>, <span class="number">0.2</span>, <span class="number">42</span>)</div><div class="line">train_dt = data_with_idx_dt.subtractByKey(test_dt)</div><div class="line">train_data_dt = train_dt.map(<span class="keyword">lambda</span> (idx,p): p)</div><div class="line">test_data_dt = test_dt.map(<span class="keyword">lambda</span> (idx,p): p)</div></pre></td></tr></table></figure>
<hr>
<p>###对线性回归模型的参数调优</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 用于在不同参数配置下评估线性回归模型的性能</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(train, test, iterations, step, regParam, regType, intercept)</span>:</span></div><div class="line">    model = LinearRegressionWithSGD.train(train, iterations, step, regParam=regParam, \</div><div class="line">                                          regType=regType, intercept=intercept)</div><div class="line">    tp = test.map(<span class="keyword">lambda</span> p: (p.label, model.predict(p.features)))</div><div class="line">    rmsle = np.sqrt(tp.map(<span class="keyword">lambda</span> (t,p): squared_log_error(t,p)).mean())</div><div class="line">    <span class="keyword">return</span> rmsle</div><div class="line"></div><div class="line"><span class="comment"># 画折线图展示不同参数与RMSLE的关系</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotting</span><span class="params">(params, metrics)</span>:</span></div><div class="line">    plt.plot(params, metrics)</div><div class="line">    plt.xscale(<span class="string">'log'</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估不同迭代次数对线性回归性能的影响</span></div><div class="line">params = [<span class="number">1</span>,<span class="number">5</span>,<span class="number">10</span>,<span class="number">20</span>,<span class="number">50</span>,<span class="number">100</span>,<span class="number">200</span>]</div><div class="line">metrics = [evaluate(train_data, test_data, param, <span class="number">0.01</span>, <span class="number">0.0</span>, <span class="string">'l2'</span>, <span class="keyword">False</span>) <span class="keyword">for</span> param <span class="keyword">in</span> params]</div><div class="line"><span class="keyword">print</span> params</div><div class="line"><span class="keyword">print</span> metrics</div><div class="line"></div><div class="line"><span class="comment"># 迭代次数与RMSLE的关系</span></div><div class="line">plotting(params, metrics)</div></pre></td></tr></table></figure>
<pre><code>[1, 5, 10, 20, 50, 100, 200]
[2.8779465130028195, 2.0390187660391499, 1.7761565324837874, 1.5828778102209107, 1.4382263191764473, 1.4050638054019449, 1.4191482045051593]
</code></pre><p><img src="http://img.blog.csdn.net/20160119151735437" alt="这里写图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估不同步长对线性回归性能的影响</span></div><div class="line">params = [<span class="number">0.01</span>,<span class="number">0.025</span>,<span class="number">0.05</span>,<span class="number">0.1</span>,<span class="number">1.0</span>]</div><div class="line">metrics = [evaluate(train_data, test_data, <span class="number">10</span>, param, <span class="number">0.0</span>, <span class="string">'l2'</span>, <span class="keyword">False</span>) <span class="keyword">for</span> param <span class="keyword">in</span> params]</div><div class="line"><span class="keyword">print</span> params</div><div class="line"><span class="keyword">print</span> metrics</div><div class="line"></div><div class="line"><span class="comment"># 步长与RMSLE的关系</span></div><div class="line">plotting(params, metrics)</div></pre></td></tr></table></figure>
<pre><code>[0.01, 0.025, 0.05, 0.1, 1.0]
[1.7761565324837874, 1.4379348243997032, 1.4189071944747718, 1.5027293911925559, nan]
</code></pre><p><img src="http://img.blog.csdn.net/20160119151750953" alt="这里写图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估不同L2正则化参数对线性回归性能的影响，L2正则化既是对过大的模型权重向量2范数进行惩罚</span></div><div class="line">params = [<span class="number">0.0</span>,<span class="number">0.01</span>,<span class="number">0.1</span>,<span class="number">1.0</span>,<span class="number">5.0</span>,<span class="number">10.0</span>,<span class="number">20.0</span>]</div><div class="line">metrics = [evaluate(train_data, test_data, <span class="number">10</span>, <span class="number">0.1</span>, param, <span class="string">'l2'</span>, <span class="keyword">False</span>) <span class="keyword">for</span> param <span class="keyword">in</span> params]</div><div class="line"><span class="keyword">print</span> params</div><div class="line"><span class="keyword">print</span> metrics</div><div class="line"></div><div class="line"><span class="comment"># L2正则化参数与RMSLE的关系</span></div><div class="line">plotting(params, metrics)</div></pre></td></tr></table></figure>
<pre><code>[0.0, 0.01, 0.1, 1.0, 5.0, 10.0, 20.0]
[1.5027293911925559, 1.5020646031965639, 1.4961903335175231, 1.4479313176192781, 1.4113329999970989, 1.5381692234875386, 1.8279640526059082]
</code></pre><p><img src="http://img.blog.csdn.net/20160119151809922" alt="这里写图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估不同L1正则化参数对线性回归性能的影响</span></div><div class="line">params = [<span class="number">0.0</span>,<span class="number">0.01</span>,<span class="number">0.1</span>,<span class="number">1.0</span>,<span class="number">10.0</span>,<span class="number">100.0</span>,<span class="number">1000.0</span>]</div><div class="line">metrics = [evaluate(train_data, test_data, <span class="number">10</span>, <span class="number">0.1</span>, param, <span class="string">'l1'</span>, <span class="keyword">False</span>) <span class="keyword">for</span> param <span class="keyword">in</span> params]</div><div class="line"><span class="keyword">print</span> params</div><div class="line"><span class="keyword">print</span> metrics</div><div class="line"></div><div class="line"><span class="comment"># L1正则化参数与RMSLE的关系</span></div><div class="line">plotting(params, metrics)</div></pre></td></tr></table></figure>
<pre><code>[0.0, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]
[1.5027293911925559, 1.5026938950690176, 1.5023761634555699, 1.499412856617814, 1.4713669769550108, 1.7596682962964314, 4.7551250073268614]
</code></pre><p><img src="http://img.blog.csdn.net/20160119151831845" alt="这里写图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 查看线性回归模型在不同的L1正则化参数下权重向量中0的个数</span></div><div class="line"><span class="keyword">for</span> regParam <span class="keyword">in</span> [<span class="number">1.0</span>, <span class="number">10.0</span>, <span class="number">100.0</span>]:</div><div class="line">    model = LinearRegressionWithSGD.train(train_data, <span class="number">10</span>, <span class="number">0.1</span>, regParam=regParam,\</div><div class="line">                                         regType=<span class="string">'l1'</span>, intercept=<span class="keyword">False</span>)</div><div class="line">    <span class="keyword">print</span> <span class="string">"L1 (%s) number of zero weights: "</span>%regParam + str(sum(model.weights.array == <span class="number">0</span>))</div><div class="line"><span class="comment"># L1正则化参数越大，即对模型的L1范数惩罚越大，    那么      权重</span></div></pre></td></tr></table></figure>
<pre><code>L1 (1.0) number of zero weights: 4
L1 (10.0) number of zero weights: 33
L1 (100.0) number of zero weights: 58
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估是否使用截距（intercept）对线性回归性能的影响</span></div><div class="line">params = [<span class="keyword">False</span>,<span class="keyword">True</span>]</div><div class="line">metrics = [evaluate(train_data, test_data, <span class="number">10</span>, <span class="number">0.1</span>, <span class="number">1.0</span>, <span class="string">'l2'</span>, param) <span class="keyword">for</span> param <span class="keyword">in</span> params]</div><div class="line"><span class="keyword">print</span> params</div><div class="line"><span class="keyword">print</span> metrics</div><div class="line"></div><div class="line"><span class="comment"># 是否使用截距与RMSLE的关系</span></div><div class="line">plt.bar(params, metrics, color=<span class="string">'lightblue'</span>)</div><div class="line">fig = plt.gcf()</div><div class="line"><span class="comment"># 使用截距使RMSLE有略微的增加</span></div></pre></td></tr></table></figure>
<pre><code>[False, True]
[1.4479313176192781, 1.4798261513419801]
</code></pre><p><img src="http://img.blog.csdn.net/20160119151850689" alt="这里写图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 用于在不同参数配置下评估决策回归数模型的性能</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_dt</span><span class="params">(train, test, maxDepth, maxBins)</span>:</span></div><div class="line">    model = DecisionTree.trainRegressor(train, &#123;&#125;, impurity=<span class="string">'variance'</span>, maxDepth=maxDepth, \</div><div class="line">                                          maxBins=maxBins)</div><div class="line">    preds = model.predict(test.map(<span class="keyword">lambda</span> p: p.features))</div><div class="line">    actual = test.map(<span class="keyword">lambda</span> p: p.label)</div><div class="line">    tp = actual.zip(preds)</div><div class="line">    rmsle = np.sqrt(tp.map(<span class="keyword">lambda</span> (t,p): squared_log_error(t,p)).mean())</div><div class="line">    <span class="keyword">return</span> rmsle</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估不同最大树深度对决策回归树性能的影响</span></div><div class="line">params = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">10</span>,<span class="number">20</span>]</div><div class="line">metrics = [evaluate_dt(train_data_dt, test_data_dt, param, <span class="number">32</span>) <span class="keyword">for</span> param <span class="keyword">in</span> params]</div><div class="line"><span class="keyword">print</span> params</div><div class="line"><span class="keyword">print</span> metrics</div><div class="line"></div><div class="line"><span class="comment"># 最大树深度与RMSLE的关系</span></div><div class="line">plt.plot(params, metrics)</div><div class="line">fig = plt.gcf()</div></pre></td></tr></table></figure>
<pre><code>[1, 2, 3, 4, 5, 10, 20]
[1.0280339660196287, 0.92686672078778276, 0.81807794023407532, 0.74060228537329209, 0.63583503599563096, 0.42659354467941862, 0.45291736653588244]
</code></pre><p><img src="http://img.blog.csdn.net/20160119151911393" alt="这里写图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估不同最大划分数对决策回归树性能的影响</span></div><div class="line">params = [<span class="number">2</span>,<span class="number">4</span>,<span class="number">8</span>,<span class="number">16</span>,<span class="number">32</span>,<span class="number">64</span>, <span class="number">100</span>]</div><div class="line">metrics = [evaluate_dt(train_data_dt, test_data_dt, <span class="number">5</span>, param) <span class="keyword">for</span> param <span class="keyword">in</span> params]</div><div class="line"><span class="keyword">print</span> params</div><div class="line"><span class="keyword">print</span> metrics</div><div class="line"></div><div class="line"><span class="comment"># 最大树深度与RMSLE的关系</span></div><div class="line">plt.plot(params, metrics)</div><div class="line">fig = plt.gcf()</div></pre></td></tr></table></figure>
<pre><code>[2, 4, 8, 16, 32, 64, 100]
[1.3069788763726049, 0.81923394899750324, 0.75745322513058744, 0.62430742982038667, 0.63583503599563096, 0.63583503599563096, 0.63583503599563096]
</code></pre><p><img src="http://img.blog.csdn.net/20160119151926877" alt="这里写图片描述"></p>
<p>###使用IPython的交互插件进行参数调优<br>需要IPython notebook<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> IPython.html.widgets <span class="keyword">import</span> interact, interactive, fixed</div><div class="line"><span class="keyword">from</span> IPython.html <span class="keyword">import</span> widgets</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(param)</span>:</span></div><div class="line">    metrics = evaluate_dt(train_data_dt, test_data_dt, <span class="number">5</span>, param)</div><div class="line">    <span class="keyword">print</span> param</div><div class="line">    <span class="keyword">print</span> metrics</div><div class="line"></div><div class="line">interact(f, param=(<span class="number">10</span>,<span class="number">20</span>));</div></pre></td></tr></table></figure></p>
<p><img src="http://img.blog.csdn.net/20160119152107317" alt="这里写图片描述"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/01/17/在spark上做简单的文本分类(python)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yiyang Peng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/7233064.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yiyang's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/01/17/在spark上做简单的文本分类(python)/" itemprop="url">在spark上做简单的文本分类</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-01-17T23:58:00+08:00">
                2016-01-17
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>数据集选的是20_newsgroups，我按7：3分的训练集和测试集。</p>
<p>总的流程如下：</p>
<p><img src="http://img.blog.csdn.net/20160117232525303" alt="文本分类基本步骤"><br>这里把数据集中的每一条文本都表示成TFTDF向量，用训练集的TFTDF向量来训练模型，用测试集的TFTDF向量进行分类测试，最后统计测试准确率。</p>
<hr>
<p>###初始化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 设置训练集，测试集路径。</span></div><div class="line">trainPath = <span class="string">"hdfs:///user/yy/20_newsgroups/train/*"</span></div><div class="line">testPath = <span class="string">"hdfs:///user/yy/20_newsgroups/test/*"</span></div><div class="line"></div><div class="line"><span class="comment"># 分类时，新闻主题需要转换成数字，labelsDict将主题转换成数字</span></div><div class="line">labelsDict = &#123;<span class="string">'alt.atheism'</span>:<span class="number">0</span>, <span class="string">'comp.graphics'</span>:<span class="number">1</span>, <span class="string">'comp.os.ms-windows.misc'</span>:<span class="number">2</span>,\</div><div class="line">              <span class="string">'comp.sys.ibm.pc.hardware'</span>:<span class="number">3</span>, <span class="string">'comp.sys.mac.hardware'</span>:<span class="number">4</span>, <span class="string">'comp.windows.x'</span>:<span class="number">5</span>,\</div><div class="line">              <span class="string">'misc.forsale'</span>:<span class="number">6</span>, <span class="string">'rec.autos'</span>:<span class="number">7</span>, <span class="string">'rec.motorcycles'</span>:<span class="number">8</span>, <span class="string">'rec.sport.baseball'</span>:<span class="number">9</span>,\</div><div class="line">              <span class="string">'rec.sport.hockey'</span>:<span class="number">10</span>, <span class="string">'sci.crypt'</span>:<span class="number">11</span>, <span class="string">'sci.electronics'</span>:<span class="number">12</span>, <span class="string">'sci.med'</span>:<span class="number">13</span>,\</div><div class="line">              <span class="string">'sci.space'</span>:<span class="number">14</span>, <span class="string">'soc.religion.christian'</span>:<span class="number">15</span>, <span class="string">'talk.politics.guns'</span>:<span class="number">16</span>,\</div><div class="line">              <span class="string">'talk.politics.mideast'</span>:<span class="number">17</span>, <span class="string">'talk.politics.misc'</span>:<span class="number">18</span>, <span class="string">'talk.religion.misc'</span>:<span class="number">19</span>&#125;</div><div class="line"></div><div class="line"><span class="comment"># keyTolabels则将数字再转换回主题，主要是方便自己看的</span></div><div class="line">keyTolabels = &#123;<span class="number">0</span>:<span class="string">'alt.atheism'</span>, <span class="number">1</span>:<span class="string">'comp.graphics'</span>, <span class="number">2</span>:<span class="string">'comp.os.ms-windows.misc'</span>,\</div><div class="line">              <span class="number">3</span>:<span class="string">'comp.sys.ibm.pc.hardware'</span>, <span class="number">4</span>:<span class="string">'comp.sys.mac.hardware'</span>, <span class="number">5</span>:<span class="string">'comp.windows.x'</span>,\</div><div class="line">              <span class="number">6</span>:<span class="string">'misc.forsale'</span>, <span class="number">7</span>:<span class="string">'rec.autos'</span>, <span class="number">8</span>:<span class="string">'rec.motorcycles'</span>, <span class="number">9</span>:<span class="string">'rec.sport.baseball'</span>,\</div><div class="line">              <span class="number">10</span>:<span class="string">'rec.sport.hockey'</span>, <span class="number">11</span>:<span class="string">'sci.crypt'</span>, <span class="number">12</span>:<span class="string">'sci.electronics'</span>, <span class="number">13</span>:<span class="string">'sci.med'</span>,\</div><div class="line">              <span class="number">14</span>:<span class="string">'sci.space'</span>, <span class="number">15</span>:<span class="string">'soc.religion.christian'</span>, <span class="number">16</span>:<span class="string">'talk.politics.guns'</span>,\</div><div class="line">              <span class="number">17</span>:<span class="string">'talk.politics.mideast'</span>, <span class="number">18</span>:<span class="string">'talk.politics.misc'</span>, <span class="number">19</span>:<span class="string">'talk.religion.misc'</span>&#125;</div></pre></td></tr></table></figure>
<hr>
<p>###预处理函数<br>完成对文档的分词，去停用词，词干提取，同义词替换的工作，需要安装一个自然语言处理的第三方库nltk。当然，每个节点都需要安装。预处理的基本步骤如下：<br><img src="http://img.blog.csdn.net/20160117233401568" alt="预处理步骤"><br>这里的同义词替换做的非常简单，只是从单词的第一个同义词集里取出第一个同义词。这么做有时会产生歧义，因为单词在不同的语义下有不同的同义词集，只取第一个同义词集即限定了仅仅使用单词的第一个语义。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenlize</span><span class="params">(doc)</span>:</span></div><div class="line">    <span class="keyword">import</span> nltk, re</div><div class="line">    <span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords</div><div class="line">    <span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> wordnet</div><div class="line">    </div><div class="line">    r = re.compile(<span class="string">r'[\w]+'</span>) <span class="comment"># 以非字母数字字符来进行分词</span></div><div class="line">    my_stopwords = nltk.corpus.stopwords.words(<span class="string">'english'</span>)</div><div class="line">    porter = nltk.PorterStemmer()</div><div class="line">    </div><div class="line">    newdoc = []</div><div class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> nltk.regexp_tokenize(doc, r): <span class="comment"># 分词</span></div><div class="line">        newWord = porter.stem(word.lower()) <span class="comment"># 词干提取</span></div><div class="line">        <span class="keyword">if</span> newWord <span class="keyword">in</span> my_stopwords: <span class="comment"># 去停用词</span></div><div class="line">            <span class="keyword">continue</span></div><div class="line">        tokenSynsets = wordnet.synsets(newWord)</div><div class="line">        newdoc.append(newWord <span class="keyword">if</span> tokenSynsets == [] <span class="keyword">else</span> tokenSynsets[<span class="number">0</span>].lemma_names()[<span class="number">0</span>]) <span class="comment"># 同义词替换</span></div><div class="line">    <span class="keyword">return</span> newdoc</div></pre></td></tr></table></figure></p>
<hr>
<p>###导入训练集<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">trainTokens = sc.wholeTextFiles(trainPath)\</div><div class="line">                .map(<span class="keyword">lambda</span> (fileName, doc): doc)\</div><div class="line">                .map(<span class="keyword">lambda</span> doc: tokenlize(doc))</div></pre></td></tr></table></figure></p>
<hr>
<p>###构建单词映射哈希表，tfidf模型<br>训练集和测试集都需要使用这个哈希表，它的大小根据不同单词的数量来设置，一般取2的n方，在前期数据探索的时候需要计算一下不同单词的数量。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pyspark.mllib.feature <span class="keyword">import</span> HashingTF</div><div class="line">hasingTF = HashingTF(<span class="number">2</span> ** <span class="number">16</span>)</div><div class="line"></div><div class="line"><span class="comment"># 将训练集每个文档都映射为tf向量</span></div><div class="line">trainTf = hasingTF.transform(trainTokens)</div><div class="line">trainTf.cache()</div><div class="line"></div><div class="line"><span class="comment"># 构建IDF模型，训练集和测试集都用它</span></div><div class="line"><span class="keyword">from</span> pyspark.mllib.feature <span class="keyword">import</span> IDF</div><div class="line">idf = IDF().fit(trainTf)</div><div class="line"></div><div class="line"><span class="comment"># 将训练集每个tf向量转换为tfidf向量</span></div><div class="line">trainTfidf = idf.transform(trainTf)</div><div class="line">trainTfidf.cache()</div></pre></td></tr></table></figure></p>
<hr>
<p>###标注训练集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 为训练集标注，成为最终可用的训练集，每个样本都需要放在LabeledPoint里</span></div><div class="line"><span class="keyword">from</span> pyspark.mllib.regression <span class="keyword">import</span> LabeledPoint</div><div class="line">trainLabels = sc.wholeTextFiles(trainPath)\</div><div class="line">                .map(<span class="keyword">lambda</span> (path, doc): path.split(<span class="string">'/'</span>)[<span class="number">-2</span>])</div><div class="line">train = trainLabels.zip(trainTfidf)\</div><div class="line">                   .map(<span class="keyword">lambda</span> (topic, vector): LabeledPoint(labelsDict[topic], vector))</div><div class="line">train.cache()</div></pre></td></tr></table></figure>
<hr>
<p>###导入测试集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 导入测试集并完成预处理</span></div><div class="line">testTokens = sc.wholeTextFiles(testPath)\</div><div class="line">               .map(<span class="keyword">lambda</span> (fileName, doc): doc)\</div><div class="line">               .map(<span class="keyword">lambda</span> doc: tokenlize(doc))</div></pre></td></tr></table></figure>
<hr>
<p>###将测试集转换成tfidf向量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 将测试集每个文档都映射为tf向量，和训练集用的是同一个哈希映射hasingTF</span></div><div class="line"><span class="keyword">from</span> pyspark.mllib.feature <span class="keyword">import</span> HashingTF</div><div class="line">testTf = hasingTF.transform(testTokens)</div><div class="line"></div><div class="line"><span class="comment"># 将测试集每个tf向量转换为tfidf向量，和训练集用的是同一个IDF模型idf</span></div><div class="line"><span class="keyword">from</span> pyspark.mllib.feature <span class="keyword">import</span> IDF</div><div class="line">testTfidf = idf.transform(testTf)</div></pre></td></tr></table></figure>
<hr>
<p>###标注测试集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 为测试集标注，成为最终可用与测试的测试集</span></div><div class="line"><span class="keyword">from</span> pyspark.mllib.regression <span class="keyword">import</span> LabeledPoint</div><div class="line">testLabels = sc.wholeTextFiles(testPath)\</div><div class="line">               .map(<span class="keyword">lambda</span> (path, doc): path.split(<span class="string">'/'</span>)[<span class="number">-2</span>])</div><div class="line"></div><div class="line">test = testLabels.zip(testTfidf)\</div><div class="line">                 .map(<span class="keyword">lambda</span> (topic, vector): LabeledPoint(labelsDict[topic], vector))</div><div class="line">testCount = test.count()</div></pre></td></tr></table></figure>
<hr>
<h3 id="训练朴素贝叶斯模型并计算准确率"><a href="#训练朴素贝叶斯模型并计算准确率" class="headerlink" title="训练朴素贝叶斯模型并计算准确率"></a>训练朴素贝叶斯模型并计算准确率</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pyspark.mllib.classification <span class="keyword">import</span> NaiveBayes</div><div class="line">model = NaiveBayes.train(train, <span class="number">0.1</span>)</div><div class="line"></div><div class="line"><span class="comment"># 计算测试的准确率</span></div><div class="line">predictionAndLabel = test.map(<span class="keyword">lambda</span> p: (model.predict(p.features), p.label))</div><div class="line">accuracy = <span class="number">1.0</span> * predictionAndLabel.filter(<span class="keyword">lambda</span> x: x[<span class="number">0</span>] == x[<span class="number">1</span>]).count() / testCount</div><div class="line"><span class="keyword">print</span> accuracy</div></pre></td></tr></table></figure>
<pre><code>0.803298634582
</code></pre><hr>
<p>###训练多元逻辑回归模型并计算准确率</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span>  pyspark.mllib.classification <span class="keyword">import</span> LogisticRegressionWithLBFGS</div><div class="line">lrModel = LogisticRegressionWithLBFGS.train(train, iterations=<span class="number">10</span>, numClasses=<span class="number">20</span>)</div><div class="line"></div><div class="line"><span class="comment"># 计算测试的准确率</span></div><div class="line">predictionAndLabel = test.map(<span class="keyword">lambda</span> p: (lrModel.predict(p.features), p.label))</div><div class="line">accuracy = <span class="number">1.0</span> * predictionAndLabel.filter(<span class="keyword">lambda</span> x: x[<span class="number">0</span>] == x[<span class="number">1</span>]).count() / testCount</div><div class="line"><span class="keyword">print</span> accuracy</div></pre></td></tr></table></figure>
<pre><code>0.812897120454
</code></pre><hr>
<p>如果有兴趣，可以随便拿一份新闻组文本来测试一下，给自己一个更为直观的感受。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line">aTestText = <span class="string">"""</span></div><div class="line">Path: cantaloupe.srv.cs.cmu.edu!rochester!udel!bogus.sura.net!howland.reston.ans.net!ira.uka.de!math.fu-berlin.de!cs.tu-berlin.de!ossip</div><div class="line">From: ossip@cs.tu-berlin.de (Ossip Kaehr)</div><div class="line">Newsgroups: comp.sys.mac.hardware</div><div class="line">Subject: SE/30 8bit card does not work with 20mb..</div><div class="line">Date: 21 Apr 1993 23:22:22 GMT</div><div class="line">Organization: Technical University of Berlin, Germany</div><div class="line">Lines: 27</div><div class="line">Message-ID: &lt;1r4kve$6cl@news.cs.tu-berlin.de&gt;</div><div class="line">NNTP-Posting-Host: trillian.cs.tu-berlin.de</div><div class="line">Mime-Version: 1.0</div><div class="line">Content-Type: text/plain; charset=iso-8859-1</div><div class="line">Content-Transfer-Encoding: 8bit</div><div class="line">Summary: HELP!</div><div class="line">Keywords: SE/30 MODE32 System7 PDS</div><div class="line"></div><div class="line">Hello!</div><div class="line"></div><div class="line">I have a SE/30 and a Generation Systems 8bit PDS card for a 17"</div><div class="line">screen.</div><div class="line">It worked great until I upgraded from 5 to 20 mb ram.</div><div class="line">Now with Sys7.1 and MODE32 or 32enabler it does not boot..</div><div class="line"></div><div class="line">a tech support person said the card does not support these 32bit</div><div class="line">fixes.</div><div class="line"></div><div class="line">BUT: when pressing the shift key while booting (when the ext. monitor</div><div class="line">goes black after having been grey) the system  SOMETIMES boots properly!!</div><div class="line">and then works ok with the 20mb and full graphics.</div><div class="line"></div><div class="line">WHAT's HAPPENING???</div><div class="line"></div><div class="line">Thanks a lot for any advice!!!</div><div class="line">please answer by mail.</div><div class="line"></div><div class="line">Ossip Kaehr</div><div class="line">ossip@cs.tu-berlin.de</div><div class="line">voice: +49.30.6226317</div><div class="line">-- </div><div class="line"> __   --------------------------------------------------------------   __</div><div class="line">/_/\  Ossip Kaehr	Hermannstrasse 32  D-1000 Berlin 44  Germany  /\_\</div><div class="line">\_\/  Tel. +49.30.6223910 or 6218814     EMail ossip@cs.tu-berlin.de  \/_/</div><div class="line">      --------------------------------------------------------------</div><div class="line"></div><div class="line">"""</div></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">testTf = hasingTF.transform(tokenlize(aTestText)) <span class="comment"># 预处理后转换为tf向量</span></div><div class="line">testTfidf = idf.transform(testTf) <span class="comment"># 再转换成tfidf向量</span></div><div class="line"><span class="keyword">print</span> keyTolabels[lrModel.predict(testTfidf)] <span class="comment"># 预测并输出结果</span></div></pre></td></tr></table></figure>
<pre><code>&apos;comp.sys.mac.hardware&apos;
</code></pre><hr>
<p>###总结spark上如何将文档转换成tfidf向量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 构建哈希表用于映射所有单词</span></div><div class="line"><span class="keyword">from</span> pyspark.mllib.feature <span class="keyword">import</span> HashingTF</div><div class="line">hasingTF = HashingTF(<span class="number">2</span> ** <span class="number">16</span>) <span class="comment"># 维数需要大于不同单词的总数</span></div><div class="line"></div><div class="line"><span class="comment"># 将文档映射为tf向量，这里的trainTokens为rdd类型</span></div><div class="line">trainTf = hasingTF.transform(trainTokens)</div><div class="line">testTf = hasingTF.transform(testTokens)</div><div class="line"></div><div class="line"><span class="comment"># 构建IDF模型，训练集和测试集都用它</span></div><div class="line"><span class="keyword">from</span> pyspark.mllib.feature <span class="keyword">import</span> IDF</div><div class="line">idf = IDF().fit(trainTf)</div><div class="line"></div><div class="line"><span class="comment"># 将tf向量转换为tfidf向量</span></div><div class="line">trainTfidf = idf.transform(trainTf)</div><div class="line">testTfidf = idf.transform(testTf)</div></pre></td></tr></table></figure>
<hr>
<p>###相关阅读<br><a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" target="_blank" rel="external">https://en.wikipedia.org/wiki/Tf%E2%80%93idf</a><br><a href="https://en.wikipedia.org/wiki/Natural_Language_Toolkit" target="_blank" rel="external">https://en.wikipedia.org/wiki/Natural_Language_Toolkit</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/7233064.jpg"
               alt="Yiyang Peng" />
          <p class="site-author-name" itemprop="name">Yiyang Peng</p>
           
              <p class="site-description motion-element" itemprop="description">Try try try Never mind</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">32</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">38</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/yiyang186" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.zhihu.com/people/peng-yiyang-88" target="_blank" title="知乎">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  知乎
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yiyang Peng</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



  


  




	





  





  






  





  

  

  

  

  

  

</body>
</html>
