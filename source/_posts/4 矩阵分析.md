---
title: 矩阵的范数与导数
date: 2016-02-12 22:10:00
categories:
  - 数学
tags: 
  - 矩阵
---

# 向量范数
## 概念
向量x属于空间V，若有一种实值函数f(x)能将向量x映射为一个实数，记作f(x)=||x||，只要这个实值函数||x||满足
1）正定性：   		||x|| ≥ 0
2）齐次性：			||kx|| = |k|||x||（$k \in N$）
3）三角不等式：	||x+y|| ≤ ||x||+||y|| ( x,y均为V空间的向量)
那么这个函数||x||就可以用来表征向量x的大小，叫做向量x的范数。凡是满足这三个条件的的实值函数都能当做向量范数。这个有了范数的空间V也叫做赋范线性空间。

## 常用的向量范数
p-范数
向量{% raw %}$x=(x_1,x_2,...x_n)${% endraw %}, 定义向量x的p-范数为
{% raw %}$$||x||_p=(\sum_{i=1}^n|x_i|^p)^{1/p}, 1 \leq p \leq + \infty $${% endraw %}

|常用的向量范数     |求法                                   |
|------------------|---------------------------------------|
| {% raw %}$||x||_1${% endraw %}      |向量中所有元素的模的和                     |
| {% raw %}$||x||_2${% endraw %}      |向量中所有元素的模的平方和，再求和的平方根  |
| {% raw %}$||x||_p${% endraw %}      |向量中所有元素的模的p次幂的和，再对和开p次方|
| {% raw %}$||x||_\infty${% endraw %} |向量中所有元素的模的最大值|

# 矩阵范数
## 概念
定于矩阵A的一个实函数，记作f(A)=||A||，只要这个函数||A||满足
1）正定性：		    || A || ≥ 0
2）齐次性：			||k A || = |k||| A ||
3）三角不等式：	|| A +B|| ≤ || A ||+||B||
4)  相容性：			||AB|| ≤ ||A||||B||	（乘积不等式）
此时称||A||是矩阵A的范数，如果只满足前3个条件，那只是广义矩阵范数。
## 几种常见的矩阵范数
![这里写图片描述](http://img.blog.csdn.net/20160211144645736)

|常用的矩阵范数|名称|求法|
|:-------------|:-----------------|:---------------------------------------------------------------------|
|{% raw %}$||A||_1${% endraw %}|列和范数/列范数|对每一列求各个元素的模的和，有n列就有n个和，再取这些和的最大值|
|{% raw %}$||A||_∞${% endraw %}|行和范数/行范数|对每一行求各个元素的模的和，有n行就有n个和，再后取这些和的最大值|
|{% raw %}$||A||_2${% endraw %}|谱范数|$A^HA$的所有特征值中的最大值的平方根|


# 特征值估计
## 盖尔圆
方阵的盖尔圆所在的平面为复平面，x轴为实数，y轴为虚数，方阵的特征值只会出现在盖尔圆内。N阶方阵{% raw %}$A(a_{ij})${% endraw %}共有n个盖尔圆，它的第i个盖尔圆以{% raw %}$a_{ii}${% endraw %}为圆心,以
{% raw %}$$R_i = |a_{i1}| + |a_{i2}| + … + |a_{in}| - |a_{ii}|$${% endraw %}
为半径，即第i个盖尔圆的半径以矩阵第i行，除去对角元素的，其他所有元素的模的和。
第i个盖尔圆{% raw %}$G_i${% endraw %}的表示为
{% raw %}$$G_i = \{ Z |  |Z-a_{ii}| \leq Ri \}, Z \in C$${% endraw %}
有k个孤立的盖尔圆内则至少有k个相异的特征值，相交的盖尔圆内可能有重根。

# 矩阵函数
## 概念
- 矩阵函数
如果矩阵A中的每个元素{% raw %}$a_{ij}(t)${% endraw %}都是变量t的函数，则称A(t)为矩阵函数。如果矩阵的每个元素都有极限，则这个矩阵函数也有极限。

- 矩阵序列
矩阵序列{% raw %}$A(k)_{m \times n}, k  \in N${% endraw %}, 共有$m \times n$个元素，那么就有$m \times n$组数列， 当每个数列{% raw %}$\{a_{ij}(k)\}${% endraw %}均分别收敛于相应的极限{% raw %}$a_{ij}${% endraw %}时，则矩阵序列{A(t)}收敛于A, 其中A由{% raw %}$a_{ij}${% endraw %}组成。

- 谱半径
矩阵A所有特征值的模的最大值

- 单纯矩阵与矩阵函数
对于可对角化的单纯矩阵而言，f(A)的特征值就是f(λ)，可用来求f(A)的谱分解和谱半径

## 判断矩阵幂级数敛散性
1. 考虑矩阵幂级数$\sum A(k)$, 先把矩阵A换成未知数x，计算这个数项幂级数$\sum x(k)$的收敛半径R
2. 求矩阵A的特征值，并计算其谱半径{% raw %}$\rho (λ)$ {% endraw %} (特征值模的最大值)
3. 若{% raw %}$\rho (\lambda)<R${% endraw %},则矩阵幂级数绝对收敛;<br>若{% raw %}$\rho (\lambda)>R${% endraw %},则发散.
4. 若$\rho (λ)=R$，上述方法失效，可计算A(k)的Jordan形，$A(n)=P^{-1}J(k)P$，通过证明J(k)的敛散来证明A(k)的敛散，进而证明$\sum A(k)$的敛散。
5. J(k)的每个元素都是关于n的级数，看看当n->∞时，所有元素是不是都收敛，有一个不收敛就是发散，都收敛时，A的矩阵幂级数才收敛
![这里写图片描述](http://img.blog.csdn.net/20160211151215293)

## 矩阵函数的计算方法
- Jordan标准型法（不推荐）
1）求m阶矩阵A的Jordan标准形J和可逆阵P, $P^{-1}$，使得$P^{-1}AP=J$
2）求f(J), {% raw %}$f(J)=diag(f(J_1), f(J_2), \dots f(J_m))${% endraw %}，其中{% raw %}$f(J_i)_{r \times r}${% endraw %}
3）$f(A)=Pf(J)P^{-1}$

![这里写图片描述](http://img.blog.csdn.net/20160211152030968)

- 待定系数法(推荐)
1）求A的最小式，得到最小次的总次数degmA(λ)=k
2）令{% raw %}$p(λ)=b_0+b_1λ+b_2λ^2+…+b_{k-1}λ^{k-1}${% endraw %}， k是几就有几个b, {% raw %}$b_0 \dots b_{k-1}${% endraw %}
3）列方程组
{% raw %}$p(λ_i)= f(λ_i)${% endraw %}
若{% raw %}$λ_i${% endraw %}是2重根，则再设{% raw %}$p’(λ_i)= f’(λ_i)${% endraw %}
如f(A)=sinA, {% raw %}$m_{A(λ)}=( λ-2)^2( λ-1)${% endraw %}，令{% raw %}$p(λ)= b_0+b_1λ+b_2λ^2${% endraw %},要满足的方程组为

{% raw %}
$$
\left\{
\begin{array}{c}
P(1)=sin1 \\
P(2)=sin2 \\
P’(2)=cos2
\end{array}
\right.
$$
{% endraw %}	

即

{% raw %}
$$
\left\{
\begin{array}{c}
b0+b1+b2=sin1 \\
b0+2b1+4b2=sin2 \\
b1+4b2=cos2
\end{array}
\right.
$$
{% endraw %}

4）解出{% raw %}$b_i${% endraw %}，即解出了p(λ), 把p(λ)换成A就是p(A), 最后f (A)= p(A)
![这里写图片描述](http://img.blog.csdn.net/20160211153159811)


# 矩阵求导
矩阵求导包括标量，行向量$x^T$, 列向量x，矩阵之间的求导。
## 矩阵Y=F(x)对标量x求导
相当于矩阵{% raw %}$Y_{m \times n}${% endraw %}中的每个元素对x求导，转化为$m \times n$次普通的求导
![这里写图片描述](http://img.blog.csdn.net/20160212165402569)
## 标量y对列向量x求导
相当于标量y对列向量x的每个分量求偏导，再组成一个新的列向量
![这里写图片描述](http://img.blog.csdn.net/20160212165451757)


## 行向量$y^T$对列向量x求导
相当于行向量$y^T$的每一个分量作为标量对列向量x求导，转化为标量对列向量x求导的情况。考虑{% raw %}$y^T=(y_1, y_2, \dots y_n)^T, x=(x_1, x_2, \dots, x_m)${% endraw %}，则y的n个分量都对x的求导，得到n个维度为m的列向量，最后这n个列向量再组成m行n列的矩阵。
![这里写图片描述](http://img.blog.csdn.net/20160212165526790)

注意：
1. $1 \times n$的行向量对$m \times 1$的列向量求导后是$m \times n$的矩阵。
2. 重要结论：
$${dx^T \over dx} = I$$$${d(Ax)^T \over dx} = A^T$$

## 列向量y对行向量$x^T$求导
转化为行向量$y^T$对列向量 x 的导数，然后转置。
![这里写图片描述](http://img.blog.csdn.net/20160212165614369)
注意
1. m×1 向量对 1×n 向量求导结果为 m×n 矩阵。
2. 重要结论：
$${dx \over dx^T} = ({dx^T \over dx})^T=I$$$${d(Ax) \over dx^T} =({d(Ax)^T \over dx})^T = (A^T)^T=A$$

## 向量积$u^Tv$对列向量x求导的运算法则
$${d(u^Tv) \over dx}={d(u^T) \over dx} \cdot v+{d(v^T) \over dx} \cdot u$$
例如：$${d(x^Tx) \over dx}={d(x^T) \over dx} \cdot x+{d(x^T) \over dx} \cdot x=I \cdot x + I \cdot x =2x$$$${d(x^TAx) \over dx}={d(x^T) \over dx} \cdot Ax+{d(Ax)^T \over dx} \cdot x=I \cdot Ax + A^T \cdot x =(A+A^T)x$$

## 矩阵Y对列向量x求导
将Y对x的每一个分量求偏导，构成一个超列向量，超向量中的每个分量都是一个矩阵。转化为矩阵对标量求导的情况。
![这里写图片描述](http://img.blog.csdn.net/20160212215141519)
注意：矩阵对列向量求导的结果是以矩阵作为分量的超向量。

## 矩阵Y对行向量$x^T$求导
相当于Y对$x^T$的每一个分量求偏导，结果是个超级行向量。
{% raw %}$$Y=F(x) \rightarrow {dY \over dx^T}=[{∂F \over ∂x_1} \ {∂F \over ∂x_2}\  \dots \ {∂F \over ∂x_n}] $${% endraw %}


## 标量y对矩阵X求导
相当于标量y对矩阵X中的每个元素求导，结果是个和矩阵X行列相等的矩阵
![这里写图片描述](http://img.blog.csdn.net/20160212215644947)

重要结论：$${d(u^TXv) \over dX} = u \cdot v^T$$$${d[(Xu)^TXu] \over dX} = 2Xu \cdot u^T$$$${d[(Xu-v)^T(Xu-v)] \over dX} = 2(Xu-v)u^T$$

## 矩阵Y对矩阵X求导
将矩阵{% raw %}$Y_{m \times n}${% endraw %}的每个元素对矩阵X求导，转化为$m \times n$个标量对矩阵{% raw %}$X_{s \times r}${% endraw %}求导，最后排起来得到$m \times n$的超级矩阵，其中每个元素为$s \times r$的矩阵。
矩阵对矩阵求导的结果是以矩阵作为元素的超级矩阵。