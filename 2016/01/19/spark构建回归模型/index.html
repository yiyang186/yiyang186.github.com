<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="spark,python," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="###加载数据集数据集为Bike-Sharing-Dataset12345678path = &quot;hdfs:///user/yy/Bike-Sharing-Dataset/hour_noheader.csv&quot;raw_data = sc.textFile(path)num_data = raw_data.count()records = raw_data.map(lambda x: x.split(&quot;">
<meta name="keywords" content="spark,python">
<meta property="og:type" content="article">
<meta property="og:title" content="在spark上做简单的回归">
<meta property="og:url" content="http://yoursite.com/2016/01/19/spark构建回归模型/index.html">
<meta property="og:site_name" content="Yiyang&#39;s Blog">
<meta property="og:description" content="###加载数据集数据集为Bike-Sharing-Dataset12345678path = &quot;hdfs:///user/yy/Bike-Sharing-Dataset/hour_noheader.csv&quot;raw_data = sc.textFile(path)num_data = raw_data.count()records = raw_data.map(lambda x: x.split(&quot;">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://img.blog.csdn.net/20160119151242014">
<meta property="og:image" content="http://img.blog.csdn.net/20160119151303592">
<meta property="og:image" content="http://img.blog.csdn.net/20160119151334608">
<meta property="og:image" content="http://img.blog.csdn.net/20160119151735437">
<meta property="og:image" content="http://img.blog.csdn.net/20160119151750953">
<meta property="og:image" content="http://img.blog.csdn.net/20160119151809922">
<meta property="og:image" content="http://img.blog.csdn.net/20160119151831845">
<meta property="og:image" content="http://img.blog.csdn.net/20160119151850689">
<meta property="og:image" content="http://img.blog.csdn.net/20160119151911393">
<meta property="og:image" content="http://img.blog.csdn.net/20160119151926877">
<meta property="og:image" content="http://img.blog.csdn.net/20160119152107317">
<meta property="og:updated_time" content="2017-07-26T14:40:09.538Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="在spark上做简单的回归">
<meta name="twitter:description" content="###加载数据集数据集为Bike-Sharing-Dataset12345678path = &quot;hdfs:///user/yy/Bike-Sharing-Dataset/hour_noheader.csv&quot;raw_data = sc.textFile(path)num_data = raw_data.count()records = raw_data.map(lambda x: x.split(&quot;">
<meta name="twitter:image" content="http://img.blog.csdn.net/20160119151242014">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2016/01/19/spark构建回归模型/"/>





  <title>在spark上做简单的回归 | Yiyang's Blog</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?3b9de7582df94dad7be13b2e75675386";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->










</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Yiyang's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404.html" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br />
            
            公益404
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/01/19/spark构建回归模型/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yiyang Peng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/7233064.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yiyang's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">在spark上做简单的回归</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-01-19T15:24:00+08:00">
                2016-01-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>###加载数据集<br>数据集为<a href="http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset" target="_blank" rel="external">Bike-Sharing-Dataset</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">path = <span class="string">"hdfs:///user/yy/Bike-Sharing-Dataset/hour_noheader.csv"</span></div><div class="line">raw_data = sc.textFile(path)</div><div class="line">num_data = raw_data.count()</div><div class="line">records = raw_data.map(<span class="keyword">lambda</span> x: x.split(<span class="string">","</span>))</div><div class="line">records.cache()</div><div class="line">first = records.first()</div><div class="line"><span class="keyword">print</span> first</div><div class="line"><span class="keyword">print</span> num_data</div></pre></td></tr></table></figure></p>
<pre><code>[u&apos;1&apos;, u&apos;2011-01-01&apos;, u&apos;1&apos;, u&apos;0&apos;, u&apos;1&apos;, u&apos;0&apos;, u&apos;0&apos;, u&apos;6&apos;, u&apos;0&apos;, u&apos;1&apos;, u&apos;0.24&apos;, u&apos;0.2879&apos;, u&apos;0.81&apos;, u&apos;0&apos;, u&apos;3&apos;, u&apos;13&apos;, u&apos;16&apos;]
17379
</code></pre><hr>
<p>###为线性回归模型准备数据集<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 将特征映射到二元编码向量的映射函数</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_mapping</span><span class="params">(rdd, idx)</span>:</span></div><div class="line">    <span class="keyword">return</span> rdd.map(<span class="keyword">lambda</span> fields: fields[idx])\</div><div class="line">              .distinct()\</div><div class="line">              .zipWithIndex()\</div><div class="line">              .collectAsMap()</div></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 查看映射字典结构</span></div><div class="line"><span class="keyword">print</span> <span class="string">"Mapping of first categorical feature column: %s"</span> % get_mapping(records, <span class="number">2</span>)</div></pre></td></tr></table></figure>
<pre><code>Mapping of first categorical feature column: {u&apos;1&apos;: 0, u&apos;3&apos;: 1, u&apos;2&apos;: 2, u&apos;4&apos;: 3}
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 建立将特征映射到二元编码向量的映射字典</span></div><div class="line">mappings = [get_mapping(records, i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>, <span class="number">10</span>)]</div><div class="line">cat_len = sum(map(len, mappings))</div><div class="line">num_len = len(records.first()[<span class="number">11</span>:<span class="number">15</span>])</div><div class="line">total_len = num_len + cat_len</div><div class="line"><span class="keyword">print</span> <span class="string">"Feature vector length for categorical features: %d"</span> % cat_len</div><div class="line"><span class="keyword">print</span> <span class="string">"Feature vector length for numerical features: %d"</span> % num_len</div><div class="line"><span class="keyword">print</span> <span class="string">"Total feature vector length: %d"</span> % total_len</div></pre></td></tr></table></figure>
<pre><code>Feature vector length for categorical features: 57
Feature vector length for numerical features: 4
Total feature vector length: 61
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pyspark.mllib.regression <span class="keyword">import</span> LabeledPoint</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"><span class="comment"># 用于建立二元编码的特征向量</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_features</span><span class="params">(record)</span>:</span></div><div class="line">    cat_vec = np.zeros(cat_len)</div><div class="line">    i = <span class="number">0</span></div><div class="line">    step = <span class="number">0</span></div><div class="line">    <span class="keyword">for</span> field <span class="keyword">in</span> record[<span class="number">2</span>:<span class="number">9</span>]:</div><div class="line">        m = mappings[i]</div><div class="line">        idx = m[field]</div><div class="line">        cat_vec[idx+step] = <span class="number">1</span></div><div class="line">        i += <span class="number">1</span></div><div class="line">        step += len(m)</div><div class="line">    num_vec = np.array([float(field) <span class="keyword">for</span> field <span class="keyword">in</span> record[<span class="number">10</span>:<span class="number">14</span>]])</div><div class="line">    <span class="keyword">return</span> np.concatenate((cat_vec, num_vec))</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_label</span><span class="params">(record)</span>:</span></div><div class="line">    <span class="keyword">return</span> float(record[<span class="number">-1</span>])</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 对每条记录提取特征向量（使用二元编码）和标签</span></div><div class="line">data = records.map(<span class="keyword">lambda</span> r: LabeledPoint(extract_label(r), extract_features(r)))</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 查看使用了二元编码的训练样本结构</span></div><div class="line">first_point = data.first()</div><div class="line"><span class="keyword">print</span> <span class="string">"Raw data: "</span> + str(first[<span class="number">2</span>:])</div><div class="line"><span class="keyword">print</span> <span class="string">"Label: "</span> + str(first_point.label)</div><div class="line"><span class="keyword">print</span> <span class="string">"Linear Model feature vector:\n"</span> + str(first_point.features)</div><div class="line"><span class="keyword">print</span> <span class="string">"Linear Model feature vector length: "</span> + str(len(first_point.features))</div></pre></td></tr></table></figure>
<pre><code>Raw data: [u&apos;1&apos;, u&apos;0&apos;, u&apos;1&apos;, u&apos;0&apos;, u&apos;0&apos;, u&apos;6&apos;, u&apos;0&apos;, u&apos;1&apos;, u&apos;0.24&apos;, u&apos;0.2879&apos;, u&apos;0.81&apos;, u&apos;0&apos;, u&apos;3&apos;, u&apos;13&apos;, u&apos;16&apos;]
Label: 16.0
Linear Model feature vector:
[1.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.24,0.2879,0.81,0.0]
Linear Model feature vector length: 61
</code></pre><hr>
<p>###为决策回归树准备数据集<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 决策回归树不需要将类型数据用二元编码表示</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_features_dt</span><span class="params">(record)</span>:</span></div><div class="line">    <span class="keyword">return</span> np.array(map(float, record[<span class="number">2</span>:<span class="number">14</span>]))</div></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 对每条记录提取特征向量（未使用二元编码）和标签</span></div><div class="line">data_dt = records.map(<span class="keyword">lambda</span> r: LabeledPoint(extract_label(r), extract_features_dt(r)))</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 查看未使用二元编码的训练样本结构</span></div><div class="line">first_point_dt = data_dt.first()</div><div class="line"><span class="keyword">print</span> <span class="string">"Label: "</span> + str(first_point_dt.label)</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree feature vector: "</span> + str(first_point_dt.features)</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree feature vector length: "</span> + str(len(first_point_dt.features))</div></pre></td></tr></table></figure>
<pre><code>Label: 16.0
Decision Tree feature vector: [1.0,0.0,1.0,0.0,0.0,6.0,0.0,1.0,0.24,0.2879,0.81,0.0]
Decision Tree feature vector length: 12
</code></pre><hr>
<p>###线性回归和决策回归树的帮助文档<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pyspark.mllib.regression <span class="keyword">import</span> LinearRegressionWithSGD</div><div class="line"><span class="keyword">from</span> pyspark.mllib.tree <span class="keyword">import</span> DecisionTree</div></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">help(LinearRegressionWithSGD.train)</div></pre></td></tr></table></figure>
<pre><code>Help on method train in module pyspark.mllib.regression:

train(cls, data, iterations=100, step=1.0, miniBatchFraction=1.0, initialWeights=None, regParam=0.0, regType=None, intercept=False, validateData=True) method of __builtin__.type instance
    Train a linear regression model using Stochastic Gradient
    Descent (SGD).
    This solves the least squares regression formulation
            f(weights) = 1/n ||A weights-y||^2^
    (which is the mean squared error).
    Here the data matrix has n rows, and the input RDD holds the
    set of rows of A, each with its corresponding right hand side
    label y. See also the documentation for the precise formulation.

    :param data:              The training data, an RDD of
                              LabeledPoint.
    :param iterations:        The number of iterations
                              (default: 100).
    :param step:              The step parameter used in SGD
                              (default: 1.0).
    :param miniBatchFraction: Fraction of data to be used for each
                              SGD iteration (default: 1.0).
    :param initialWeights:    The initial weights (default: None).
    :param regParam:          The regularizer parameter
                              (default: 0.0).
    :param regType:           The type of regularizer used for
                              training our model.

                              :Allowed values:
                                 - &quot;l1&quot; for using L1 regularization (lasso),
                                 - &quot;l2&quot; for using L2 regularization (ridge),
                                 - None for no regularization

                                 (default: None)

    :param intercept:         Boolean parameter which indicates the
                              use or not of the augmented representation
                              for training data (i.e. whether bias
                              features are activated or not,
                              default: False).
    :param validateData:      Boolean parameter which indicates if
                              the algorithm should validate data
                              before training. (default: True)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">help(DecisionTree.trainRegressor)</div></pre></td></tr></table></figure>
<pre><code>Help on method trainRegressor in module pyspark.mllib.tree:

trainRegressor(cls, data, categoricalFeaturesInfo, impurity=&apos;variance&apos;, maxDepth=5, maxBins=32, minInstancesPerNode=1, minInfoGain=0.0) method of __builtin__.type instance
    Train a DecisionTreeModel for regression.

    :param data: Training data: RDD of LabeledPoint.
                 Labels are real numbers.
    :param categoricalFeaturesInfo: Map from categorical feature
             index to number of categories.
             Any feature not in this map is treated as continuous.
    :param impurity: Supported values: &quot;variance&quot;
    :param maxDepth: Max depth of tree.
             E.g., depth 0 means 1 leaf node.
             Depth 1 means 1 internal node + 2 leaf nodes.
    :param maxBins: Number of bins used for finding splits at each
             node.
    :param minInstancesPerNode: Min number of instances required at
             child nodes to create the parent split
    :param minInfoGain: Min info gain required to create a split
    :return: DecisionTreeModel

    Example usage:

    &gt;&gt;&gt; from pyspark.mllib.regression import LabeledPoint
    &gt;&gt;&gt; from pyspark.mllib.tree import DecisionTree
    &gt;&gt;&gt; from pyspark.mllib.linalg import SparseVector
    &gt;&gt;&gt;
    &gt;&gt;&gt; sparse_data = [
    ...     LabeledPoint(0.0, SparseVector(2, {0: 0.0})),
    ...     LabeledPoint(1.0, SparseVector(2, {1: 1.0})),
    ...     LabeledPoint(0.0, SparseVector(2, {0: 0.0})),
    ...     LabeledPoint(1.0, SparseVector(2, {1: 2.0}))
    ... ]
    &gt;&gt;&gt;
    &gt;&gt;&gt; model = DecisionTree.trainRegressor(sc.parallelize(sparse_data), {})
    &gt;&gt;&gt; model.predict(SparseVector(2, {1: 1.0}))
    1.0
    &gt;&gt;&gt; model.predict(SparseVector(2, {1: 0.0}))
    0.0
    &gt;&gt;&gt; rdd = sc.parallelize([[0.0, 1.0], [0.0, 0.0]])
    &gt;&gt;&gt; model.predict(rdd).collect()
    [1.0, 0.0]
</code></pre><hr>
<p>###训练回归模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 训练线性回归模型,后面会慢慢改进</span></div><div class="line">linear_model = LinearRegressionWithSGD.train(data, iterations=<span class="number">50</span>, step=<span class="number">0.1</span>, intercept=<span class="keyword">False</span>)</div><div class="line">true_vs_predicted = data.map(<span class="keyword">lambda</span> p: (p.label, linear_model.predict(p.features)))</div><div class="line"><span class="keyword">print</span>  <span class="string">"Linear Model predictions: "</span> + str(true_vs_predicted.take(<span class="number">5</span>))</div></pre></td></tr></table></figure>
<pre><code>Linear Model predictions: [(16.0, 110.54561916607503), (40.0, 107.92836240337226), (32.0, 107.45239452594706), (13.0, 107.46860142170017), (1.0, 107.19840815670955)]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 训练决策回归模型,后面会慢慢改进</span></div><div class="line">dt_model = DecisionTree.trainRegressor(data_dt, &#123;&#125;)</div><div class="line">preds = dt_model.predict(data_dt.map(<span class="keyword">lambda</span> p: p.features))</div><div class="line">actual = data.map(<span class="keyword">lambda</span> p: p.label)</div><div class="line">true_vs_predicted_dt = actual.zip(preds)</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree predictions: "</span> + str(true_vs_predicted_dt.take(<span class="number">5</span>))</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree depth: "</span> + str(dt_model.depth())</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree number of nodes: "</span> + str(dt_model.numNodes())</div></pre></td></tr></table></figure>
<pre><code>Decision Tree predictions: [(16.0, 54.913223140495866), (40.0, 54.913223140495866), (32.0, 53.171052631578945), (13.0, 14.284023668639053), (1.0, 14.284023668639053)]
Decision Tree depth: 5
Decision Tree number of nodes: 63
</code></pre><hr>
<p>###评估回归模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 几个计算误差的函数</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">squared_error</span><span class="params">(actual, pred)</span>:</span></div><div class="line">    <span class="keyword">return</span> (pred - actual) ** <span class="number">2</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">abs_error</span><span class="params">(actual, pred)</span>:</span></div><div class="line">    <span class="keyword">return</span> np.abs(pred - actual)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">squared_log_error</span><span class="params">(pred, actual)</span>:</span></div><div class="line">    <span class="keyword">return</span> (np.log(pred+<span class="number">1</span>) - np.log(actual+<span class="number">1</span>)) ** <span class="number">2</span></div><div class="line"></div><div class="line"><span class="comment"># 评估函数</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">myEvaluation</span><span class="params">(true_vs_predicted)</span>:</span></div><div class="line">    mse = true_vs_predicted.map(<span class="keyword">lambda</span> (t,p): squared_error(t,p)).mean()</div><div class="line">    mae = true_vs_predicted.map(<span class="keyword">lambda</span> (t,p): abs_error(t,p)).mean()</div><div class="line">    rmsle = np.sqrt(true_vs_predicted.map(<span class="keyword">lambda</span> (t,p): squared_log_error(t,p)).mean())</div><div class="line">    <span class="keyword">return</span> (mse, mae, rmsle)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估线性回归模型</span></div><div class="line">mse ,mae ,rmsle = myEvaluation(true_vs_predicted)</div><div class="line"><span class="keyword">print</span> <span class="string">"Linear Model - Mean Squared Error: %2.4f"</span> % mse</div><div class="line"><span class="keyword">print</span> <span class="string">"Linear Model - Mean Absolute Error: %2.4f"</span> % mae</div><div class="line"><span class="keyword">print</span> <span class="string">"Linear Model - Root Mean Squared Log Error: %2.4f"</span> % rmsle</div><div class="line"><span class="comment"># 1.46只达到了kaggle上的平均成绩</span></div></pre></td></tr></table></figure>
<pre><code>Linear Model - Mean Squared Error: 27408.1527
Linear Model - Mean Absolute Error: 127.4103
Linear Model - Root Mean Squared Log Error: 1.4847
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估决策回归模型</span></div><div class="line">mse_dt ,mae_dt ,rmsle_dt = myEvaluation(true_vs_predicted_dt)</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree - Mean Squared Error: %2.4f"</span> % mse_dt</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree - Mean Absolute Error: %2.4f"</span> % mae_dt</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree - Root Mean Squared Log Error: %2.4f"</span> % rmsle_dt</div><div class="line"><span class="comment"># 最好成绩是0.2左右，0.6只能算马马虎虎</span></div></pre></td></tr></table></figure>
<pre><code>Decision Tree - Mean Squared Error: 11560.7978
Decision Tree - Mean Absolute Error: 71.0969
Decision Tree - Root Mean Squared Log Error: 0.6259
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">%matplotlib inline</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line"><span class="comment"># 通过画直方图来检查目标值的分布情况</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">checkTargets</span><span class="params">(targets)</span>:</span></div><div class="line">    plt.hist(targets, bins=<span class="number">40</span>, color=<span class="string">'lightblue'</span>, normed=<span class="keyword">True</span>)</div><div class="line">    fig = plt.gcf()</div><div class="line">    fig.set_size_inches(<span class="number">16</span>,<span class="number">10</span>)</div></pre></td></tr></table></figure>
<hr>
<p>###目标变量分布</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 对于线性回归模型,当目标变量服从正态分布,误差项满足高斯--马尔科夫条件（零均值、等方差、不相关）时,回归参数的最小二乘估计是一致最小方差无偏估计. 显然这里的响应变量并不服从正态分布</span></div><div class="line">targets = records.map(<span class="keyword">lambda</span> r: float(r[<span class="number">-1</span>])).collect()</div><div class="line">checkTargets(targets)</div></pre></td></tr></table></figure>
<p><img src="http://img.blog.csdn.net/20160119151242014" alt="这里写图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 对目标值，即响应变量（因变量）进行对数变换，并查看变换后的分布</span></div><div class="line">log_targets = records.map(<span class="keyword">lambda</span> r: np.log(float(r[<span class="number">-1</span>]))).collect()</div><div class="line">checkTargets(log_targets)</div></pre></td></tr></table></figure>
<p><img src="http://img.blog.csdn.net/20160119151303592" alt="这里写图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 对目标值，即响应变量（因变量）进行平方根变换，并查看变换后的分布</span></div><div class="line">log_targets = records.map(<span class="keyword">lambda</span> r: np.sqrt(float(r[<span class="number">-1</span>]))).collect()</div><div class="line">checkTargets(log_targets)</div></pre></td></tr></table></figure>
<p><img src="http://img.blog.csdn.net/20160119151334608" alt="这里写图片描述"></p>
<hr>
<p>###对目标变量作对数变换后重新训练并评估<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 用对数变换后的目标值重新训练线性回归模型</span></div><div class="line">data_log = data.map(<span class="keyword">lambda</span> lp: LabeledPoint(np.log(lp.label), lp.features))</div><div class="line">model_log = LinearRegressionWithSGD.train(data_log, iterations=<span class="number">50</span>, step=<span class="number">0.1</span>)</div><div class="line">true_vs_predicted_log = data_log.map(<span class="keyword">lambda</span> p: (np.exp(p.label), np.exp(model_log.predict(p.features))))</div></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估</span></div><div class="line">mse_log, mae_log, rmsle_log = myEvaluation(true_vs_predicted_log)</div><div class="line"><span class="keyword">print</span> <span class="string">"Linear Model - Mean Squared Error: %2.4f"</span> % mse_log</div><div class="line"><span class="keyword">print</span> <span class="string">"Linear Model - Mean Absolute Error: %2.4f"</span> % mae_log</div><div class="line"><span class="keyword">print</span> <span class="string">"Linear Model - Root Mean Squared Log Error: %2.4f"</span> % rmsle_log</div><div class="line"><span class="keyword">print</span> <span class="string">"Non log-transformed predictions:\n"</span> + str(true_vs_predicted.take(<span class="number">3</span>))</div><div class="line"><span class="keyword">print</span> <span class="string">"Log-transformed predictions:\n"</span> + str(true_vs_predicted_log.take(<span class="number">3</span>))</div></pre></td></tr></table></figure>
<pre><code>Linear Model - Mean Squared Error: 37837.3776
Linear Model - Mean Absolute Error: 133.6572
Linear Model - Root Mean Squared Log Error: 1.3315
Non log-transformed predictions:
[(16.0, 110.54561916607503), (40.0, 107.92836240337226), (32.0, 107.45239452594706)]
Log-transformed predictions:
[(15.999999999999998, 45.336304060846494), (40.0, 42.455963122588777), (32.0, 41.297013243855893)]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 用对数变换后的目标值重新训练决策回归树模型</span></div><div class="line">data_dt_log = data_dt.map(<span class="keyword">lambda</span> lp: LabeledPoint(np.log(lp.label), lp.features))</div><div class="line">dt_model_log = DecisionTree.trainRegressor(data_dt_log, &#123;&#125;)</div><div class="line">preds_log = dt_model_log.predict(data_dt_log.map(<span class="keyword">lambda</span> p: p.features))</div><div class="line">actual_log = data_dt_log.map(<span class="keyword">lambda</span> p: p.label)</div><div class="line">true_vs_predicted_dt_log = actual_log.zip(preds_log).map(<span class="keyword">lambda</span> (t,p): (np.exp(t), np.exp(p)))</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估</span></div><div class="line">mse_log_dt, mae_log_dt, rmsle_log_dt = myEvaluation(true_vs_predicted_dt_log)</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree - Mean Squared Error: %2.4f"</span> % mse_log_dt</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree - Mean Absolute Error: %2.4f"</span> % mae_log_dt</div><div class="line"><span class="keyword">print</span> <span class="string">"Decision Tree - Root Mean Squared Log Error: %2.4f"</span> % rmsle_log_dt</div><div class="line"><span class="keyword">print</span> <span class="string">"Non log-transformed predictions:\n"</span> + str(true_vs_predicted_dt.take(<span class="number">3</span>))</div><div class="line"><span class="keyword">print</span> <span class="string">"Log-transformed predictions:\n"</span> + str(true_vs_predicted_dt_log.take(<span class="number">3</span>))</div></pre></td></tr></table></figure>
<pre><code>Decision Tree - Mean Squared Error: 14781.5760
Decision Tree - Mean Absolute Error: 76.4131
Decision Tree - Root Mean Squared Log Error: 0.6406
Non log-transformed predictions:
[(16.0, 54.913223140495866), (40.0, 54.913223140495866), (32.0, 53.171052631578945)]
Log-transformed predictions:
[(15.999999999999998, 37.530779787154522), (40.0, 37.530779787154522), (32.0, 7.2797070993907287)]
</code></pre><hr>
<p>###为数据集划分训练集与测试集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 对用于线性回归的数据集，按2：8划分测试集与训练集</span></div><div class="line">data_with_idx = data.zipWithIndex().map(<span class="keyword">lambda</span> (k,v): (v,k)) <span class="comment"># 给每个样本加上序号，再反转键值对</span></div><div class="line">test = data_with_idx.sample(<span class="keyword">False</span>, <span class="number">0.2</span>, <span class="number">42</span>) <span class="comment"># 参数：不重复抽样，抽样20%，随机数种子42</span></div><div class="line">train = data_with_idx.subtractByKey(test) <span class="comment"># 从data_with_idx中抽掉（去掉）与test的key（样本序号）相等的样本</span></div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 形成可用于训练和测试的</span></div><div class="line">train_data = train.map(<span class="keyword">lambda</span> (idx,p): p)</div><div class="line">test_data = test.map(<span class="keyword">lambda</span> (idx,p): p)</div><div class="line">train_size = train_data.count()</div><div class="line">test_size = test_data.count()</div><div class="line"><span class="keyword">print</span> <span class="string">"Train data size: %d"</span> % train_size</div><div class="line"><span class="keyword">print</span> <span class="string">"Test data size: %d"</span> % test_size</div><div class="line"><span class="keyword">print</span> <span class="string">"Total data size: %d"</span> % num_data</div><div class="line"><span class="keyword">print</span> <span class="string">"Train + Test size: %d"</span> % (train_size+test_size)</div></pre></td></tr></table></figure>
<pre><code>Train data size: 13934
Test data size: 3445
Total data size: 17379
Train + Test size: 17379
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 对用于决策回归的数据集，按2：8划分测试集与训练集</span></div><div class="line">data_with_idx_dt = data_dt.zipWithIndex().map(<span class="keyword">lambda</span> (k,v): (v,k))</div><div class="line">test_dt = data_with_idx_dt.sample(<span class="keyword">False</span>, <span class="number">0.2</span>, <span class="number">42</span>)</div><div class="line">train_dt = data_with_idx_dt.subtractByKey(test_dt)</div><div class="line">train_data_dt = train_dt.map(<span class="keyword">lambda</span> (idx,p): p)</div><div class="line">test_data_dt = test_dt.map(<span class="keyword">lambda</span> (idx,p): p)</div></pre></td></tr></table></figure>
<hr>
<p>###对线性回归模型的参数调优</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 用于在不同参数配置下评估线性回归模型的性能</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(train, test, iterations, step, regParam, regType, intercept)</span>:</span></div><div class="line">    model = LinearRegressionWithSGD.train(train, iterations, step, regParam=regParam, \</div><div class="line">                                          regType=regType, intercept=intercept)</div><div class="line">    tp = test.map(<span class="keyword">lambda</span> p: (p.label, model.predict(p.features)))</div><div class="line">    rmsle = np.sqrt(tp.map(<span class="keyword">lambda</span> (t,p): squared_log_error(t,p)).mean())</div><div class="line">    <span class="keyword">return</span> rmsle</div><div class="line"></div><div class="line"><span class="comment"># 画折线图展示不同参数与RMSLE的关系</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotting</span><span class="params">(params, metrics)</span>:</span></div><div class="line">    plt.plot(params, metrics)</div><div class="line">    plt.xscale(<span class="string">'log'</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估不同迭代次数对线性回归性能的影响</span></div><div class="line">params = [<span class="number">1</span>,<span class="number">5</span>,<span class="number">10</span>,<span class="number">20</span>,<span class="number">50</span>,<span class="number">100</span>,<span class="number">200</span>]</div><div class="line">metrics = [evaluate(train_data, test_data, param, <span class="number">0.01</span>, <span class="number">0.0</span>, <span class="string">'l2'</span>, <span class="keyword">False</span>) <span class="keyword">for</span> param <span class="keyword">in</span> params]</div><div class="line"><span class="keyword">print</span> params</div><div class="line"><span class="keyword">print</span> metrics</div><div class="line"></div><div class="line"><span class="comment"># 迭代次数与RMSLE的关系</span></div><div class="line">plotting(params, metrics)</div></pre></td></tr></table></figure>
<pre><code>[1, 5, 10, 20, 50, 100, 200]
[2.8779465130028195, 2.0390187660391499, 1.7761565324837874, 1.5828778102209107, 1.4382263191764473, 1.4050638054019449, 1.4191482045051593]
</code></pre><p><img src="http://img.blog.csdn.net/20160119151735437" alt="这里写图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估不同步长对线性回归性能的影响</span></div><div class="line">params = [<span class="number">0.01</span>,<span class="number">0.025</span>,<span class="number">0.05</span>,<span class="number">0.1</span>,<span class="number">1.0</span>]</div><div class="line">metrics = [evaluate(train_data, test_data, <span class="number">10</span>, param, <span class="number">0.0</span>, <span class="string">'l2'</span>, <span class="keyword">False</span>) <span class="keyword">for</span> param <span class="keyword">in</span> params]</div><div class="line"><span class="keyword">print</span> params</div><div class="line"><span class="keyword">print</span> metrics</div><div class="line"></div><div class="line"><span class="comment"># 步长与RMSLE的关系</span></div><div class="line">plotting(params, metrics)</div></pre></td></tr></table></figure>
<pre><code>[0.01, 0.025, 0.05, 0.1, 1.0]
[1.7761565324837874, 1.4379348243997032, 1.4189071944747718, 1.5027293911925559, nan]
</code></pre><p><img src="http://img.blog.csdn.net/20160119151750953" alt="这里写图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估不同L2正则化参数对线性回归性能的影响，L2正则化既是对过大的模型权重向量2范数进行惩罚</span></div><div class="line">params = [<span class="number">0.0</span>,<span class="number">0.01</span>,<span class="number">0.1</span>,<span class="number">1.0</span>,<span class="number">5.0</span>,<span class="number">10.0</span>,<span class="number">20.0</span>]</div><div class="line">metrics = [evaluate(train_data, test_data, <span class="number">10</span>, <span class="number">0.1</span>, param, <span class="string">'l2'</span>, <span class="keyword">False</span>) <span class="keyword">for</span> param <span class="keyword">in</span> params]</div><div class="line"><span class="keyword">print</span> params</div><div class="line"><span class="keyword">print</span> metrics</div><div class="line"></div><div class="line"><span class="comment"># L2正则化参数与RMSLE的关系</span></div><div class="line">plotting(params, metrics)</div></pre></td></tr></table></figure>
<pre><code>[0.0, 0.01, 0.1, 1.0, 5.0, 10.0, 20.0]
[1.5027293911925559, 1.5020646031965639, 1.4961903335175231, 1.4479313176192781, 1.4113329999970989, 1.5381692234875386, 1.8279640526059082]
</code></pre><p><img src="http://img.blog.csdn.net/20160119151809922" alt="这里写图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估不同L1正则化参数对线性回归性能的影响</span></div><div class="line">params = [<span class="number">0.0</span>,<span class="number">0.01</span>,<span class="number">0.1</span>,<span class="number">1.0</span>,<span class="number">10.0</span>,<span class="number">100.0</span>,<span class="number">1000.0</span>]</div><div class="line">metrics = [evaluate(train_data, test_data, <span class="number">10</span>, <span class="number">0.1</span>, param, <span class="string">'l1'</span>, <span class="keyword">False</span>) <span class="keyword">for</span> param <span class="keyword">in</span> params]</div><div class="line"><span class="keyword">print</span> params</div><div class="line"><span class="keyword">print</span> metrics</div><div class="line"></div><div class="line"><span class="comment"># L1正则化参数与RMSLE的关系</span></div><div class="line">plotting(params, metrics)</div></pre></td></tr></table></figure>
<pre><code>[0.0, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]
[1.5027293911925559, 1.5026938950690176, 1.5023761634555699, 1.499412856617814, 1.4713669769550108, 1.7596682962964314, 4.7551250073268614]
</code></pre><p><img src="http://img.blog.csdn.net/20160119151831845" alt="这里写图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 查看线性回归模型在不同的L1正则化参数下权重向量中0的个数</span></div><div class="line"><span class="keyword">for</span> regParam <span class="keyword">in</span> [<span class="number">1.0</span>, <span class="number">10.0</span>, <span class="number">100.0</span>]:</div><div class="line">    model = LinearRegressionWithSGD.train(train_data, <span class="number">10</span>, <span class="number">0.1</span>, regParam=regParam,\</div><div class="line">                                         regType=<span class="string">'l1'</span>, intercept=<span class="keyword">False</span>)</div><div class="line">    <span class="keyword">print</span> <span class="string">"L1 (%s) number of zero weights: "</span>%regParam + str(sum(model.weights.array == <span class="number">0</span>))</div><div class="line"><span class="comment"># L1正则化参数越大，即对模型的L1范数惩罚越大，    那么      权重</span></div></pre></td></tr></table></figure>
<pre><code>L1 (1.0) number of zero weights: 4
L1 (10.0) number of zero weights: 33
L1 (100.0) number of zero weights: 58
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估是否使用截距（intercept）对线性回归性能的影响</span></div><div class="line">params = [<span class="keyword">False</span>,<span class="keyword">True</span>]</div><div class="line">metrics = [evaluate(train_data, test_data, <span class="number">10</span>, <span class="number">0.1</span>, <span class="number">1.0</span>, <span class="string">'l2'</span>, param) <span class="keyword">for</span> param <span class="keyword">in</span> params]</div><div class="line"><span class="keyword">print</span> params</div><div class="line"><span class="keyword">print</span> metrics</div><div class="line"></div><div class="line"><span class="comment"># 是否使用截距与RMSLE的关系</span></div><div class="line">plt.bar(params, metrics, color=<span class="string">'lightblue'</span>)</div><div class="line">fig = plt.gcf()</div><div class="line"><span class="comment"># 使用截距使RMSLE有略微的增加</span></div></pre></td></tr></table></figure>
<pre><code>[False, True]
[1.4479313176192781, 1.4798261513419801]
</code></pre><p><img src="http://img.blog.csdn.net/20160119151850689" alt="这里写图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 用于在不同参数配置下评估决策回归数模型的性能</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_dt</span><span class="params">(train, test, maxDepth, maxBins)</span>:</span></div><div class="line">    model = DecisionTree.trainRegressor(train, &#123;&#125;, impurity=<span class="string">'variance'</span>, maxDepth=maxDepth, \</div><div class="line">                                          maxBins=maxBins)</div><div class="line">    preds = model.predict(test.map(<span class="keyword">lambda</span> p: p.features))</div><div class="line">    actual = test.map(<span class="keyword">lambda</span> p: p.label)</div><div class="line">    tp = actual.zip(preds)</div><div class="line">    rmsle = np.sqrt(tp.map(<span class="keyword">lambda</span> (t,p): squared_log_error(t,p)).mean())</div><div class="line">    <span class="keyword">return</span> rmsle</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估不同最大树深度对决策回归树性能的影响</span></div><div class="line">params = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">10</span>,<span class="number">20</span>]</div><div class="line">metrics = [evaluate_dt(train_data_dt, test_data_dt, param, <span class="number">32</span>) <span class="keyword">for</span> param <span class="keyword">in</span> params]</div><div class="line"><span class="keyword">print</span> params</div><div class="line"><span class="keyword">print</span> metrics</div><div class="line"></div><div class="line"><span class="comment"># 最大树深度与RMSLE的关系</span></div><div class="line">plt.plot(params, metrics)</div><div class="line">fig = plt.gcf()</div></pre></td></tr></table></figure>
<pre><code>[1, 2, 3, 4, 5, 10, 20]
[1.0280339660196287, 0.92686672078778276, 0.81807794023407532, 0.74060228537329209, 0.63583503599563096, 0.42659354467941862, 0.45291736653588244]
</code></pre><p><img src="http://img.blog.csdn.net/20160119151911393" alt="这里写图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 评估不同最大划分数对决策回归树性能的影响</span></div><div class="line">params = [<span class="number">2</span>,<span class="number">4</span>,<span class="number">8</span>,<span class="number">16</span>,<span class="number">32</span>,<span class="number">64</span>, <span class="number">100</span>]</div><div class="line">metrics = [evaluate_dt(train_data_dt, test_data_dt, <span class="number">5</span>, param) <span class="keyword">for</span> param <span class="keyword">in</span> params]</div><div class="line"><span class="keyword">print</span> params</div><div class="line"><span class="keyword">print</span> metrics</div><div class="line"></div><div class="line"><span class="comment"># 最大树深度与RMSLE的关系</span></div><div class="line">plt.plot(params, metrics)</div><div class="line">fig = plt.gcf()</div></pre></td></tr></table></figure>
<pre><code>[2, 4, 8, 16, 32, 64, 100]
[1.3069788763726049, 0.81923394899750324, 0.75745322513058744, 0.62430742982038667, 0.63583503599563096, 0.63583503599563096, 0.63583503599563096]
</code></pre><p><img src="http://img.blog.csdn.net/20160119151926877" alt="这里写图片描述"></p>
<p>###使用IPython的交互插件进行参数调优<br>需要IPython notebook<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> IPython.html.widgets <span class="keyword">import</span> interact, interactive, fixed</div><div class="line"><span class="keyword">from</span> IPython.html <span class="keyword">import</span> widgets</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(param)</span>:</span></div><div class="line">    metrics = evaluate_dt(train_data_dt, test_data_dt, <span class="number">5</span>, param)</div><div class="line">    <span class="keyword">print</span> param</div><div class="line">    <span class="keyword">print</span> metrics</div><div class="line"></div><div class="line">interact(f, param=(<span class="number">10</span>,<span class="number">20</span>));</div></pre></td></tr></table></figure></p>
<p><img src="http://img.blog.csdn.net/20160119152107317" alt="这里写图片描述"></p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/spark/" rel="tag"># spark</a>
          
            <a href="/tags/python/" rel="tag"># python</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2016/01/17/在spark上做简单的文本分类(python)/" rel="next" title="在spark上做简单的文本分类">
                <i class="fa fa-chevron-left"></i> 在spark上做简单的文本分类
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2016/01/31/1-线性代数引论/" rel="prev" title="矩阵论的线性代数基础">
                矩阵论的线性代数基础 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/7233064.jpg"
               alt="Yiyang Peng" />
          <p class="site-author-name" itemprop="name">Yiyang Peng</p>
           
              <p class="site-description motion-element" itemprop="description">Try try try Never mind</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">31</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">36</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/yiyang186" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.zhihu.com/people/peng-yiyang-88" target="_blank" title="知乎">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  知乎
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yiyang Peng</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



  


  




	





  





  






  





  

  

  

  

  

  

</body>
</html>
